<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®° | æ— å¤„æƒ¹å°˜åŸƒ</title>
<meta name="keywords" content="">
<meta name="description" content="æå›½é½: Spiking Neural Networks: from small networks to Large Models

guoqi.li@ia.ac.cn

Research background
Transformer(Google). openai: GPT
scaling law: is endless model scalin the correct approach to achieving AGI?

å¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?

power issue for today&rsquo;s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.
human brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶
overreliance on transformer architecture:


advantages: 1. exceptional performance; 2. high parallelism


disadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences">
<meta name="author" content="Muartz">
<link rel="canonical" href="https://Muatyz.github.io/posts/exp/15-computational-neuralscience-winter-school/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://Muatyz.github.io/img/Head16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Muatyz.github.io/img/Head32.png">
<link rel="apple-touch-icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="mask-icon" href="https://Muatyz.github.io/img/Head32.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Muatyz.github.io/posts/exp/15-computational-neuralscience-winter-school/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>







<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script><meta property="og:title" content="ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°" />
<meta property="og:description" content="æå›½é½: Spiking Neural Networks: from small networks to Large Models

guoqi.li@ia.ac.cn

Research background
Transformer(Google). openai: GPT
scaling law: is endless model scalin the correct approach to achieving AGI?

å¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?

power issue for today&rsquo;s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.
human brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶
overreliance on transformer architecture:


advantages: 1. exceptional performance; 2. high parallelism


disadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Muatyz.github.io/posts/exp/15-computational-neuralscience-winter-school/" />
<meta property="og:image" content="https://s2.loli.net/2026/01/19/WTL2yVOEN4Yjlmz.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2026-01-19T00:18:23+08:00" />
<meta property="article:modified_time" content="2026-01-19T00:18:23+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://s2.loli.net/2026/01/19/WTL2yVOEN4Yjlmz.jpg" />
<meta name="twitter:title" content="ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°"/>
<meta name="twitter:description" content="æå›½é½: Spiking Neural Networks: from small networks to Large Models

guoqi.li@ia.ac.cn

Research background
Transformer(Google). openai: GPT
scaling law: is endless model scalin the correct approach to achieving AGI?

å¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?

power issue for today&rsquo;s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.
human brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶
overreliance on transformer architecture:


advantages: 1. exceptional performance; 2. high parallelism


disadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Muatyz.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "â›ï¸ å®éªŒ",
          "item": "https://Muatyz.github.io/posts/exp/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°",
      "item": "https://Muatyz.github.io/posts/exp/15-computational-neuralscience-winter-school/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°",
  "name": "ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°",
  "description": "æå›½é½: Spiking Neural Networks: from small networks to Large Models guoqi.li@ia.ac.cn\nResearch background Transformer(Google). openai: GPT\nscaling law: is endless model scalin the correct approach to achieving AGI?\nå¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?\npower issue for today\u0026rsquo;s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.\nhuman brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶\noverreliance on transformer architecture:\nadvantages: 1. exceptional performance; 2. high parallelism\ndisadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences\n",
  "keywords": [
    ""
  ],
  "articleBody": "æå›½é½: Spiking Neural Networks: from small networks to Large Models guoqi.li@ia.ac.cn\nResearch background Transformer(Google). openai: GPT\nscaling law: is endless model scalin the correct approach to achieving AGI?\nå¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?\npower issue for todayâ€™s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.\nhuman brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶\noverreliance on transformer architecture:\nadvantages: 1. exceptional performance; 2. high parallelism\ndisadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences\nhow can neuroscience contribute to the foundational theories of next generation ai? ai çš„å‘å±•é€Ÿåº¦æ˜¾è‘—è¶…è¿‡äº†ç¥ç»ç§‘å­¦çš„.\nbrain inspired large model architechture(ç±»è„‘å¤§æ¨¡å‹æ¶æ„)\nat present large models have poor bio plausibility and fail to exploit the rich multi scale dynamic features of brain networks such as somatic dynamics and dnedreitic dynamics multi scale memory functions.\nlarge models do not yet reflect the characteristics of 0-1 spike communitcation /eventdriven mechanism / dynamic computing /sparse addition. which are important foundations for\nlarge models do not fully exploit the neuron diversity neuron encoding diversity resulting in insufficient generalization ability (such as continous learning multi task zeroshot learning. )\nç¥ç»å…ƒæœ¬èº«æ˜¯å…·æœ‰å¤šæ ·æ€§ç»“æ„çš„. ä½†æ˜¯å¦‚ä½•ä½“ç°åœ¨å¤§æ¨¡å‹ä¸­?\nsnn(spiking neural networks): mainstream network in brain-inspired intelligence\nann(artificial neural networks): mainstream network in deep learning.\nsnn = ann + neuronal dynamics\nproblems:\nhow to propose a suitable nrueonal model? how to build a network to solve real world ai tasks? LIF neuron: simple and easy to use. rich biological dynamics.\nå¤§è§„æ¨¡æ—¶, åŒæ­¥è®¡ç®—çš„å›°éš¾.\nhow to buikd spiking neural networks?\nlimited in scale and performamce due to the lack of large scale learning algorithms.\nback-propagation. difficult to optimize deep snn networks.\nKey Problems å¤§æ¨¡å‹æ—¶ä»£: ä¸ºäº†æå‡æ€§èƒ½, å­˜åœ¨ä¸åªæ˜¯å †å‚æ•°çš„æ–¹æ³•å—?\nä»å¤§æ¨¡å‹å‡ºå‘,\ndendritic computation\ndendritic spiking nrural networks: 1. intrinsic complexityâ€¦\ncurrent large models: based on external complexity(scaling law driven)\nnew approach: internal complexity(intrinsic complexity driven)\nparallel dendritic spiking neuron model. æ ‘çªè®¡ç®—, ç¥ç»åŠ¨åŠ›å­¦è®¡ç®—, å¹¶è¡Œç¥ç»å…ƒè®¡ç®—.\nevent driven linear self attention spiking networks for large models(çº¿æ€§å¢åŠ æˆ–è®¸å°±æ˜¯æ€§èƒ½çš„æè‡´äº†?)\nhow to accelerate the training speed of snn large models? åœ¨ gpu ä¸Š snn ä¾èµ–çš„ç®—å­(decayâ€¦) å®ç°çš„æ•ˆç‡è¾ƒä½.\nmodel \u0026 algorithm -\u003e training platform -\u003e software tool chain â€¦\nResearch Progress significant performance improvement for snns.\n2019: snn cant be trained on ImageNet\n2025: snn is comparable to annâ€™s sota level, and the energy effiency is increased by 5-30 times.\nmain challenge in snns:\ncomplex spatiotemporal dynamics(å¤æ‚æ—¶ç©ºåŠ¨åŠ›å­¦)\nbinary spike representations\nspike ä¿¡å·ä¸å¯å¯¼. (quantization error)\nsurrogate gradient error\ntraining acceleration. the Reset mechanism\ntriton framework(adapted on gpu)\nHow to train large-scale snn effectively and efficiently?\nSTBP method: spatio temporal back propagation. è§£å†³ä¸å¯å¾®åˆ†çš„é—®é¢˜. ä¼°è®¡æ¢¯åº¦ä½¿å¾—å¯åœ¨ç½‘ç»œä¸­ä¼ æ’­.\ngradient approximation.\nTDBN method:\nhow to prove that the TDBN approach prevents vanishing/exploding gradients in deep snns?\ndirect training snn: MS-ResNet (membrane shortcut ResNet)\nattention snns: multi dimensional attention:\nspike-driven transformer. new computing operation(only involves mask and addition)\nV2: versatility. handle image classification, object detecction. semantic segmentation concurrently.\nV3: binary spike firing is a mechanistic defect. integer training, spike YOLO for Object detection.\nSVL: spike-based vision-language pretraining framework\nopen-source training platform for snns: æƒŠè›°(spiking jelly)\nasychronous sensing-computing neuromorphic chip.\nspike-based dynamic computing with asynchronous sensing computing neuromorphic chip\nstatic power: 0.41mw; typical power: 1-5 mW.\nnetwork model with internal complexity bridges artificial intelligence and neuroscience.\nspikeGPT model based on snn.\nsnn based on large models: spikeLM (ternary snn).\nsnn based large models: SpikeLLM. solved the problem of outliers in the neuronal state by varying time step of spiking neurons\nUnified Linear Model Frame work: MetaLA\nunifies linear transformer, ssm, linear rnns.\nSpikingBrain ç¬æ‚‰. spike based neuromorphic large models on fpga.\nbrain inspired edge devices (traditional vision tasks) \u003c-\u003e brain inspired cloud(nlp/generative tasks).\nMichael Hausser hausser@gmail.com, ç½‘å€\nneural codes:\nspatial codes. identity; spatial patterns; number(sparse or dense)\nactivity codes\nthe cortex exihibits high derees of variability, so is this noise or information(signal)?\nwe cant record all neurons in the brain simultaneously.\n-\u003e strategy: introduce a defined small amount of noise. 1 extra AP in a neuron.\nsingle cell io curve: prob of an extra spike. p * K = 0.019 * 1500 = 28 spikes / spike(28 \\pm 13)\n28**5 \\sim 17 000 000. -\u003e single neuron can have a huge impact.\npatch-clamp and silicon probe recordings in vivo.\nsingle-neuron pertubations grow and grow fast.\nthe cortex is highly sensitive to noise\nthe neural code must be robust to perturbations.\nuse light to build the model of neurons. advantages: non-invasive; inert; precise; multiplexable; targetable.\ntwo revolutions using light to probe neural circuits.\nrecord (ohki nature 2005)\nmanipulate(boyden nature 2005)\nthe challenge: combine recording(è®°å½•) and manipulation(æ“æ§).\nconventional optogenetics: unknown numbers of activated cells/spatial distribution of activated cells; cells targeted by genetic not functional identity; synchrony across the network.\nreplaying the neural code with light(hausser \u0026 smith 2007): calcium sensor channel rhodopsin\nall-optical toolkit\ntwo-photon optogenetics of dendritic spines and neural circuits.\nspatial light modulator(slm): a programmable beam splitter for digital holography.\nmicrosope design.\noptical insertion of single spikes in single neurons.\nconceptual goals: read \u0026 write;\nthe state of the art: subcellular connectivity probing across brain.\n",
  "wordCount" : "1136",
  "inLanguage": "zh",
  "image":"https://s2.loli.net/2026/01/19/WTL2yVOEN4Yjlmz.jpg","datePublished": "2026-01-19T00:18:23+08:00",
  "dateModified": "2026-01-19T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "Muartz"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Muatyz.github.io/posts/exp/15-computational-neuralscience-winter-school/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "æ— å¤„æƒ¹å°˜åŸƒ",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Muatyz.github.io/img/Head32.png"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  CommonHTML: {
  scale: 100
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
  
  
  
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script>

<style>
  code.has-jax {
      font: "LXGW WenKai Screen", sans-serif, Arial;
      scale: 1;
      background: "LXGW WenKai Screen", sans-serif, Arial;
      border: "LXGW WenKai Screen", sans-serif, Arial;
      color: #515151;
  }
</style>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Muatyz.github.io/" accesskey="h" title="è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿— (Alt + H)">
            <img src="https://Muatyz.github.io/img/Head64.png" alt="logo" aria-label="logo"
                 height="35">è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿—</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Muatyz.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Muatyz.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/exp/">â›ï¸ å®éªŒ</a></div>
            <h1 class="post-title">
                ç¬¬ 15 å±Šè®¡ç®—ç¥ç»ç§‘å­¦å†¬å­£å­¦æ ¡å‚ä¼šç¬”è®°
            </h1>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2026-01-19
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>1136å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>3åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Muartz
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://Muatyz.github.io/tags/physics/" style="color: var(--secondary)!important;">Physics</a>
                &nbsp;<a href="https://Muatyz.github.io/tags/numerical-calculation/" style="color: var(--secondary)!important;">Numerical Calculation</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Muatyz.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId: "Admin", 
                                region: "ap-shanghai", 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://s2.loli.net/2026/01/19/WTL2yVOEN4Yjlmz.jpg" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e6%9d%8e%e5%9b%bd%e9%bd%90-spiking-neural-networks-from-small-networks-to-large-models" aria-label="æå›½é½: Spiking Neural Networks: from small networks to Large Models">æå›½é½: Spiking Neural Networks: from small networks to Large Models</a><ul>
                        
                <li>
                    <a href="#research-background" aria-label="Research background">Research background</a></li>
                <li>
                    <a href="#key-problems" aria-label="Key Problems">Key Problems</a></li>
                <li>
                    <a href="#research-progress" aria-label="Research Progress">Research Progress</a></li></ul>
                </li>
                <li>
                    <a href="#michael-hausser" aria-label="Michael Hausser">Michael Hausser</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="æå›½é½-spiking-neural-networks-from-small-networks-to-large-models">æå›½é½: Spiking Neural Networks: from small networks to Large Models<a hidden class="anchor" aria-hidden="true" href="#æå›½é½-spiking-neural-networks-from-small-networks-to-large-models">#</a></h1>
<blockquote>
<p><a href="mailto:guoqi.li@ia.ac.cn">guoqi.li@ia.ac.cn</a></p>
</blockquote>
<h2 id="research-background">Research background<a hidden class="anchor" aria-hidden="true" href="#research-background">#</a></h2>
<p>Transformer(Google). openai: GPT</p>
<p>scaling law: is endless model scalin the correct approach to achieving AGI?</p>
<blockquote>
<p>å¦‚ä½•æ‰¾åˆ° scaling lwa ä¹‹å¤–å¯æŒç»­é©±åŠ¨å½“å‰ ai ç³»ç»Ÿåˆ°æ–°é˜¶æ®µçš„ AGI ç³»ç»Ÿ?</p>
</blockquote>
<p>power issue for today&rsquo;s AI system: åŠŸè€—éšç€æ€§èƒ½è¡¨ç°æå‡è€ŒæŒ‡æ•°å¢é•¿.</p>
<p>human brain vs current large models: äººè„‘ä»¥è¿œè¶…å¤§æ¨¡å‹çš„å‚æ•°é‡, ä»…æ¶ˆè€— 20W çš„åŠŸç‡(å¤§æ¨¡å‹ 300KW). å¦‚ä½•å€Ÿé‰´å¤§è„‘çš„æœºåˆ¶</p>
<p>overreliance on transformer architecture:</p>
<ul>
<li>
<p>advantages: 1. exceptional performance; 2. high parallelism</p>
</li>
<li>
<p>disadvantages: 1. quadratically with sequence length 2. linear growth in time and space complexity 3. challenges in handling ultra-long sequences</p>
</li>
</ul>
<p>how can neuroscience contribute to the foundational theories of next generation ai? ai çš„å‘å±•é€Ÿåº¦æ˜¾è‘—è¶…è¿‡äº†ç¥ç»ç§‘å­¦çš„.</p>
<p>brain inspired large model architechture(ç±»è„‘å¤§æ¨¡å‹æ¶æ„)</p>
<ol>
<li>
<p>at present large models have poor bio plausibility and fail to exploit the rich multi scale dynamic features of brain networks such as somatic dynamics and dnedreitic dynamics multi scale memory functions.</p>
</li>
<li>
<p>large models do not yet reflect the characteristics of 0-1 spike communitcation /eventdriven mechanism / dynamic computing /sparse addition. which are important foundations for</p>
</li>
<li>
<p>large models do not fully exploit the neuron diversity neuron encoding diversity resulting in insufficient generalization ability (such as continous learning multi task zeroshot learning. )</p>
</li>
</ol>
<blockquote>
<p>ç¥ç»å…ƒæœ¬èº«æ˜¯å…·æœ‰å¤šæ ·æ€§ç»“æ„çš„. ä½†æ˜¯å¦‚ä½•ä½“ç°åœ¨å¤§æ¨¡å‹ä¸­?</p>
</blockquote>
<ul>
<li>
<p>snn(spiking neural networks): mainstream network in brain-inspired intelligence</p>
</li>
<li>
<p>ann(artificial neural networks): mainstream network in deep learning.</p>
</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2026/01/19/A5t1J9fE4zIylWU.jpg" alt=""  />
<img loading="lazy" src="https://s2.loli.net/2026/01/19/FDlIRPYdXeVynZN.jpg" alt=""  /></p>
<p>snn = ann + neuronal dynamics</p>
<p>problems:</p>
<ul>
<li>how to propose a suitable nrueonal model?</li>
<li>how to build a network to solve real world ai tasks?</li>
</ul>
<p>LIF neuron: simple and easy to use. rich biological dynamics.</p>
<p>å¤§è§„æ¨¡æ—¶, åŒæ­¥è®¡ç®—çš„å›°éš¾.</p>
<p>how to buikd spiking neural networks?</p>
<p>limited in scale and performamce due to the lack of large scale learning algorithms.</p>
<p>back-propagation. difficult to optimize deep snn networks.</p>
<h2 id="key-problems">Key Problems<a hidden class="anchor" aria-hidden="true" href="#key-problems">#</a></h2>
<ol>
<li>
<p>å¤§æ¨¡å‹æ—¶ä»£: ä¸ºäº†æå‡æ€§èƒ½, å­˜åœ¨ä¸åªæ˜¯å †å‚æ•°çš„æ–¹æ³•å—?</p>
</li>
<li>
<p>ä»å¤§æ¨¡å‹å‡ºå‘,</p>
</li>
</ol>
<p>dendritic computation</p>
<p>dendritic spiking nrural networks: 1. intrinsic complexity&hellip;</p>
<p>current large models: based on external complexity(scaling law driven)</p>
<p>new approach: internal complexity(intrinsic complexity driven)</p>
<ol>
<li>
<p>parallel dendritic spiking neuron model. æ ‘çªè®¡ç®—, ç¥ç»åŠ¨åŠ›å­¦è®¡ç®—, å¹¶è¡Œç¥ç»å…ƒè®¡ç®—.</p>
</li>
<li>
<p>event driven linear self attention spiking networks for large models(çº¿æ€§å¢åŠ æˆ–è®¸å°±æ˜¯æ€§èƒ½çš„æè‡´äº†?)</p>
</li>
<li>
<p>how to accelerate the training speed of snn large models?  åœ¨ gpu ä¸Š snn ä¾èµ–çš„ç®—å­(decay&hellip;) å®ç°çš„æ•ˆç‡è¾ƒä½.</p>
</li>
</ol>
<p>model &amp; algorithm -&gt; training platform -&gt; software tool chain &hellip;</p>
<h2 id="research-progress">Research Progress<a hidden class="anchor" aria-hidden="true" href="#research-progress">#</a></h2>
<p>significant performance improvement for snns.</p>
<p>2019: snn cant be trained on ImageNet</p>
<p>2025: snn is comparable to ann&rsquo;s sota level, and the energy effiency is increased by 5-30 times.</p>
<p>main challenge in snns:</p>
<ol>
<li>
<p>complex spatiotemporal dynamics(å¤æ‚æ—¶ç©ºåŠ¨åŠ›å­¦)</p>
</li>
<li>
<p>binary spike representations</p>
</li>
</ol>
<p>spike ä¿¡å·ä¸å¯å¯¼. (quantization error)</p>
<p>surrogate gradient error</p>
<ol start="3">
<li>training acceleration.</li>
</ol>
<p>the Reset mechanism</p>
<p>triton framework(adapted on gpu)</p>
<p>How to train large-scale snn effectively and efficiently?</p>
<p>STBP method: spatio temporal back propagation. è§£å†³ä¸å¯å¾®åˆ†çš„é—®é¢˜. ä¼°è®¡æ¢¯åº¦ä½¿å¾—å¯åœ¨ç½‘ç»œä¸­ä¼ æ’­.</p>
<p>gradient approximation.</p>
<p>TDBN method:</p>
<p>how to prove that the TDBN approach prevents vanishing/exploding gradients in deep snns?</p>
<p>direct training snn: MS-ResNet (membrane shortcut ResNet)</p>
<p>attention snns: multi dimensional attention:</p>
<p>spike-driven transformer. new computing operation(only involves mask and addition)</p>
<ul>
<li>
<p>V2: versatility. handle image classification, object detecction. semantic segmentation concurrently.</p>
</li>
<li>
<p>V3: binary spike firing is a mechanistic defect. integer training, spike YOLO for Object detection.</p>
</li>
</ul>
<p>SVL: spike-based vision-language pretraining framework</p>
<p>open-source training platform for snns: æƒŠè›°(spiking jelly)</p>
<p>asychronous sensing-computing neuromorphic chip.</p>
<p>spike-based dynamic computing with asynchronous sensing computing neuromorphic chip</p>
<p>static power: 0.41mw; typical power: 1-5 mW.</p>
<p>network model with internal complexity bridges artificial intelligence and neuroscience.</p>
<p>spikeGPT model based on snn.</p>
<p>snn based on large models: spikeLM (ternary snn).</p>
<p>snn based large models: SpikeLLM.  solved the problem of outliers in the neuronal state by varying time step of spiking neurons</p>
<p>Unified Linear Model Frame work: MetaLA</p>
<p>unifies linear transformer, ssm, linear rnns.</p>
<p>SpikingBrain ç¬æ‚‰. <a href="https://aurora-surgeon-instructor-brooks.trycloudflare.com" target="_blank" rel="noopener nofollow noreferrer" ></a></p>
<p>spike based neuromorphic large models on fpga.</p>
<p>brain inspired edge devices (traditional vision tasks) &lt;-&gt; brain inspired cloud(nlp/generative tasks).</p>
<h1 id="michael-hausser">Michael Hausser<a hidden class="anchor" aria-hidden="true" href="#michael-hausser">#</a></h1>
<blockquote>
<p><a href="mailto:hausser@gmail.com">hausser@gmail.com</a>, <a href="www.dendrites.org">ç½‘å€</a></p>
</blockquote>
<p>neural codes:</p>
<ul>
<li>
<p>spatial codes. identity; spatial patterns; number(sparse or dense)</p>
</li>
<li>
<p>activity codes</p>
</li>
</ul>
<p>the cortex exihibits high derees of variability, so is this noise or information(signal)?</p>
<p>we cant record all neurons in the brain simultaneously.</p>
<p>-&gt; strategy: introduce a defined small amount of noise. 1 extra AP in a neuron.</p>
<ul>
<li>single cell io curve: prob of an extra spike.</li>
</ul>
<p>p * K = 0.019 * 1500 = 28 spikes / spike(28 \pm 13)</p>
<p>28**5 \sim 17 000 000. -&gt; single neuron can have a huge impact.</p>
<p>patch-clamp and silicon probe recordings in vivo.</p>
<ul>
<li>
<p>single-neuron pertubations grow and grow fast.</p>
</li>
<li>
<p>the cortex is highly sensitive to noise</p>
</li>
<li>
<p>the neural code must be robust to perturbations.</p>
</li>
</ul>
<p>use light to build the model of neurons. advantages: non-invasive; inert; precise; multiplexable; targetable.</p>
<p>two revolutions using light to probe neural circuits.</p>
<ol>
<li>
<p>record (ohki nature 2005)</p>
</li>
<li>
<p>manipulate(boyden nature 2005)</p>
</li>
</ol>
<p>the challenge: combine recording(è®°å½•) and manipulation(æ“æ§).</p>
<p>conventional optogenetics:  unknown numbers of activated cells/spatial distribution of activated cells; cells targeted by genetic not functional identity; synchrony across the network.</p>
<p>replaying the neural code with light(hausser &amp; smith 2007): calcium sensor channel rhodopsin</p>
<p>all-optical toolkit</p>
<p>two-photon optogenetics of dendritic spines and neural circuits.</p>
<p>spatial light modulator(slm): a programmable beam splitter for digital holography.</p>
<p>microsope design.</p>
<p>optical insertion of single spikes in single neurons.</p>
<p>conceptual goals: read &amp; write;</p>
<p>the state of the art: subcellular connectivity probing across brain.</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Muatyz.github.io/posts/read/reference/statistical-mechanics-for-networks-of-real-neurons/statistical-mechanics-for-networks-of-real-neurons-7/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>Renormalization group for neurons</span>
  </a>
  <a class="next" href="https://Muatyz.github.io/posts/life/2026-document/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>2026 å¹´åº¦éšç¬”</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>





<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-api-one-xi.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            region: 'ap-shanghai',  
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>Muartz</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script><script>

    let detail = document.getElementsByClassName('details')
   
    details = [].slice.call(detail);
   
    for (let index = 0; index < details.length; index++) {
   
    let element = details[index]
   
    const summary = element.getElementsByClassName('details-summary')[0];
   
    if (summary) {
   
    summary.addEventListener('click', () => {
   
    element.classList.toggle('open');
   
    }, false);
   
    }
   
    }
   
   </script>   

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>


<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        
        
        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        
        
        

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>


<script>
    
    document.addEventListener('keydown', function(event) {
      
      if (event.key === 'j') {
        
        var nextPageLink = document.querySelector('.pagination-item.pagination-next > a');
        if (nextPageLink) {
          nextPageLink.click();
        }
      } else if (event.key === 'k') {
        
        var prevPageLink = document.querySelector('.pagination-item.pagination-previous > a');
        if (prevPageLink) {
          prevPageLink.click();
        }
      }
    });
  </script>
  
</body>







<body>
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
</body>


</html>
