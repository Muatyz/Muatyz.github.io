<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Neurons with graded response have collective computational properties like those of two-state neurons | æ— å¤„æƒ¹å°˜åŸƒ</title>
<meta name="keywords" content="">
<meta name="description" content="Hopfield model">
<meta name="author" content="Muartz">
<link rel="canonical" href="https://Muatyz.github.io/posts/read/reference/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://Muatyz.github.io/img/Head16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Muatyz.github.io/img/Head32.png">
<link rel="apple-touch-icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="mask-icon" href="https://Muatyz.github.io/img/Head32.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Muatyz.github.io/posts/read/reference/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>







<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script><meta property="og:title" content="Neurons with graded response have collective computational properties like those of two-state neurons" />
<meta property="og:description" content="Hopfield model" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Muatyz.github.io/posts/read/reference/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/" />
<meta property="og:image" content="https://s2.loli.net/2025/10/12/scPqfCW3HNJn8Kr.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-10-12T00:18:23+08:00" />
<meta property="article:modified_time" content="2025-10-12T00:18:23+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://s2.loli.net/2025/10/12/scPqfCW3HNJn8Kr.png" />
<meta name="twitter:title" content="Neurons with graded response have collective computational properties like those of two-state neurons"/>
<meta name="twitter:description" content="Hopfield model"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Muatyz.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "ğŸ“• é˜…è¯»",
          "item": "https://Muatyz.github.io/posts/read/"
        },

        {
          "@type": "ListItem",
          "position":  3 ,
          "name": "ğŸ“• æ–‡çŒ®",
          "item": "https://Muatyz.github.io/posts/read/reference/"
        }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Neurons with graded response have collective computational properties like those of two-state neurons",
      "item": "https://Muatyz.github.io/posts/read/reference/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Neurons with graded response have collective computational properties like those of two-state neurons",
  "name": "Neurons with graded response have collective computational properties like those of two-state neurons",
  "description": "Hopfield model",
  "keywords": [
    ""
  ],
  "articleBody": "Discussion Abstract A model for a large network of â€œneuronsâ€ with a graded response (or sigmoid input-output relation) is studied. This deterministic system has collective properties in very close correspondence with the earlier stochastic model based on McCulloch-Pitts neurons. The content-addressable memory and other emergent collective properties of the original model also are present in the graded response model. The idea that such collective properties are used in biological systems is given added credence by the continued presence of such properties for more nearly biological â€œneurons.â€ Collective analog electrical circuits of the kind described will certainly function. The collective states of the two models have a simple correspondence. The original model will continue to be useful for simulations, because its connection to graded response systems is established. Equations that include the effect of action potentials in the graded response system are also developed.\næœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªå…·æœ‰åˆ†çº§å“åº”ï¼ˆæˆ–è¥¿æ ¼ç›è¾“å…¥-è¾“å‡ºå…³ç³»ï¼‰çš„å¤§å‹ â€œç¥ç»å…ƒâ€ ç½‘ç»œæ¨¡å‹ã€‚è¿™ä¸ªç¡®å®šæ€§ç³»ç»Ÿçš„é›†ä½“ç‰¹æ€§ä¸æ—©æœŸåŸºäº McCulloch-Pitts ç¥ç»å…ƒçš„éšæœºæ¨¡å‹éå¸¸æ¥è¿‘ã€‚åŸå§‹æ¨¡å‹çš„å†…å®¹å¯å¯»å€è®°å¿†å’Œå…¶ä»–çªå‘æ€§é›†ä½“ç‰¹æ€§ä¹Ÿå­˜åœ¨äºåˆ†çº§å“åº”æ¨¡å‹ä¸­ã€‚æ›´æ¥è¿‘ç”Ÿç‰© â€œç¥ç»å…ƒâ€ çš„é›†ä½“ç‰¹æ€§çš„æŒç»­å­˜åœ¨ï¼Œä½¿è¿™ç§é›†ä½“ç‰¹æ€§ç”¨äºç”Ÿç‰©ç³»ç»Ÿçš„è§‚ç‚¹æ›´åŠ å¯ä¿¡ã€‚æ‰€æè¿°çš„é‚£ç§é›†ä½“æ¨¡æ‹Ÿç”µè·¯è‚¯å®šä¼šå‘æŒ¥ä½œç”¨ã€‚ä¸¤ç§æ¨¡å‹çš„é›†ä½“çŠ¶æ€æœ‰ç€ç®€å•çš„å¯¹åº”å…³ç³»ã€‚åŸå§‹æ¨¡å‹å°†ç»§ç»­ç”¨äºæ¨¡æ‹Ÿï¼Œå› ä¸ºå®ƒä¸åˆ†çº§å“åº”ç³»ç»Ÿçš„è”ç³»å·²ç»å»ºç«‹ã€‚æ­¤å¤–ï¼Œè¿˜å»ºç«‹äº†åŒ…æ‹¬åˆ†çº§å“åº”ç³»ç»Ÿä¸­åŠ¨ä½œç”µä½æ•ˆåº”çš„æ–¹ç¨‹ã€‚\nRecent papers have explored the ability of a system of highly interconnected â€œneuronsâ€ to have useful collective computational properties. These properties emerge spontaneously in a system having a large number of elementary â€œneurons.â€ Content-addressable memory (CAM) is one of the simplest collective properties of such a system. The mathematical modeling has been based on â€œneuronsâ€ that are different both from real biological neurons and from the realistic functioning of simple electronic circuits. Some of these differences are major enough that neurobiologists and circuit engineers alike have questioned whether real neural or electrical circuits would actually exhibit the kind of behaviors found in the model system even if the â€œneuronsâ€ were connected in the fashion envisioned.\næœ€è¿‘çš„è®ºæ–‡æ¢è®¨äº†é«˜åº¦äº’è”çš„ â€œç¥ç»å…ƒâ€ ç³»ç»Ÿå…·æœ‰æœ‰ç”¨çš„é›†ä½“è®¡ç®—ç‰¹æ€§çš„èƒ½åŠ›ã€‚è¿™äº›ç‰¹æ€§åœ¨å…·æœ‰å¤§é‡åŸºæœ¬ â€œç¥ç»å…ƒâ€ çš„ç³»ç»Ÿä¸­è‡ªå‘å‡ºç°ã€‚å†…å®¹å¯å¯»å€è®°å¿†ï¼ˆCAMï¼‰æ˜¯è¿™ç§ç³»ç»Ÿæœ€ç®€å•çš„é›†ä½“ç‰¹æ€§ä¹‹ä¸€ã€‚æ•°å­¦å»ºæ¨¡åŸºäºçš„ â€œç¥ç»å…ƒâ€ ä¸çœŸå®çš„ç”Ÿç‰©ç¥ç»å…ƒå’Œç®€å•ç”µå­ç”µè·¯çš„ç°å®åŠŸèƒ½éƒ½ä¸åŒã€‚å…¶ä¸­ä¸€äº›å·®å¼‚è¶³å¤Ÿå¤§ï¼Œä»¥è‡³äºç¥ç»ç”Ÿç‰©å­¦å®¶å’Œç”µè·¯å·¥ç¨‹å¸ˆéƒ½è´¨ç–‘ï¼Œå³ä½¿ â€œç¥ç»å…ƒâ€ ä»¥è®¾æƒ³çš„æ–¹å¼è¿æ¥ï¼ŒçœŸå®çš„ç¥ç»æˆ–ç”µè·¯æ˜¯å¦çœŸçš„ä¼šè¡¨ç°å‡ºæ¨¡å‹ç³»ç»Ÿä¸­å‘ç°çš„é‚£ç§è¡Œä¸ºã€‚\nTwo major divergences between the model and biological or physical systems stand out. Real neurons (and real physical devices such as operational amplifiers that might mimic them) have continuous input-output relations. (Action potentials are omitted until Discussion.) The original modeling used two-state McCulloch-Pitts (4) threshold devices having outputs of 0 or 1 only. Real neurons and real physical circuits have integrative time delays due to capacitance, and the time evolution of the state of such systems should be represented by a differential equation (perhaps with added noise). The original modeling used a stochastic algorithm involving sudden 0-1 or 1-0 changes of states of neurons at random times. This paper shows that the important properties of the original model remain intact when these two simplifications of the modeling are eliminated. Although it is uncertain whether the properties of these new continuous â€œneuronsâ€ are yet close enough to the essential properties of real neurons (and/or their dendritic arborization) to be directly applicable to neurobiology, a major conceptual obstacle has been eliminated. It is certain that a CAM constructed on the basic ideas of the original model (1) but built of operational amplifiers and resistors will function.\næœ¬æ–‡çªå‡ºäº†æ¨¡å‹ä¸ç”Ÿç‰©æˆ–ç‰©ç†ç³»ç»Ÿä¹‹é—´çš„ä¸¤ä¸ªä¸»è¦å·®å¼‚ã€‚çœŸå®çš„ç¥ç»å…ƒï¼ˆä»¥åŠå¯èƒ½æ¨¡ä»¿å®ƒä»¬çš„è¿ç®—æ”¾å¤§å™¨ç­‰çœŸå®ç‰©ç†è®¾å¤‡ï¼‰å…·æœ‰è¿ç»­çš„è¾“å…¥-è¾“å‡ºå…³ç³»ã€‚ï¼ˆåŠ¨ä½œç”µä½åœ¨ è®¨è®º ä¹‹å‰è¢«çœç•¥ã€‚ï¼‰åŸå§‹å»ºæ¨¡ä½¿ç”¨äº†åªæœ‰ 0 æˆ– 1 è¾“å‡ºçš„ä¸¤æ€ McCulloch-Pitts (4) é˜ˆå€¼è®¾å¤‡ã€‚çœŸå®çš„ç¥ç»å…ƒå’ŒçœŸå®çš„ç‰©ç†ç”µè·¯ç”±äºç”µå®¹è€Œå…·æœ‰ç§¯åˆ†æ—¶é—´å»¶è¿Ÿï¼Œè¿™ç§ç³»ç»ŸçŠ¶æ€çš„æ—¶é—´æ¼”åŒ–åº”è¯¥ç”±å¾®åˆ†æ–¹ç¨‹ï¼ˆå¯èƒ½åŠ ä¸Šå™ªå£°ï¼‰è¡¨ç¤ºã€‚åŸå§‹å»ºæ¨¡ä½¿ç”¨äº†ä¸€ç§éšæœºç®—æ³•ï¼Œæ¶‰åŠç¥ç»å…ƒçŠ¶æ€åœ¨éšæœºæ—¶é—´çªç„¶ä» 0-1 æˆ– 1-0 çš„å˜åŒ–ã€‚æœ¬æ–‡è¡¨æ˜ï¼Œå½“æ¶ˆé™¤è¿™ä¸¤ç§ç®€åŒ–å»ºæ¨¡æ—¶ï¼ŒåŸå§‹æ¨¡å‹çš„é‡è¦å±æ€§ä»ç„¶ä¿æŒä¸å˜ã€‚å°½ç®¡å°šä¸ç¡®å®šè¿™äº›æ–°çš„è¿ç»­ â€œç¥ç»å…ƒâ€ çš„å±æ€§æ˜¯å¦è¶³å¤Ÿæ¥è¿‘çœŸå®ç¥ç»å…ƒï¼ˆå’Œ/æˆ–å®ƒä»¬çš„æ ‘çªåˆ†æ”¯ï¼‰çš„åŸºæœ¬å±æ€§ï¼Œä»¥ç›´æ¥åº”ç”¨äºç¥ç»ç”Ÿç‰©å­¦ï¼Œä½†ä¸€ä¸ªä¸»è¦çš„æ¦‚å¿µéšœç¢å·²ç»è¢«æ¶ˆé™¤ã€‚å¯ä»¥è‚¯å®šçš„æ˜¯ï¼ŒåŸºäºåŸå§‹æ¨¡å‹ï¼ˆ1ï¼‰çš„åŸºæœ¬æ€æƒ³æ„å»ºçš„ CAMï¼Œä½†ç”±è¿ç®—æ”¾å¤§å™¨å’Œç”µé˜»å™¨æ„æˆï¼Œå°†ä¼šå‘æŒ¥ä½œç”¨ã€‚\nForm of the Original Model The original model used two-state threshold â€œneuronsâ€ that followed a stochastic algorithm. Each model neuron $i$ had two states, characterized by the output $V_{i}$ of the neuron having the values $V_{i}^{0}$ or $V_{i}^{1}$ (which may often be taken as 0 and 1, respectively). The input of each neuron came from two sources, external inputs $I_{i}$ and inputs from other neurons. The total input to neuron $i$ is then\n$$ \\text{Input to}\\space i =H_{i} = \\sum_{j\\neq i}T_{ij}V_{j}+I_{i} $$\nThe element $T_{ij}$ can be biologically viewed as a description of the synaptic interconnection strength from neuron $j$ to neuron $i$.\nåŸå§‹æ¨¡å‹ä½¿ç”¨äº†éµå¾ªéšæœºç®—æ³•çš„ä¸¤æ€é˜ˆå€¼ â€œç¥ç»å…ƒâ€ã€‚æ¯ä¸ªæ¨¡å‹ç¥ç»å…ƒ $i$ æœ‰ä¸¤ä¸ªçŠ¶æ€ï¼Œå…¶è¾“å‡º $V_{i}$ çš„å€¼åˆ†åˆ«ä¸º $V_{i}^{0}$ æˆ– $V_{i}^{1}$ï¼ˆé€šå¸¸å¯ä»¥åˆ†åˆ«å–ä¸º 0 å’Œ 1ï¼‰ã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥æ¥è‡ªä¸¤ä¸ªæ¥æºï¼Œå¤–éƒ¨è¾“å…¥ $I_{i}$ å’Œæ¥è‡ªå…¶ä»–ç¥ç»å…ƒçš„è¾“å…¥ã€‚ç¥ç»å…ƒ $i$ çš„æ€»è¾“å…¥ä¸º\n$$ \\text{Input to}\\space i =H_{i} = \\sum_{j\\neq i}T_{ij}V_{j}+I_{i} $$\nå…ƒç´  $T_{ij}$ å¯ä»¥ä»ç”Ÿç‰©å­¦è§’åº¦çœ‹ä½œæ˜¯æè¿°ä»ç¥ç»å…ƒ $j$ åˆ°ç¥ç»å…ƒ $i$ çš„çªè§¦è¿æ¥å¼ºåº¦ã€‚\nCAM and other useful computations in this system involve the change of state of the system with time. The motion of the state of a system of $N$ neurons in state space describes the computation that the set of neurons is performing. A model therefore must describe how the state evolves in time, and the original model describes this in terms of a stochastic evolution. Each neuron samples its input at random times. It changes the value of its output or leaves it fixed according to a threshold rule with thresholds $U_{i}$.\n$$ \\begin{equation*} \\begin{aligned} V_{i} \u0026\\rightarrow V_{i}^{0}\\space\\text{if}\\space \\sum_{j\\neq i}T_{ij}V_{j}+I_{i} U_{i}. \\end{aligned} \\end{equation*} $$\nThe interrogation of each neuron is a stochastic process, taking place at a mean rate $W$ for each neuron. The times of interrogation of each neuron are independent of the times at which other neurons are interrogated. The algorithm is thus asynchronous, in contrast to the usual kind of processing done with threshold devices. This asynchrony was deliberately introduced to represent a combination of propagation delays, jitter, and noise in real neural systems. Synchronous systems might have additional collective properties.\nCAM å’Œè¯¥ç³»ç»Ÿä¸­çš„å…¶ä»–æœ‰ç”¨è®¡ç®—æ¶‰åŠç³»ç»ŸçŠ¶æ€éšæ—¶é—´çš„å˜åŒ–ã€‚$N$ ä¸ªç¥ç»å…ƒç³»ç»ŸçŠ¶æ€ç©ºé—´ä¸­çŠ¶æ€çš„è¿åŠ¨æè¿°äº†ç¥ç»å…ƒé›†åˆæ­£åœ¨æ‰§è¡Œçš„è®¡ç®—ã€‚å› æ­¤ï¼Œæ¨¡å‹å¿…é¡»æè¿°çŠ¶æ€å¦‚ä½•éšæ—¶é—´æ¼”å˜ï¼ŒåŸå§‹æ¨¡å‹é€šè¿‡éšæœºæ¼”åŒ–æ¥æè¿°è¿™ä¸€ç‚¹ã€‚æ¯ä¸ªç¥ç»å…ƒåœ¨éšæœºæ—¶é—´é‡‡æ ·å…¶è¾“å…¥ã€‚å®ƒæ ¹æ®é˜ˆå€¼è§„åˆ™å’Œé˜ˆå€¼ $U_{i}$ æ”¹å˜å…¶è¾“å‡ºå€¼æˆ–ä¿æŒä¸å˜ã€‚\n$$ \\begin{equation*} \\begin{aligned} V_{i} \u0026\\rightarrow V_{i}^{0}\\space\\text{if}\\space \\sum_{j\\neq i}T_{ij}V_{j}+I_{i} U_{i}. \\end{aligned} \\end{equation*} $$\næ¯ä¸ªç¥ç»å…ƒçš„è¯¢é—®æ˜¯ä¸€ä¸ªéšæœºè¿‡ç¨‹ï¼Œæ¯ä¸ªç¥ç»å…ƒä»¥å¹³å‡é€Ÿç‡ $W$ è¿›è¡Œã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¯¢é—®æ—¶é—´ä¸å…¶ä»–ç¥ç»å…ƒçš„è¯¢é—®æ—¶é—´ç›¸äº’ç‹¬ç«‹ã€‚å› æ­¤ï¼Œè¯¥ç®—æ³•æ˜¯å¼‚æ­¥çš„ï¼Œè¿™ä¸ä½¿ç”¨é˜ˆå€¼è®¾å¤‡è¿›è¡Œçš„é€šå¸¸å¤„ç†æ–¹å¼å½¢æˆå¯¹æ¯”ã€‚è¿™ç§å¼‚æ­¥æ€§æ˜¯ä¸ºäº†è¡¨ç¤ºçœŸå®ç¥ç»ç³»ç»Ÿä¸­çš„ä¼ æ’­å»¶è¿Ÿã€æŠ–åŠ¨å’Œå™ªå£°çš„ç»„åˆè€Œæ•…æ„å¼•å…¥çš„ã€‚åŒæ­¥ç³»ç»Ÿå¯èƒ½å…·æœ‰é¢å¤–çš„é›†ä½“ç‰¹æ€§ã€‚\nThe original model behaves as an associative memory (or CAM) when the state space flow generated by the algorithm is characterized by a set of stable fixed points. If these stable points describe a simple flow in which nearby points in state space tend to remain close during the flow (i.e., a nonmixing flow), then initial states that are close (in Hamming distance) to a particular stable state and far from all others will tend to terminate in that nearby stable state.\nå½“ç®—æ³•ç”Ÿæˆçš„çŠ¶æ€ç©ºé—´æµä»¥ä¸€ç»„ç¨³å®šçš„å›ºå®šç‚¹ä¸ºç‰¹å¾æ—¶ï¼ŒåŸå§‹æ¨¡å‹è¡¨ç°ä¸ºè”æƒ³è®°å¿†ï¼ˆæˆ– CAMï¼‰ã€‚å¦‚æœè¿™äº›ç¨³å®šç‚¹æè¿°äº†ä¸€ä¸ªç®€å•çš„æµï¼Œå…¶ä¸­çŠ¶æ€ç©ºé—´ä¸­ç›¸é‚»çš„ç‚¹åœ¨æµåŠ¨è¿‡ç¨‹ä¸­å€¾å‘äºä¿æŒæ¥è¿‘ï¼ˆå³éæ··åˆæµï¼‰ï¼Œé‚£ä¹ˆä¸ç‰¹å®šç¨³å®šçŠ¶æ€æ¥è¿‘ï¼ˆåœ¨Hamming è·ç¦»ä¸Šï¼‰ä¸”è¿œç¦»æ‰€æœ‰å…¶ä»–çŠ¶æ€çš„åˆå§‹çŠ¶æ€å°†å€¾å‘äºç»ˆæ­¢åœ¨é‚£ä¸ªé™„è¿‘çš„ç¨³å®šçŠ¶æ€ä¸­ã€‚\nIf the location of a particular stable point in state space is thought of as the information of a particular memory of the system, states near to that particular stable point contain partial information aboutâ€™ that memory. From an initial state of partial information about a memory, a final stable state with all the information of the memory is found. The memory is reached not by knowing an address, but rather by supplying in the initial state some subpart of the memory. Any subpart of adequate size will do-the memory is truly addressable by content rather than location. A given $T$ matrix contains many memories simultaneously, which are reconstructed individually from partial information in an initial state.\nå¦‚æœå°†çŠ¶æ€ç©ºé—´ä¸­ç‰¹å®šç¨³å®šç‚¹çš„ä½ç½®è§†ä¸ºç³»ç»Ÿç‰¹å®šè®°å¿†çš„ä¿¡æ¯ï¼Œé‚£ä¹ˆæ¥è¿‘è¯¥ç‰¹å®šç¨³å®šç‚¹çš„çŠ¶æ€åŒ…å«æœ‰å…³è¯¥è®°å¿†çš„éƒ¨åˆ†ä¿¡æ¯ã€‚ä»å…³äºè®°å¿†çš„éƒ¨åˆ†ä¿¡æ¯çš„åˆå§‹çŠ¶æ€ï¼Œå¯ä»¥æ‰¾åˆ°å…·æœ‰æ‰€æœ‰è®°å¿†ä¿¡æ¯çš„æœ€ç»ˆç¨³å®šçŠ¶æ€ã€‚è®°å¿†ä¸æ˜¯é€šè¿‡çŸ¥é“åœ°å€æ¥å®ç°çš„ï¼Œè€Œæ˜¯é€šè¿‡åœ¨åˆå§‹çŠ¶æ€ä¸­æä¾›è®°å¿†çš„ä¸€éƒ¨åˆ†æ¥å®ç°çš„ã€‚ä»»ä½•è¶³å¤Ÿå¤§å°çš„å­éƒ¨åˆ†éƒ½å¯ä»¥â€”â€”è®°å¿†ç¡®å®æ˜¯é€šè¿‡å†…å®¹è€Œä¸æ˜¯ä½ç½®æ¥å¯»å€çš„ã€‚ç»™å®šçš„ $T$ çŸ©é˜µåŒæ—¶åŒ…å«è®¸å¤šè®°å¿†ï¼Œè¿™äº›è®°å¿†å¯ä»¥ä»åˆå§‹çŠ¶æ€ä¸­çš„éƒ¨åˆ†ä¿¡æ¯ä¸­å•ç‹¬é‡å»ºã€‚\nConvergent flow to stable states is the essential feature of this CAM operation. There is a simple mathematical condition which guarantees that the state space flow algorithm converges on stable states. Any symmetric $T$ with zero diagonal elements (i.e., $T_{ij} = T_{ji}$, $T_{ii} = 0$) will produce such a flow. The proof of this property followed from the construction of an appropriate energy function that is always decreased by any state change produced by the algorithm. Consider the function\n$$ E = -\\frac{1}{2}\\sum_{i}\\sum_{j\\neq i}T_{ij}V_{i}V_{j} - \\sum_{i}I_{i}V_{i} + \\sum_{i}U_{i}V_{i} $$\nThe change $\\Delta E$ in $E$ due to changing the state of neuron $i$ by $\\Delta V_{i}$ is\n$$ \\Delta E = -\\left[\\sum_{j\\neq i}T_{ij}V_{j} + I_{i} -U_{i}\\right]\\Delta V_{i}. $$\nBut according to the algorithm,$\\Delta V_{i}$ is positive only when the bracket is positive, and similarly for the negative case. Thus any change in $E$ under the algorithm is negative. $E$ is bounded, so the iteration of the algorithm must lead to stable states that do not further change with time.\nå‘ç¨³å®šçŠ¶æ€çš„æ”¶æ•›æµæ˜¯è¿™ç§ CAM æ“ä½œçš„åŸºæœ¬ç‰¹å¾ã€‚æœ‰ä¸€ä¸ªç®€å•çš„æ•°å­¦æ¡ä»¶å¯ä»¥ä¿è¯çŠ¶æ€ç©ºé—´æµç®—æ³•æ”¶æ•›åˆ°ç¨³å®šçŠ¶æ€ã€‚ä»»ä½•å…·æœ‰é›¶å¯¹è§’çº¿å…ƒç´ çš„å¯¹ç§° $T$ï¼ˆå³ $T_{ij} = T_{ji}$ï¼Œ$T_{ii} = 0$ï¼‰éƒ½ä¼šäº§ç”Ÿè¿™æ ·çš„æµã€‚è¯¥å±æ€§çš„è¯æ˜æ¥è‡ªäºæ„é€ ä¸€ä¸ªé€‚å½“çš„èƒ½é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æ€»æ˜¯é€šè¿‡ç®—æ³•äº§ç”Ÿçš„ä»»ä½•çŠ¶æ€å˜åŒ–è€Œå‡å°‘ã€‚è€ƒè™‘å‡½æ•°\n$$ E = -\\frac{1}{2}\\sum_{i}\\sum_{j\\neq i}T_{ij}V_{i}V_{j} - \\sum_{i}I_{i}V_{i} + \\sum_{i}U_{i}V_{i} $$\nç”±äºé€šè¿‡ $\\Delta V_{i}$ æ”¹å˜ç¥ç»å…ƒ $i$ çš„çŠ¶æ€è€Œå¯¼è‡´çš„ $E$ çš„å˜åŒ– $\\Delta E$ ä¸º\n$$ \\Delta E = -\\left[\\sum_{j\\neq i}T_{ij}V_{j} + I_{i} -U_{i}\\right]\\Delta V_{i}. $$\nä½†æ ¹æ®ç®—æ³•ï¼Œ$\\Delta V_{i}$ ä»…åœ¨æ‹¬å·ä¸ºæ­£æ—¶ä¸ºæ­£ï¼Œè´Ÿæƒ…å†µäº¦ç„¶ã€‚å› æ­¤ï¼Œç®—æ³•ä¸‹çš„ä»»ä½• $E$ å˜åŒ–éƒ½æ˜¯è´Ÿçš„ã€‚$E$ æ˜¯æœ‰ç•Œçš„ï¼Œå› æ­¤ç®—æ³•çš„è¿­ä»£å¿…é¡»å¯¼è‡´ä¸ä¼šéšæ—¶é—´è¿›ä¸€æ­¥å˜åŒ–çš„ç¨³å®šçŠ¶æ€ã€‚\nA Continuous, Deterministic Model We now construct a model that is based on continuous variables and responses but retains all the significant behaviors of the original model. Let the output variable $V_{i}$ for neuron $i$ have the range $V_{i}^{0}\\leq V_{i}\\leq V_{i}^{1}$ and be a continuous and monotone-increasing function of the instantaneous input $u_{i}$ to neuron $i$. The typical input-output relation $g_{i}(u_{i})$ shown in Fig.1a is sigmoid with asymptotes $V_{i}^{0}$ and $V_{i}^{1}$. For neurons exhibiting action potentials, $u_{i}$ could be thought of as the mean soma potential of a neuron from the total effect of its excitatory and inhibitory inputs. $V_{i}$ can be viewed as the short-term average of the firing rate of the cell $i$. Other biological interpretations are possible- for example, nonlinear processing may be done at junctions in a dendritic arbor, and the model â€œneuronsâ€ could represent such junctions. In terms of electrical circuits, $g_{i}(u_{i})$ represents the input-output characteristic of a nonlinear amplifier with negligible response time. It is convenient also to define the inverse output-input relation, $g_{i}^{-1}(V)$.\næˆ‘ä»¬ç°åœ¨æ„å»ºä¸€ä¸ªåŸºäºè¿ç»­å˜é‡å’Œå“åº”çš„æ¨¡å‹ï¼Œä½†ä¿ç•™äº†åŸå§‹æ¨¡å‹çš„æ‰€æœ‰æ˜¾è‘—è¡Œä¸ºã€‚è®©ç¥ç»å…ƒ $i$ çš„è¾“å‡ºå˜é‡ $V_{i}$ å…·æœ‰èŒƒå›´ $V_{i}^{0}\\leq V_{i}\\leq V_{i}^{1}$ï¼Œå¹¶ä¸”æ˜¯ç¥ç»å…ƒ $i$ å¯¹ç¬æ—¶è¾“å…¥ $u_{i}$ çš„è¿ç»­ä¸”å•è°ƒé€’å¢çš„å‡½æ•°ã€‚å›¾ 1a æ‰€ç¤ºçš„å…¸å‹è¾“å…¥-è¾“å‡ºå…³ç³» $g_{i}(u_{i})$ æ˜¯å…·æœ‰æ¸è¿‘çº¿ $V_{i}^{0}$ å’Œ $V_{i}^{1}$ çš„è¥¿æ ¼ç›å‡½æ•°ã€‚å¯¹äºè¡¨ç°å‡ºåŠ¨ä½œç”µä½çš„ç¥ç»å…ƒï¼Œ$u_{i}$ å¯ä»¥è¢«è§†ä¸ºæ¥è‡ªå…¶å…´å¥‹æ€§å’ŒæŠ‘åˆ¶æ€§è¾“å…¥æ€»æ•ˆåº”çš„ç¥ç»å…ƒä½“ç”µä½çš„å¹³å‡å€¼ã€‚$V_{i}$ å¯ä»¥è¢«è§†ä¸ºç»†èƒ $i$ çš„å‘å°„ç‡çš„çŸ­æœŸå¹³å‡å€¼ã€‚å…¶ä»–ç”Ÿç‰©å­¦è§£é‡Šä¹Ÿæ˜¯å¯èƒ½çš„â€”â€”ä¾‹å¦‚ï¼Œéçº¿æ€§å¤„ç†å¯èƒ½åœ¨æ ‘çªåˆ†æ”¯çš„è¿æ¥å¤„è¿›è¡Œï¼Œæ¨¡å‹ â€œç¥ç»å…ƒâ€ å¯ä»¥ä»£è¡¨è¿™æ ·çš„è¿æ¥ã€‚åœ¨ç”µè·¯æ–¹é¢ï¼Œ$g_{i}(u_{i})$ ä»£è¡¨å…·æœ‰å¯å¿½ç•¥å“åº”æ—¶é—´çš„éçº¿æ€§æ”¾å¤§å™¨çš„è¾“å…¥-è¾“å‡ºç‰¹æ€§ã€‚åŒæ ·æ–¹ä¾¿çš„æ˜¯å®šä¹‰é€†è¾“å‡º-è¾“å…¥å…³ç³»ï¼Œ$g_{i}^{-1}(V)$ã€‚\nIn a biological system, $u_{i}$ will lag behind the instantaneous outputs $V_{j}$ of the other cells because of the input capacitance $C$ of the cell membranesâ€™ the transmembrane resistance $R$, and the finite impedance $T_{ij}^{-1}$ between the output $V_{j}$ and the cell body of cell $i$. Thus there is a resistance-capacitance (RC) charging equation that determines the rate of change of $u_{i}$.\n$$ \\begin{equation*} \\begin{aligned} C_{i}(\\mathrm{d}u_{i}/\\mathrm{d}t) \u0026= \\sum_{j}T_{ij}V_{j} - u_{i}/R_{i} + I_{i}\\\\ u_{i} \u0026= g_{i}^{-1}(V_{i}). \\end{aligned} \\end{equation*} $$\n$T_{ij}V_{j}$ represents the electrical current input to cell $i$ due to the present potential of cell $j$, and $T_{ij}$ is thus the synapse efficacy. Linear summing of inputs is assumed. $T_{ij}$ of both signs should occur. $I_{i}$ is any other (fixed) input current to neuron $i$.\nåœ¨ç”Ÿç‰©ç³»ç»Ÿä¸­ï¼Œç”±äºç»†èƒè†œçš„è¾“å…¥ç”µå®¹ $C$ã€è·¨è†œç”µé˜» $R$ ä»¥åŠè¾“å‡º $V_{j}$ å’Œç»†èƒä½“ $i$ ä¹‹é—´çš„æœ‰é™é˜»æŠ— $T_{ij}^{-1}$ï¼Œ$u_{i}$ å°†è½åäºå…¶ä»–ç»†èƒçš„ç¬æ—¶è¾“å‡º $V_{j}$ã€‚å› æ­¤ï¼Œæœ‰ä¸€ä¸ªç”µé˜»-ç”µå®¹ï¼ˆRCï¼‰å……ç”µæ–¹ç¨‹å†³å®šäº† $u_{i}$ çš„å˜åŒ–ç‡ã€‚\n$$ \\begin{equation*} \\begin{aligned} C_{i}(\\mathrm{d}u_{i}/\\mathrm{d}t) \u0026= \\sum_{j}T_{ij}V_{j} - u_{i}/R_{i} + I_{i}\\\\ u_{i} \u0026= g_{i}^{-1}(V_{i}). \\end{aligned} \\end{equation*} $$\n$T_{ij}V_{j}$ ä»£è¡¨ç”±äºç»†èƒ $j$ çš„å½“å‰ç”µä½è€Œå¯¹ç»†èƒ $i$ çš„ç”µæµè¾“å…¥ï¼Œå› æ­¤ $T_{ij}$ æ˜¯çªè§¦æ•ˆèƒ½ã€‚å‡è®¾è¾“å…¥æ˜¯çº¿æ€§æ±‚å’Œçš„ã€‚$T_{ij}$ åº”è¯¥æœ‰ä¸¤ç§ç¬¦å·ã€‚$I_{i}$ æ˜¯å¯¹ç¥ç»å…ƒ $i$ çš„ä»»ä½•å…¶ä»–ï¼ˆå›ºå®šï¼‰è¾“å…¥ç”µæµã€‚\nThe same set of equations represents the resistively connected network of electrical amplifiers sketched in Fig. 2. It appears more complicated than the description of the neural system because the electrical problem of providing inhibition and excitation requires an additional inverting amplifier and a negative signal wire. The magnitude of $T_{ij}$ is $1/R_{ij}$, where $R_{ij}$ is the resistor connecting the output of $j$ to the input line $i$, while the sign of $T_{ij}$ is determined by the choice of the positive or negative output of amplifier $j$ at the connection site. $R_{i}$ is now\n$$ \\frac{1}{R_{i}} = \\frac{1}{\\rho_{i}} + \\sum_{j}\\frac{1}{R_{ij}} $$\nwhere $\\rho_{i}$ is the input resistance of amplifier $i$. $C_{i}$ is the total input capacitance of the amplifier $i$ and its associated input lead. We presume the output impedance of the amplifiers is negligible. These simplifications result in Eq. 5 being appropriate also for the network of Fig. 2.\nåŒä¸€ç»„æ–¹ç¨‹è¡¨ç¤ºå›¾ 2 ä¸­è‰å›¾æ‰€ç¤ºçš„ç”µé˜»è¿æ¥çš„ç”µå­æ”¾å¤§å™¨ç½‘ç»œã€‚å®ƒçœ‹èµ·æ¥æ¯”ç¥ç»ç³»ç»Ÿçš„æè¿°æ›´å¤æ‚ï¼Œå› ä¸ºæä¾›æŠ‘åˆ¶å’Œå…´å¥‹çš„ç”µæ°”é—®é¢˜éœ€è¦ä¸€ä¸ªé¢å¤–çš„åç›¸æ”¾å¤§å™¨å’Œä¸€ä¸ªè´Ÿä¿¡å·çº¿ã€‚$T_{ij}$ çš„å¤§å°æ˜¯ $1/R_{ij}$ï¼Œå…¶ä¸­ $R_{ij}$ æ˜¯å°† $j$ çš„è¾“å‡ºè¿æ¥åˆ°è¾“å…¥çº¿ $i$ çš„ç”µé˜»ï¼Œè€Œ $T_{ij}$ çš„ç¬¦å·ç”±æ”¾å¤§å™¨ $j$ åœ¨è¿æ¥ç‚¹å¤„é€‰æ‹©æ­£è¾“å‡ºæˆ–è´Ÿè¾“å‡ºå†³å®šã€‚$R_{i}$ ç°åœ¨æ˜¯\n$$ \\frac{1}{R_{i}} = \\frac{1}{\\rho_{i}} + \\sum_{j}\\frac{1}{R_{ij}} $$\nå…¶ä¸­ $\\rho_{i}$ æ˜¯æ”¾å¤§å™¨ $i$ çš„è¾“å…¥ç”µé˜»ã€‚$C_{i}$ æ˜¯æ”¾å¤§å™¨ $i$ åŠå…¶ç›¸å…³è¾“å…¥å¼•çº¿çš„æ€»è¾“å…¥ç”µå®¹ã€‚æˆ‘ä»¬å‡è®¾æ”¾å¤§å™¨çš„è¾“å‡ºé˜»æŠ—å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚è¿™äº›ç®€åŒ–ä½¿å¾—æ–¹ç¨‹ 5 ä¹Ÿé€‚ç”¨äºå›¾ 2 çš„ç½‘ç»œã€‚\nAn electrical circuit that corresponds to Eq. 5 when the amplifiers are fast. The input capacitance and resistances are not drawn. A particularly simple special case can have all positive $T_{ij}$ of the same strength and no negative $T_{ij}$ and replaces the array of negative wires with a single negative feedback amplifier sending a common output to each â€œneuron.â€\nå½“æ”¾å¤§å™¨å¿«é€Ÿå·¥ä½œæ—¶ï¼Œä¸å…¬å¼ 5 ç›¸å¯¹åº”çš„ç”µè·¯ã€‚è¾“å…¥ç”µå®¹å’Œç”µé˜»æœªç”»å‡ºã€‚ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„ç‰¹ä¾‹æ˜¯ï¼Œæ‰€æœ‰æ­£å‘ $T_{ij}$ çš„å¼ºåº¦ç›¸åŒï¼Œè€Œæ²¡æœ‰è´Ÿå‘ $T_{ij}$ï¼Œç”¨ä¸€ä¸ªå‘æ¯ä¸ª â€œç¥ç»å…ƒâ€ å‘é€å…±åŒè¾“å‡ºçš„è´Ÿåé¦ˆæ”¾å¤§å™¨æ¥å–ä»£è´Ÿå‘å¯¼çº¿é˜µåˆ—ã€‚\nConsider the quantity\n$$ E = -\\frac{1}{2}\\sum_{i}\\sum_{j}T_{ij}V_{i}V_{j} + \\sum_{i}\\frac{1}{R_{i}}\\int_{0}^{V_{i}}g_{i}^{-1}(V)\\mathrm{d}V + \\sum_{i}I_{i}V_{i} $$\nIts time derivative for a symmetric $T$ is\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} = -\\sum_{i}\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\left(\\sum_{j}T_{ij}V_{j} - \\frac{u_{i}}{R_{i}} + I_{i}\\right). $$\nThe parenthesis is the right-hand side of Eq. 5, so\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} = -\\sum C_{i}\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\frac{\\mathrm{d}u_{i}}{\\mathrm{d}t} = -\\sum C_{i}g_{i}^{-1\\prime}(V_{i})\\left(\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\right)^{2}. $$\nSince $g_{i}^{-1}(V_{i})$ is a monotone increasing function and $C_{i}$ is positive, each term in this sum is nonnegative. Therefore\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} \\leq 0,\\frac{\\mathrm{d}E}{\\mathrm{d}t} = 0\\rightarrow \\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t} = 0\\space\\text{for all}\\space i. $$\nTogether with the boundedness of $E$, Eq. 10 shows that the time evolution of the system is a motion in state space that seeks out minima in $E$ and comes to a stop at such points. $E$ is a Liapunov function for the system.\nè€ƒè™‘é‡\n$$ E = -\\frac{1}{2}\\sum_{i}\\sum_{j}T_{ij}V_{i}V_{j} + \\sum_{i}\\frac{1}{R_{i}}\\int_{0}^{V_{i}}g_{i}^{-1}(V)\\mathrm{d}V + \\sum_{i}I_{i}V_{i} $$\nå¯¹äºå¯¹ç§° $T$ï¼Œå®ƒçš„æ—¶é—´å¯¼æ•°æ˜¯\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} = -\\sum_{i}\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\left(\\sum_{j}T_{ij}V_{j} - \\frac{u_{i}}{R_{i}} + I_{i}\\right). $$\næ‹¬å·å†…æ˜¯æ–¹ç¨‹ 5 çš„å³ä¾§ï¼Œå› æ­¤\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} = -\\sum C_{i}\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\frac{\\mathrm{d}u_{i}}{\\mathrm{d}t} = -\\sum C_{i}g_{i}^{-1\\prime}(V_{i})\\left(\\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t}\\right)^{2}. $$\nç”±äº $g_{i}^{-1}(V_{i})$ æ˜¯å•è°ƒé€’å¢å‡½æ•°ä¸” $C_{i}$ ä¸ºæ­£ï¼Œå› æ­¤è¯¥å’Œä¸­çš„æ¯ä¸€é¡¹éƒ½æ˜¯éè´Ÿçš„ã€‚å› æ­¤\n$$ \\frac{\\mathrm{d}E}{\\mathrm{d}t} \\leq 0,\\frac{\\mathrm{d}E}{\\mathrm{d}t} = 0\\rightarrow \\frac{\\mathrm{d}V_{i}}{\\mathrm{d}t} = 0\\space\\text{for all}\\space i. $$\nç»“åˆ $E$ çš„æœ‰ç•Œæ€§ï¼Œæ–¹ç¨‹ 10 æ˜¾ç¤ºç³»ç»Ÿçš„æ—¶é—´æ¼”åŒ–æ˜¯åœ¨çŠ¶æ€ç©ºé—´ä¸­å¯»æ‰¾ $E$ çš„æå°å€¼å¹¶åœ¨è¿™äº›ç‚¹åœæ­¢çš„è¿åŠ¨ã€‚$E$ æ˜¯ç³»ç»Ÿçš„ Liapunov å‡½æ•°ã€‚\nThis deterministic model has the same flow properties in its continuous space that the stochastic model does in its discrete space. It can therefore be used in CAM or any other computational task for which an energy function is essential. We expect that the qualitative effects of disorganized or organized anti-symmetric parts of $T_{ij}$ should have similar effects on the CAM operation of the newâ€™ and old system. The new computational behaviors (such as learning sequences) that can be produced by antisymmetric contributions to $T_{ij}$ within the stochastic model will also hold for the deterministic continuous model. Anecdotal support for these assertions comes from unpublished work of John Platt (California Institute of Technology) solving Eq. 5 on a computer with some random $T_{ij}$ removed from an otherwise symmetric $T$, and from experimental work of John Lambe (Jet Propulsion Laboratory), David Feinstein (California Institute of Technology), and Platt generating sequences of states by using an antisymmetric part of $T$ in a real circuit of a six â€œneuronsâ€ (personal communications).\nè¯¥ç¡®å®šæ€§æ¨¡å‹åœ¨å…¶è¿ç»­ç©ºé—´ä¸­å…·æœ‰ä¸éšæœºæ¨¡å‹åœ¨å…¶ç¦»æ•£ç©ºé—´ä¸­ç›¸åŒçš„æµåŠ¨ç‰¹æ€§ã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨äº CAM æˆ–ä»»ä½•å…¶ä»–éœ€è¦èƒ½é‡å‡½æ•°çš„è®¡ç®—ä»»åŠ¡ã€‚æˆ‘ä»¬é¢„è®¡ï¼Œ$T_{ij}$ çš„æ— ç»„ç»‡æˆ–æœ‰ç»„ç»‡çš„åå¯¹ç§°éƒ¨åˆ†çš„å®šæ€§æ•ˆåº”åº”è¯¥å¯¹æ–°æ—§ç³»ç»Ÿçš„ CAM æ“ä½œäº§ç”Ÿç±»ä¼¼çš„å½±å“ã€‚é€šè¿‡åœ¨éšæœºæ¨¡å‹ä¸­å¯¹ $T_{ij}$ è¿›è¡Œåå¯¹ç§°è´¡çŒ®æ‰€äº§ç”Ÿçš„æ–°è®¡ç®—è¡Œä¸ºï¼ˆå¦‚å­¦ä¹ åºåˆ—ï¼‰ä¹Ÿé€‚ç”¨äºç¡®å®šæ€§çš„è¿ç»­æ¨¡å‹ã€‚å¯¹è¿™äº›æ–­è¨€çš„è½¶äº‹æ”¯æŒæ¥è‡ª John Plattï¼ˆåŠ å·ç†å·¥å­¦é™¢ï¼‰çš„æœªå‘è¡¨å·¥ä½œï¼Œä»–åœ¨è®¡ç®—æœºä¸Šæ±‚è§£æ–¹ç¨‹ 5ï¼Œå¹¶ä»ä¸€ä¸ªæœ¬æ¥æ˜¯å¯¹ç§°çš„ $T$ ä¸­ç§»é™¤äº†ä¸€äº›éšæœº $T_{ij}$ï¼Œä»¥åŠ John Lambeï¼ˆå–·æ°”æ¨è¿›å®éªŒå®¤ï¼‰ã€David Feinsteinï¼ˆåŠ å·ç†å·¥å­¦é™¢ï¼‰å’Œ Platt çš„å®éªŒå·¥ä½œï¼Œä»–ä»¬é€šè¿‡åœ¨ä¸€ä¸ªç”±å…­ä¸ª â€œç¥ç»å…ƒâ€ ç»„æˆçš„çœŸå®ç”µè·¯ä¸­ä½¿ç”¨ $T$ çš„åå¯¹ç§°éƒ¨åˆ†ç”ŸæˆçŠ¶æ€åºåˆ—ï¼ˆä¸ªäººé€šä¿¡ï¼‰ã€‚\nRelation Between the Stable States of the Two Models For a given $T$, the stable states of the continuous system have a simple correspondence with the stable states of the stochastic system. We will work with a slightly simplified instance of the general equations to put a minimum of mathematics in the way of seeing the correspondence. The same basic idea carries over, with more arithmetic, to the general case.\nå¯¹äºç»™å®šçš„ $T$ï¼Œè¿ç»­ç³»ç»Ÿçš„ç¨³å®šçŠ¶æ€ä¸éšæœºç³»ç»Ÿçš„ç¨³å®šçŠ¶æ€æœ‰ä¸€ä¸ªç®€å•çš„å¯¹åº”å…³ç³»ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€èˆ¬æ–¹ç¨‹çš„ä¸€ä¸ªç¨å¾®ç®€åŒ–çš„å®ä¾‹ï¼Œä»¥å°½é‡å‡å°‘æ•°å­¦æ–¹é¢çš„éšœç¢ï¼Œä»è€Œçœ‹åˆ°è¿™ç§å¯¹åº”å…³ç³»ã€‚ç›¸åŒçš„åŸºæœ¬æ€æƒ³å¯ä»¥é€šè¿‡æ›´å¤šçš„ç®—æœ¯è¿ç®—æ¨å¹¿åˆ°ä¸€èˆ¬æƒ…å†µã€‚\nConsider the case in which $V_{i}^{0}\u003c0",
  "wordCount" : "10725",
  "inLanguage": "zh",
  "image":"https://s2.loli.net/2025/10/12/scPqfCW3HNJn8Kr.png","datePublished": "2025-10-12T00:18:23+08:00",
  "dateModified": "2025-10-12T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "Muartz"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Muatyz.github.io/posts/read/reference/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "æ— å¤„æƒ¹å°˜åŸƒ",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Muatyz.github.io/img/Head32.png"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  CommonHTML: {
  scale: 100
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
  
  
  
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script>

<style>
  code.has-jax {
      font: "LXGW WenKai Screen", sans-serif, Arial;
      scale: 1;
      background: "LXGW WenKai Screen", sans-serif, Arial;
      border: "LXGW WenKai Screen", sans-serif, Arial;
      color: #515151;
  }
</style>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Muatyz.github.io/" accesskey="h" title="è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿— (Alt + H)">
            <img src="https://Muatyz.github.io/img/Head64.png" alt="logo" aria-label="logo"
                 height="35">è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿—</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Muatyz.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Muatyz.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/">ğŸ“• é˜…è¯»</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/reference/">ğŸ“• æ–‡çŒ®</a></div>
            <h1 class="post-title">
                Neurons with graded response have collective computational properties like those of two-state neurons
            </h1>
            <div class="post-description">
                Hopfield model
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-10-12
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>10725å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>22åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Muartz
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://Muatyz.github.io/tags/physics/" style="color: var(--secondary)!important;">Physics</a>
                &nbsp;<a href="https://Muatyz.github.io/tags/numerical-calculation/" style="color: var(--secondary)!important;">Numerical Calculation</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Muatyz.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId: "Admin", 
                                region: "ap-shanghai", 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://s2.loli.net/2025/10/12/scPqfCW3HNJn8Kr.png" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#discussion" aria-label="Discussion">Discussion</a></li>
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#form-of-the-original-model" aria-label="Form of the Original Model">Form of the Original Model</a></li>
                <li>
                    <a href="#a-continuous-deterministic-model" aria-label="A Continuous, Deterministic Model">A Continuous, Deterministic Model</a></li>
                <li>
                    <a href="#relation-between-the-stable-states-of-the-two-models" aria-label="Relation Between the Stable States of the Two Models">Relation Between the Stable States of the Two Models</a></li>
                <li>
                    <a href="#discussion-1" aria-label="Discussion">Discussion</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="discussion">Discussion<a hidden class="anchor" aria-hidden="true" href="#discussion">#</a></h1>
<p><span id="Discussion"></span></p>
<h1 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h1>
<blockquote>
<p>A model for a large network of &ldquo;neurons&rdquo; with a graded response (or sigmoid input-output relation) is studied. This deterministic system has collective properties in very close correspondence with the earlier stochastic model based on McCulloch-Pitts neurons. The content-addressable memory and other emergent collective properties of the original model also are present in the graded response model. The idea that such collective properties are used in biological systems is given added credence by the continued presence of such properties for more nearly biological &ldquo;neurons.&rdquo; Collective analog electrical circuits of the kind described will certainly function. The collective states of the two models have a simple correspondence. The original model will continue to be useful for simulations, because its connection to graded response systems is established. Equations that include the effect of action potentials in the graded response system are also developed.</p>
</blockquote>
<p>æœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªå…·æœ‰åˆ†çº§å“åº”ï¼ˆæˆ–è¥¿æ ¼ç›è¾“å…¥-è¾“å‡ºå…³ç³»ï¼‰çš„å¤§å‹ &ldquo;ç¥ç»å…ƒ&rdquo; ç½‘ç»œæ¨¡å‹ã€‚è¿™ä¸ªç¡®å®šæ€§ç³»ç»Ÿçš„é›†ä½“ç‰¹æ€§ä¸æ—©æœŸåŸºäº McCulloch-Pitts ç¥ç»å…ƒçš„éšæœºæ¨¡å‹éå¸¸æ¥è¿‘ã€‚åŸå§‹æ¨¡å‹çš„å†…å®¹å¯å¯»å€è®°å¿†å’Œå…¶ä»–çªå‘æ€§é›†ä½“ç‰¹æ€§ä¹Ÿå­˜åœ¨äºåˆ†çº§å“åº”æ¨¡å‹ä¸­ã€‚æ›´æ¥è¿‘ç”Ÿç‰© &ldquo;ç¥ç»å…ƒ&rdquo; çš„é›†ä½“ç‰¹æ€§çš„æŒç»­å­˜åœ¨ï¼Œä½¿è¿™ç§é›†ä½“ç‰¹æ€§ç”¨äºç”Ÿç‰©ç³»ç»Ÿçš„è§‚ç‚¹æ›´åŠ å¯ä¿¡ã€‚æ‰€æè¿°çš„é‚£ç§é›†ä½“æ¨¡æ‹Ÿç”µè·¯è‚¯å®šä¼šå‘æŒ¥ä½œç”¨ã€‚ä¸¤ç§æ¨¡å‹çš„é›†ä½“çŠ¶æ€æœ‰ç€ç®€å•çš„å¯¹åº”å…³ç³»ã€‚åŸå§‹æ¨¡å‹å°†ç»§ç»­ç”¨äºæ¨¡æ‹Ÿï¼Œå› ä¸ºå®ƒä¸åˆ†çº§å“åº”ç³»ç»Ÿçš„è”ç³»å·²ç»å»ºç«‹ã€‚æ­¤å¤–ï¼Œè¿˜å»ºç«‹äº†åŒ…æ‹¬åˆ†çº§å“åº”ç³»ç»Ÿä¸­åŠ¨ä½œç”µä½æ•ˆåº”çš„æ–¹ç¨‹ã€‚</p>
<hr>
<blockquote>
<p>Recent papers have explored the ability of a system of highly interconnected &ldquo;neurons&rdquo; to have useful collective computational properties. These properties emerge spontaneously in a system having a large number of elementary &ldquo;neurons.&rdquo; Content-addressable memory (CAM) is one of the simplest collective properties of such a system. The mathematical modeling has been based on &ldquo;neurons&rdquo; that are different both from real biological neurons and from the realistic functioning of simple electronic circuits. Some of these differences are major enough that neurobiologists and circuit engineers alike have questioned whether real neural or electrical circuits would actually exhibit the kind of behaviors found in the model system even if the &ldquo;neurons&rdquo; were connected in the fashion envisioned.</p>
</blockquote>
<p>æœ€è¿‘çš„è®ºæ–‡æ¢è®¨äº†é«˜åº¦äº’è”çš„ &ldquo;ç¥ç»å…ƒ&rdquo; ç³»ç»Ÿå…·æœ‰æœ‰ç”¨çš„é›†ä½“è®¡ç®—ç‰¹æ€§çš„èƒ½åŠ›ã€‚è¿™äº›ç‰¹æ€§åœ¨å…·æœ‰å¤§é‡åŸºæœ¬ &ldquo;ç¥ç»å…ƒ&rdquo; çš„ç³»ç»Ÿä¸­è‡ªå‘å‡ºç°ã€‚å†…å®¹å¯å¯»å€è®°å¿†ï¼ˆCAMï¼‰æ˜¯è¿™ç§ç³»ç»Ÿæœ€ç®€å•çš„é›†ä½“ç‰¹æ€§ä¹‹ä¸€ã€‚æ•°å­¦å»ºæ¨¡åŸºäºçš„ &ldquo;ç¥ç»å…ƒ&rdquo; ä¸çœŸå®çš„ç”Ÿç‰©ç¥ç»å…ƒå’Œç®€å•ç”µå­ç”µè·¯çš„ç°å®åŠŸèƒ½éƒ½ä¸åŒã€‚å…¶ä¸­ä¸€äº›å·®å¼‚è¶³å¤Ÿå¤§ï¼Œä»¥è‡³äºç¥ç»ç”Ÿç‰©å­¦å®¶å’Œç”µè·¯å·¥ç¨‹å¸ˆéƒ½è´¨ç–‘ï¼Œå³ä½¿ &ldquo;ç¥ç»å…ƒ&rdquo; ä»¥è®¾æƒ³çš„æ–¹å¼è¿æ¥ï¼ŒçœŸå®çš„ç¥ç»æˆ–ç”µè·¯æ˜¯å¦çœŸçš„ä¼šè¡¨ç°å‡ºæ¨¡å‹ç³»ç»Ÿä¸­å‘ç°çš„é‚£ç§è¡Œä¸ºã€‚</p>
<blockquote>
<p>Two major divergences between the model and biological or physical systems stand out. Real neurons (and real physical devices such as operational amplifiers that might mimic them) have continuous input-output relations. (Action potentials are omitted until <a href="#Discussion">Discussion</a>.) The original modeling used two-state McCulloch-Pitts (4) threshold devices having outputs of 0 or 1 only. Real neurons and real physical circuits have integrative time delays due to capacitance, and the time evolution of the state of such systems should be represented by a differential equation (perhaps with added noise). The original modeling used a stochastic algorithm involving sudden 0-1 or 1-0 changes of states of neurons at random times. This paper shows that the important properties of the original model remain intact when these two simplifications of the modeling are eliminated. Although it is uncertain whether the properties of these new continuous &ldquo;neurons&rdquo; are yet close enough to the essential properties of real neurons (and/or their dendritic arborization) to be directly applicable to neurobiology, a major conceptual obstacle has been eliminated. It is certain that a CAM constructed on the basic ideas  of the original model (1) but built of operational amplifiers and resistors will function.</p>
</blockquote>
<p>æœ¬æ–‡çªå‡ºäº†æ¨¡å‹ä¸ç”Ÿç‰©æˆ–ç‰©ç†ç³»ç»Ÿä¹‹é—´çš„ä¸¤ä¸ªä¸»è¦å·®å¼‚ã€‚çœŸå®çš„ç¥ç»å…ƒï¼ˆä»¥åŠå¯èƒ½æ¨¡ä»¿å®ƒä»¬çš„è¿ç®—æ”¾å¤§å™¨ç­‰çœŸå®ç‰©ç†è®¾å¤‡ï¼‰å…·æœ‰è¿ç»­çš„è¾“å…¥-è¾“å‡ºå…³ç³»ã€‚ï¼ˆåŠ¨ä½œç”µä½åœ¨ <a href="#Discussion">è®¨è®º</a> ä¹‹å‰è¢«çœç•¥ã€‚ï¼‰åŸå§‹å»ºæ¨¡ä½¿ç”¨äº†åªæœ‰ 0 æˆ– 1 è¾“å‡ºçš„ä¸¤æ€ McCulloch-Pitts (4) é˜ˆå€¼è®¾å¤‡ã€‚çœŸå®çš„ç¥ç»å…ƒå’ŒçœŸå®çš„ç‰©ç†ç”µè·¯ç”±äºç”µå®¹è€Œå…·æœ‰ç§¯åˆ†æ—¶é—´å»¶è¿Ÿï¼Œè¿™ç§ç³»ç»ŸçŠ¶æ€çš„æ—¶é—´æ¼”åŒ–åº”è¯¥ç”±å¾®åˆ†æ–¹ç¨‹ï¼ˆå¯èƒ½åŠ ä¸Šå™ªå£°ï¼‰è¡¨ç¤ºã€‚åŸå§‹å»ºæ¨¡ä½¿ç”¨äº†ä¸€ç§éšæœºç®—æ³•ï¼Œæ¶‰åŠç¥ç»å…ƒçŠ¶æ€åœ¨éšæœºæ—¶é—´çªç„¶ä» 0-1 æˆ– 1-0 çš„å˜åŒ–ã€‚æœ¬æ–‡è¡¨æ˜ï¼Œå½“æ¶ˆé™¤è¿™ä¸¤ç§ç®€åŒ–å»ºæ¨¡æ—¶ï¼ŒåŸå§‹æ¨¡å‹çš„é‡è¦å±æ€§ä»ç„¶ä¿æŒä¸å˜ã€‚å°½ç®¡å°šä¸ç¡®å®šè¿™äº›æ–°çš„è¿ç»­ &ldquo;ç¥ç»å…ƒ&rdquo; çš„å±æ€§æ˜¯å¦è¶³å¤Ÿæ¥è¿‘çœŸå®ç¥ç»å…ƒï¼ˆå’Œ/æˆ–å®ƒä»¬çš„æ ‘çªåˆ†æ”¯ï¼‰çš„åŸºæœ¬å±æ€§ï¼Œä»¥ç›´æ¥åº”ç”¨äºç¥ç»ç”Ÿç‰©å­¦ï¼Œä½†ä¸€ä¸ªä¸»è¦çš„æ¦‚å¿µéšœç¢å·²ç»è¢«æ¶ˆé™¤ã€‚å¯ä»¥è‚¯å®šçš„æ˜¯ï¼ŒåŸºäºåŸå§‹æ¨¡å‹ï¼ˆ1ï¼‰çš„åŸºæœ¬æ€æƒ³æ„å»ºçš„ CAMï¼Œä½†ç”±è¿ç®—æ”¾å¤§å™¨å’Œç”µé˜»å™¨æ„æˆï¼Œå°†ä¼šå‘æŒ¥ä½œç”¨ã€‚</p>
<h1 id="form-of-the-original-model">Form of the Original Model<a hidden class="anchor" aria-hidden="true" href="#form-of-the-original-model">#</a></h1>
<blockquote>
<p>The original model used two-state threshold &ldquo;neurons&rdquo; that followed a stochastic algorithm. Each model neuron $i$ had two states, characterized by the output $V_{i}$ of the neuron having the values $V_{i}^{0}$ or $V_{i}^{1}$ (which may often be taken as 0 and 1, respectively). The input of each neuron came from two sources, external inputs $I_{i}$ and inputs from other neurons. The total input to neuron $i$ is then</p>
<p>$$
\text{Input to}\space i =H_{i} = \sum_{j\neq i}T_{ij}V_{j}+I_{i}
$$</p>
<p>The element $T_{ij}$ can be biologically viewed as a description of the synaptic interconnection strength from neuron $j$ to neuron $i$.</p>
</blockquote>
<p>åŸå§‹æ¨¡å‹ä½¿ç”¨äº†éµå¾ªéšæœºç®—æ³•çš„ä¸¤æ€é˜ˆå€¼ &ldquo;ç¥ç»å…ƒ&rdquo;ã€‚æ¯ä¸ªæ¨¡å‹ç¥ç»å…ƒ $i$ æœ‰ä¸¤ä¸ªçŠ¶æ€ï¼Œå…¶è¾“å‡º $V_{i}$ çš„å€¼åˆ†åˆ«ä¸º $V_{i}^{0}$ æˆ– $V_{i}^{1}$ï¼ˆé€šå¸¸å¯ä»¥åˆ†åˆ«å–ä¸º 0 å’Œ 1ï¼‰ã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥æ¥è‡ªä¸¤ä¸ªæ¥æºï¼Œå¤–éƒ¨è¾“å…¥ $I_{i}$ å’Œæ¥è‡ªå…¶ä»–ç¥ç»å…ƒçš„è¾“å…¥ã€‚ç¥ç»å…ƒ $i$ çš„æ€»è¾“å…¥ä¸º</p>
<p>$$
\text{Input to}\space i =H_{i} = \sum_{j\neq i}T_{ij}V_{j}+I_{i}
$$</p>
<p>å…ƒç´  $T_{ij}$ å¯ä»¥ä»ç”Ÿç‰©å­¦è§’åº¦çœ‹ä½œæ˜¯æè¿°ä»ç¥ç»å…ƒ $j$ åˆ°ç¥ç»å…ƒ $i$ çš„çªè§¦è¿æ¥å¼ºåº¦ã€‚</p>
<blockquote>
<p>CAM and other useful computations in this system involve the change of state of the system with time. The motion of the state of a system of $N$ neurons in state space describes the computation that the set of neurons is performing. A model therefore must describe how the state evolves in time, and the original model describes this in terms of a stochastic evolution. Each neuron samples its input at random times. It changes the value of its output or leaves it fixed according to a threshold rule with thresholds $U_{i}$.</p>
<p>$$
\begin{equation*}
\begin{aligned}
V_{i} &amp;\rightarrow V_{i}^{0}\space\text{if}\space \sum_{j\neq i}T_{ij}V_{j}+I_{i} &lt;U_{i},\\
&amp;\rightarrow V_{i}^{1}\space\text{if}\space \sum_{j\neq i}T_{ij}V_{j}+I_{i} &gt;U_{i}.
\end{aligned}
\end{equation*}
$$</p>
<p>The interrogation of each neuron is a stochastic process, taking place at a mean rate $W$ for each neuron. The times of interrogation of each neuron are independent of the times at which other neurons are interrogated. The algorithm is thus asynchronous, in contrast to the usual kind of processing done with threshold devices. This asynchrony was deliberately introduced to represent a combination of propagation delays, jitter, and noise in real neural systems. Synchronous systems might have additional collective properties.</p>
</blockquote>
<p>CAM å’Œè¯¥ç³»ç»Ÿä¸­çš„å…¶ä»–æœ‰ç”¨è®¡ç®—æ¶‰åŠç³»ç»ŸçŠ¶æ€éšæ—¶é—´çš„å˜åŒ–ã€‚$N$ ä¸ªç¥ç»å…ƒç³»ç»ŸçŠ¶æ€ç©ºé—´ä¸­çŠ¶æ€çš„è¿åŠ¨æè¿°äº†ç¥ç»å…ƒé›†åˆæ­£åœ¨æ‰§è¡Œçš„è®¡ç®—ã€‚å› æ­¤ï¼Œæ¨¡å‹å¿…é¡»æè¿°çŠ¶æ€å¦‚ä½•éšæ—¶é—´æ¼”å˜ï¼ŒåŸå§‹æ¨¡å‹é€šè¿‡éšæœºæ¼”åŒ–æ¥æè¿°è¿™ä¸€ç‚¹ã€‚æ¯ä¸ªç¥ç»å…ƒåœ¨éšæœºæ—¶é—´é‡‡æ ·å…¶è¾“å…¥ã€‚å®ƒæ ¹æ®é˜ˆå€¼è§„åˆ™å’Œé˜ˆå€¼ $U_{i}$ æ”¹å˜å…¶è¾“å‡ºå€¼æˆ–ä¿æŒä¸å˜ã€‚</p>
<p>$$
\begin{equation*}
\begin{aligned}
V_{i} &amp;\rightarrow V_{i}^{0}\space\text{if}\space \sum_{j\neq i}T_{ij}V_{j}+I_{i} &lt;U_{i},\\
&amp;\rightarrow V_{i}^{1}\space\text{if}\space \sum_{j\neq i}T_{ij}V_{j}+I_{i} &gt;U_{i}.
\end{aligned}
\end{equation*}
$$</p>
<p>æ¯ä¸ªç¥ç»å…ƒçš„è¯¢é—®æ˜¯ä¸€ä¸ªéšæœºè¿‡ç¨‹ï¼Œæ¯ä¸ªç¥ç»å…ƒä»¥å¹³å‡é€Ÿç‡ $W$ è¿›è¡Œã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¯¢é—®æ—¶é—´ä¸å…¶ä»–ç¥ç»å…ƒçš„è¯¢é—®æ—¶é—´ç›¸äº’ç‹¬ç«‹ã€‚å› æ­¤ï¼Œè¯¥ç®—æ³•æ˜¯å¼‚æ­¥çš„ï¼Œè¿™ä¸ä½¿ç”¨é˜ˆå€¼è®¾å¤‡è¿›è¡Œçš„é€šå¸¸å¤„ç†æ–¹å¼å½¢æˆå¯¹æ¯”ã€‚è¿™ç§å¼‚æ­¥æ€§æ˜¯ä¸ºäº†è¡¨ç¤ºçœŸå®ç¥ç»ç³»ç»Ÿä¸­çš„ä¼ æ’­å»¶è¿Ÿã€æŠ–åŠ¨å’Œå™ªå£°çš„ç»„åˆè€Œæ•…æ„å¼•å…¥çš„ã€‚åŒæ­¥ç³»ç»Ÿå¯èƒ½å…·æœ‰é¢å¤–çš„é›†ä½“ç‰¹æ€§ã€‚</p>
<blockquote>
<p>The original model behaves as an associative memory (or CAM) when the state space flow generated by the algorithm is characterized by a set of stable fixed points. If these stable points describe a simple flow in which nearby points in state space tend to remain close during the flow (i.e., a nonmixing flow), then initial states that are close (in Hamming distance) to a particular stable state and far from all others will tend to terminate in that nearby stable state.</p>
</blockquote>
<p>å½“ç®—æ³•ç”Ÿæˆçš„çŠ¶æ€ç©ºé—´æµä»¥ä¸€ç»„ç¨³å®šçš„å›ºå®šç‚¹ä¸ºç‰¹å¾æ—¶ï¼ŒåŸå§‹æ¨¡å‹è¡¨ç°ä¸ºè”æƒ³è®°å¿†ï¼ˆæˆ– CAMï¼‰ã€‚å¦‚æœè¿™äº›ç¨³å®šç‚¹æè¿°äº†ä¸€ä¸ªç®€å•çš„æµï¼Œå…¶ä¸­çŠ¶æ€ç©ºé—´ä¸­ç›¸é‚»çš„ç‚¹åœ¨æµåŠ¨è¿‡ç¨‹ä¸­å€¾å‘äºä¿æŒæ¥è¿‘ï¼ˆå³éæ··åˆæµï¼‰ï¼Œé‚£ä¹ˆä¸ç‰¹å®šç¨³å®šçŠ¶æ€æ¥è¿‘ï¼ˆåœ¨Hamming è·ç¦»ä¸Šï¼‰ä¸”è¿œç¦»æ‰€æœ‰å…¶ä»–çŠ¶æ€çš„åˆå§‹çŠ¶æ€å°†å€¾å‘äºç»ˆæ­¢åœ¨é‚£ä¸ªé™„è¿‘çš„ç¨³å®šçŠ¶æ€ä¸­ã€‚</p>
<blockquote>
<p>If the location of a particular stable point in state space is thought of as the information of a particular memory of the system, states near to that particular stable point contain partial information about&rsquo; that memory. From an initial state of partial information about a memory, a final stable state with all the information of the memory is found. The memory is reached not by knowing an address, but rather by supplying in the initial state some subpart of the memory. Any subpart of adequate size will do-the memory is truly addressable by content rather than location. A given $T$ matrix contains many memories simultaneously, which are reconstructed individually from partial information in an initial state.</p>
</blockquote>
<p>å¦‚æœå°†çŠ¶æ€ç©ºé—´ä¸­ç‰¹å®šç¨³å®šç‚¹çš„ä½ç½®è§†ä¸ºç³»ç»Ÿç‰¹å®šè®°å¿†çš„ä¿¡æ¯ï¼Œé‚£ä¹ˆæ¥è¿‘è¯¥ç‰¹å®šç¨³å®šç‚¹çš„çŠ¶æ€åŒ…å«æœ‰å…³è¯¥è®°å¿†çš„éƒ¨åˆ†ä¿¡æ¯ã€‚ä»å…³äºè®°å¿†çš„éƒ¨åˆ†ä¿¡æ¯çš„åˆå§‹çŠ¶æ€ï¼Œå¯ä»¥æ‰¾åˆ°å…·æœ‰æ‰€æœ‰è®°å¿†ä¿¡æ¯çš„æœ€ç»ˆç¨³å®šçŠ¶æ€ã€‚è®°å¿†ä¸æ˜¯é€šè¿‡çŸ¥é“åœ°å€æ¥å®ç°çš„ï¼Œè€Œæ˜¯é€šè¿‡åœ¨åˆå§‹çŠ¶æ€ä¸­æä¾›è®°å¿†çš„ä¸€éƒ¨åˆ†æ¥å®ç°çš„ã€‚ä»»ä½•è¶³å¤Ÿå¤§å°çš„å­éƒ¨åˆ†éƒ½å¯ä»¥â€”â€”è®°å¿†ç¡®å®æ˜¯é€šè¿‡å†…å®¹è€Œä¸æ˜¯ä½ç½®æ¥å¯»å€çš„ã€‚ç»™å®šçš„ $T$ çŸ©é˜µåŒæ—¶åŒ…å«è®¸å¤šè®°å¿†ï¼Œè¿™äº›è®°å¿†å¯ä»¥ä»åˆå§‹çŠ¶æ€ä¸­çš„éƒ¨åˆ†ä¿¡æ¯ä¸­å•ç‹¬é‡å»ºã€‚</p>
<blockquote>
<p>Convergent flow to stable states is the essential feature of this CAM operation. There is a simple mathematical condition which guarantees that the state space flow algorithm converges on stable states. Any symmetric $T$ with zero diagonal elements (i.e., $T_{ij} = T_{ji}$, $T_{ii} = 0$) will produce such a flow. The proof of this property followed from the construction of an appropriate energy function that is always decreased by any state change produced by the algorithm. Consider the function</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j\neq i}T_{ij}V_{i}V_{j} - \sum_{i}I_{i}V_{i} + \sum_{i}U_{i}V_{i}
$$</p>
<p>The change $\Delta E$ in $E$ due to changing the state of neuron $i$ by $\Delta V_{i}$ is</p>
<p>$$
\Delta E = -\left[\sum_{j\neq i}T_{ij}V_{j} + I_{i} -U_{i}\right]\Delta V_{i}.
$$</p>
<p>But according to the algorithm,$\Delta V_{i}$ is positive only when the bracket is positive, and similarly for the negative case. Thus any change in $E$ under the algorithm is negative. $E$ is bounded, so the iteration of the algorithm must lead to stable states that do not further change with time.</p>
</blockquote>
<p>å‘ç¨³å®šçŠ¶æ€çš„æ”¶æ•›æµæ˜¯è¿™ç§ CAM æ“ä½œçš„åŸºæœ¬ç‰¹å¾ã€‚æœ‰ä¸€ä¸ªç®€å•çš„æ•°å­¦æ¡ä»¶å¯ä»¥ä¿è¯çŠ¶æ€ç©ºé—´æµç®—æ³•æ”¶æ•›åˆ°ç¨³å®šçŠ¶æ€ã€‚ä»»ä½•å…·æœ‰é›¶å¯¹è§’çº¿å…ƒç´ çš„å¯¹ç§° $T$ï¼ˆå³ $T_{ij} = T_{ji}$ï¼Œ$T_{ii} = 0$ï¼‰éƒ½ä¼šäº§ç”Ÿè¿™æ ·çš„æµã€‚è¯¥å±æ€§çš„è¯æ˜æ¥è‡ªäºæ„é€ ä¸€ä¸ªé€‚å½“çš„èƒ½é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æ€»æ˜¯é€šè¿‡ç®—æ³•äº§ç”Ÿçš„ä»»ä½•çŠ¶æ€å˜åŒ–è€Œå‡å°‘ã€‚è€ƒè™‘å‡½æ•°</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j\neq i}T_{ij}V_{i}V_{j} - \sum_{i}I_{i}V_{i} + \sum_{i}U_{i}V_{i}
$$</p>
<p>ç”±äºé€šè¿‡ $\Delta V_{i}$ æ”¹å˜ç¥ç»å…ƒ $i$ çš„çŠ¶æ€è€Œå¯¼è‡´çš„ $E$ çš„å˜åŒ– $\Delta E$ ä¸º</p>
<p>$$
\Delta E = -\left[\sum_{j\neq i}T_{ij}V_{j} + I_{i} -U_{i}\right]\Delta V_{i}.
$$</p>
<p>ä½†æ ¹æ®ç®—æ³•ï¼Œ$\Delta V_{i}$ ä»…åœ¨æ‹¬å·ä¸ºæ­£æ—¶ä¸ºæ­£ï¼Œè´Ÿæƒ…å†µäº¦ç„¶ã€‚å› æ­¤ï¼Œç®—æ³•ä¸‹çš„ä»»ä½• $E$ å˜åŒ–éƒ½æ˜¯è´Ÿçš„ã€‚$E$ æ˜¯æœ‰ç•Œçš„ï¼Œå› æ­¤ç®—æ³•çš„è¿­ä»£å¿…é¡»å¯¼è‡´ä¸ä¼šéšæ—¶é—´è¿›ä¸€æ­¥å˜åŒ–çš„ç¨³å®šçŠ¶æ€ã€‚</p>
<h1 id="a-continuous-deterministic-model">A Continuous, Deterministic Model<a hidden class="anchor" aria-hidden="true" href="#a-continuous-deterministic-model">#</a></h1>
<blockquote>
<p>We now construct a model that is based on continuous variables and responses but retains all the significant behaviors of the original model. Let the output variable $V_{i}$ for neuron $i$ have the range $V_{i}^{0}\leq V_{i}\leq V_{i}^{1}$ and be a continuous and monotone-increasing function of the instantaneous input $u_{i}$ to neuron $i$. The typical input-output relation $g_{i}(u_{i})$ shown in Fig.1a is sigmoid with asymptotes $V_{i}^{0}$ and $V_{i}^{1}$. For neurons exhibiting action potentials, $u_{i}$ could be thought of as the mean soma potential of a neuron from the total effect of its excitatory and inhibitory inputs. $V_{i}$ can be viewed as the short-term average of the firing rate of the cell $i$. Other biological interpretations are possible- for example, nonlinear processing may be done at junctions in a dendritic arbor, and the model &ldquo;neurons&rdquo; could represent such junctions. In terms of electrical circuits, $g_{i}(u_{i})$ represents the input-output  characteristic of a nonlinear amplifier with negligible response time. It is convenient also to define the inverse output-input relation, $g_{i}^{-1}(V)$.</p>
</blockquote>
<p>æˆ‘ä»¬ç°åœ¨æ„å»ºä¸€ä¸ªåŸºäºè¿ç»­å˜é‡å’Œå“åº”çš„æ¨¡å‹ï¼Œä½†ä¿ç•™äº†åŸå§‹æ¨¡å‹çš„æ‰€æœ‰æ˜¾è‘—è¡Œä¸ºã€‚è®©ç¥ç»å…ƒ $i$ çš„è¾“å‡ºå˜é‡ $V_{i}$ å…·æœ‰èŒƒå›´ $V_{i}^{0}\leq V_{i}\leq V_{i}^{1}$ï¼Œå¹¶ä¸”æ˜¯ç¥ç»å…ƒ $i$ å¯¹ç¬æ—¶è¾“å…¥ $u_{i}$ çš„è¿ç»­ä¸”å•è°ƒé€’å¢çš„å‡½æ•°ã€‚å›¾ 1a æ‰€ç¤ºçš„å…¸å‹è¾“å…¥-è¾“å‡ºå…³ç³» $g_{i}(u_{i})$ æ˜¯å…·æœ‰æ¸è¿‘çº¿ $V_{i}^{0}$ å’Œ $V_{i}^{1}$ çš„è¥¿æ ¼ç›å‡½æ•°ã€‚å¯¹äºè¡¨ç°å‡ºåŠ¨ä½œç”µä½çš„ç¥ç»å…ƒï¼Œ$u_{i}$ å¯ä»¥è¢«è§†ä¸ºæ¥è‡ªå…¶å…´å¥‹æ€§å’ŒæŠ‘åˆ¶æ€§è¾“å…¥æ€»æ•ˆåº”çš„ç¥ç»å…ƒä½“ç”µä½çš„å¹³å‡å€¼ã€‚$V_{i}$ å¯ä»¥è¢«è§†ä¸ºç»†èƒ $i$ çš„å‘å°„ç‡çš„çŸ­æœŸå¹³å‡å€¼ã€‚å…¶ä»–ç”Ÿç‰©å­¦è§£é‡Šä¹Ÿæ˜¯å¯èƒ½çš„â€”â€”ä¾‹å¦‚ï¼Œéçº¿æ€§å¤„ç†å¯èƒ½åœ¨æ ‘çªåˆ†æ”¯çš„è¿æ¥å¤„è¿›è¡Œï¼Œæ¨¡å‹ &ldquo;ç¥ç»å…ƒ&rdquo; å¯ä»¥ä»£è¡¨è¿™æ ·çš„è¿æ¥ã€‚åœ¨ç”µè·¯æ–¹é¢ï¼Œ$g_{i}(u_{i})$ ä»£è¡¨å…·æœ‰å¯å¿½ç•¥å“åº”æ—¶é—´çš„éçº¿æ€§æ”¾å¤§å™¨çš„è¾“å…¥-è¾“å‡ºç‰¹æ€§ã€‚åŒæ ·æ–¹ä¾¿çš„æ˜¯å®šä¹‰é€†è¾“å‡º-è¾“å…¥å…³ç³»ï¼Œ$g_{i}^{-1}(V)$ã€‚</p>
<blockquote>
<p>In a biological system, $u_{i}$ will lag behind the instantaneous  outputs $V_{j}$ of the other cells because of the input capacitance $C$ of the cell membranes&rsquo; the transmembrane resistance $R$, and the finite impedance $T_{ij}^{-1}$ between the output $V_{j}$ and the cell body of cell $i$. Thus there is a resistance-capacitance (RC) charging equation that determines the rate of change of $u_{i}$.</p>
<p>$$
\begin{equation*}
\begin{aligned}
C_{i}(\mathrm{d}u_{i}/\mathrm{d}t) &amp;= \sum_{j}T_{ij}V_{j} - u_{i}/R_{i} + I_{i}\\
u_{i} &amp;= g_{i}^{-1}(V_{i}).
\end{aligned}
\end{equation*}
$$</p>
<p>$T_{ij}V_{j}$ represents the electrical current input to cell $i$ due to the present potential of cell $j$, and $T_{ij}$ is thus the synapse efficacy. Linear summing of inputs is assumed. $T_{ij}$ of both signs should occur. $I_{i}$ is any other (fixed) input current to neuron $i$.</p>
</blockquote>
<p>åœ¨ç”Ÿç‰©ç³»ç»Ÿä¸­ï¼Œç”±äºç»†èƒè†œçš„è¾“å…¥ç”µå®¹ $C$ã€è·¨è†œç”µé˜» $R$ ä»¥åŠè¾“å‡º $V_{j}$ å’Œç»†èƒä½“ $i$ ä¹‹é—´çš„æœ‰é™é˜»æŠ— $T_{ij}^{-1}$ï¼Œ$u_{i}$ å°†è½åäºå…¶ä»–ç»†èƒçš„ç¬æ—¶è¾“å‡º $V_{j}$ã€‚å› æ­¤ï¼Œæœ‰ä¸€ä¸ªç”µé˜»-ç”µå®¹ï¼ˆRCï¼‰å……ç”µæ–¹ç¨‹å†³å®šäº† $u_{i}$ çš„å˜åŒ–ç‡ã€‚</p>
<p>$$
\begin{equation*}
\begin{aligned}
C_{i}(\mathrm{d}u_{i}/\mathrm{d}t) &amp;= \sum_{j}T_{ij}V_{j} - u_{i}/R_{i} + I_{i}\\
u_{i} &amp;= g_{i}^{-1}(V_{i}).
\end{aligned}
\end{equation*}
$$</p>
<p>$T_{ij}V_{j}$ ä»£è¡¨ç”±äºç»†èƒ $j$ çš„å½“å‰ç”µä½è€Œå¯¹ç»†èƒ $i$ çš„ç”µæµè¾“å…¥ï¼Œå› æ­¤ $T_{ij}$ æ˜¯çªè§¦æ•ˆèƒ½ã€‚å‡è®¾è¾“å…¥æ˜¯çº¿æ€§æ±‚å’Œçš„ã€‚$T_{ij}$ åº”è¯¥æœ‰ä¸¤ç§ç¬¦å·ã€‚$I_{i}$ æ˜¯å¯¹ç¥ç»å…ƒ $i$ çš„ä»»ä½•å…¶ä»–ï¼ˆå›ºå®šï¼‰è¾“å…¥ç”µæµã€‚</p>
<blockquote>
<p>The same set of equations represents the resistively connected network of electrical amplifiers sketched in Fig. 2. It appears more complicated than the description of the neural system because the electrical problem of providing inhibition and excitation requires an additional inverting amplifier and a negative signal wire. The magnitude of $T_{ij}$ is $1/R_{ij}$, where $R_{ij}$ is the resistor connecting the output of $j$ to the input line $i$,  while the sign of $T_{ij}$ is determined by the choice of the positive or negative output of amplifier $j$ at the connection site. $R_{i}$ is now</p>
<p>$$
\frac{1}{R_{i}} = \frac{1}{\rho_{i}} + \sum_{j}\frac{1}{R_{ij}}
$$</p>
<p>where $\rho_{i}$ is the input resistance of amplifier $i$. $C_{i}$ is the total input capacitance of the amplifier $i$ and its associated input lead. We presume the output impedance of the amplifiers is negligible. These simplifications result in Eq. 5 being appropriate also for the network of Fig. 2.</p>
</blockquote>
<p>åŒä¸€ç»„æ–¹ç¨‹è¡¨ç¤ºå›¾ 2 ä¸­è‰å›¾æ‰€ç¤ºçš„ç”µé˜»è¿æ¥çš„ç”µå­æ”¾å¤§å™¨ç½‘ç»œã€‚å®ƒçœ‹èµ·æ¥æ¯”ç¥ç»ç³»ç»Ÿçš„æè¿°æ›´å¤æ‚ï¼Œå› ä¸ºæä¾›æŠ‘åˆ¶å’Œå…´å¥‹çš„ç”µæ°”é—®é¢˜éœ€è¦ä¸€ä¸ªé¢å¤–çš„åç›¸æ”¾å¤§å™¨å’Œä¸€ä¸ªè´Ÿä¿¡å·çº¿ã€‚$T_{ij}$ çš„å¤§å°æ˜¯ $1/R_{ij}$ï¼Œå…¶ä¸­ $R_{ij}$ æ˜¯å°† $j$ çš„è¾“å‡ºè¿æ¥åˆ°è¾“å…¥çº¿ $i$ çš„ç”µé˜»ï¼Œè€Œ $T_{ij}$ çš„ç¬¦å·ç”±æ”¾å¤§å™¨ $j$ åœ¨è¿æ¥ç‚¹å¤„é€‰æ‹©æ­£è¾“å‡ºæˆ–è´Ÿè¾“å‡ºå†³å®šã€‚$R_{i}$ ç°åœ¨æ˜¯</p>
<p>$$
\frac{1}{R_{i}} = \frac{1}{\rho_{i}} + \sum_{j}\frac{1}{R_{ij}}
$$</p>
<p>å…¶ä¸­ $\rho_{i}$ æ˜¯æ”¾å¤§å™¨ $i$ çš„è¾“å…¥ç”µé˜»ã€‚$C_{i}$ æ˜¯æ”¾å¤§å™¨ $i$ åŠå…¶ç›¸å…³è¾“å…¥å¼•çº¿çš„æ€»è¾“å…¥ç”µå®¹ã€‚æˆ‘ä»¬å‡è®¾æ”¾å¤§å™¨çš„è¾“å‡ºé˜»æŠ—å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚è¿™äº›ç®€åŒ–ä½¿å¾—æ–¹ç¨‹ 5 ä¹Ÿé€‚ç”¨äºå›¾ 2 çš„ç½‘ç»œã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/Ah93w5Oqr8EZNP1.png" alt=""  /></p>
<p>An electrical circuit that corresponds to Eq. 5 when the amplifiers are fast. The input capacitance and resistances are not  drawn. A particularly simple special case can have all positive $T_{ij}$ of the same strength and no negative $T_{ij}$ and replaces the array of negative wires with a single negative feedback amplifier sending a common output to each &ldquo;neuron.&rdquo;</p>
</blockquote>
<p>å½“æ”¾å¤§å™¨å¿«é€Ÿå·¥ä½œæ—¶ï¼Œä¸å…¬å¼ 5 ç›¸å¯¹åº”çš„ç”µè·¯ã€‚è¾“å…¥ç”µå®¹å’Œç”µé˜»æœªç”»å‡ºã€‚ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„ç‰¹ä¾‹æ˜¯ï¼Œæ‰€æœ‰æ­£å‘ $T_{ij}$ çš„å¼ºåº¦ç›¸åŒï¼Œè€Œæ²¡æœ‰è´Ÿå‘ $T_{ij}$ï¼Œç”¨ä¸€ä¸ªå‘æ¯ä¸ª &ldquo;ç¥ç»å…ƒ&rdquo; å‘é€å…±åŒè¾“å‡ºçš„è´Ÿåé¦ˆæ”¾å¤§å™¨æ¥å–ä»£è´Ÿå‘å¯¼çº¿é˜µåˆ—ã€‚</p>
</blockquote>
<blockquote>
<p>Consider the quantity</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j}T_{ij}V_{i}V_{j} + \sum_{i}\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V + \sum_{i}I_{i}V_{i}
$$</p>
<p>Its time derivative for a symmetric $T$ is</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} = -\sum_{i}\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\left(\sum_{j}T_{ij}V_{j} - \frac{u_{i}}{R_{i}} + I_{i}\right).
$$</p>
<p>The parenthesis is the right-hand side of Eq. 5, so</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} = -\sum C_{i}\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\frac{\mathrm{d}u_{i}}{\mathrm{d}t} = -\sum C_{i}g_{i}^{-1\prime}(V_{i})\left(\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\right)^{2}.
$$</p>
<p>Since $g_{i}^{-1}(V_{i})$ is a monotone increasing function and $C_{i}$ is positive, each term in this sum is nonnegative. Therefore</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} \leq 0,\frac{\mathrm{d}E}{\mathrm{d}t} = 0\rightarrow \frac{\mathrm{d}V_{i}}{\mathrm{d}t} = 0\space\text{for all}\space i.
$$</p>
<p>Together with the boundedness of $E$, Eq. 10 shows that the time evolution of the system is a motion in state space that seeks out minima in $E$ and comes to a stop at such points. $E$ is a Liapunov function for the system.</p>
</blockquote>
<p>è€ƒè™‘é‡</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j}T_{ij}V_{i}V_{j} + \sum_{i}\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V + \sum_{i}I_{i}V_{i}
$$</p>
<p>å¯¹äºå¯¹ç§° $T$ï¼Œå®ƒçš„æ—¶é—´å¯¼æ•°æ˜¯</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} = -\sum_{i}\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\left(\sum_{j}T_{ij}V_{j} - \frac{u_{i}}{R_{i}} + I_{i}\right).
$$</p>
<p>æ‹¬å·å†…æ˜¯æ–¹ç¨‹ 5 çš„å³ä¾§ï¼Œå› æ­¤</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} = -\sum C_{i}\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\frac{\mathrm{d}u_{i}}{\mathrm{d}t} = -\sum C_{i}g_{i}^{-1\prime}(V_{i})\left(\frac{\mathrm{d}V_{i}}{\mathrm{d}t}\right)^{2}.
$$</p>
<p>ç”±äº $g_{i}^{-1}(V_{i})$ æ˜¯å•è°ƒé€’å¢å‡½æ•°ä¸” $C_{i}$ ä¸ºæ­£ï¼Œå› æ­¤è¯¥å’Œä¸­çš„æ¯ä¸€é¡¹éƒ½æ˜¯éè´Ÿçš„ã€‚å› æ­¤</p>
<p>$$
\frac{\mathrm{d}E}{\mathrm{d}t} \leq 0,\frac{\mathrm{d}E}{\mathrm{d}t} = 0\rightarrow \frac{\mathrm{d}V_{i}}{\mathrm{d}t} = 0\space\text{for all}\space i.
$$</p>
<p>ç»“åˆ $E$ çš„æœ‰ç•Œæ€§ï¼Œæ–¹ç¨‹ 10 æ˜¾ç¤ºç³»ç»Ÿçš„æ—¶é—´æ¼”åŒ–æ˜¯åœ¨çŠ¶æ€ç©ºé—´ä¸­å¯»æ‰¾ $E$ çš„æå°å€¼å¹¶åœ¨è¿™äº›ç‚¹åœæ­¢çš„è¿åŠ¨ã€‚$E$ æ˜¯ç³»ç»Ÿçš„ Liapunov å‡½æ•°ã€‚</p>
<blockquote>
<p>This deterministic model has the same flow properties in its continuous space that the stochastic model does in its discrete space. It can therefore be used in CAM or any other computational task for which an energy function is essential. We expect that the qualitative effects of disorganized or  organized anti-symmetric parts of $T_{ij}$ should have similar effects on the CAM operation of the new&rsquo; and old system. The  new computational behaviors (such as learning sequences)  that can be produced by antisymmetric contributions to $T_{ij}$ within the stochastic model will also hold for the deterministic continuous model. Anecdotal support for these assertions comes from unpublished work of John Platt (California Institute of Technology) solving Eq. 5 on a computer with some  random $T_{ij}$ removed from an otherwise symmetric $T$, and from experimental work of John Lambe (Jet Propulsion Laboratory), David Feinstein (California Institute of Technology), and Platt generating sequences of states by using an antisymmetric part of $T$ in a real circuit of a six &ldquo;neurons&rdquo; (personal communications).</p>
</blockquote>
<p>è¯¥ç¡®å®šæ€§æ¨¡å‹åœ¨å…¶è¿ç»­ç©ºé—´ä¸­å…·æœ‰ä¸éšæœºæ¨¡å‹åœ¨å…¶ç¦»æ•£ç©ºé—´ä¸­ç›¸åŒçš„æµåŠ¨ç‰¹æ€§ã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨äº CAM æˆ–ä»»ä½•å…¶ä»–éœ€è¦èƒ½é‡å‡½æ•°çš„è®¡ç®—ä»»åŠ¡ã€‚æˆ‘ä»¬é¢„è®¡ï¼Œ$T_{ij}$ çš„æ— ç»„ç»‡æˆ–æœ‰ç»„ç»‡çš„åå¯¹ç§°éƒ¨åˆ†çš„å®šæ€§æ•ˆåº”åº”è¯¥å¯¹æ–°æ—§ç³»ç»Ÿçš„ CAM æ“ä½œäº§ç”Ÿç±»ä¼¼çš„å½±å“ã€‚é€šè¿‡åœ¨éšæœºæ¨¡å‹ä¸­å¯¹ $T_{ij}$ è¿›è¡Œåå¯¹ç§°è´¡çŒ®æ‰€äº§ç”Ÿçš„æ–°è®¡ç®—è¡Œä¸ºï¼ˆå¦‚å­¦ä¹ åºåˆ—ï¼‰ä¹Ÿé€‚ç”¨äºç¡®å®šæ€§çš„è¿ç»­æ¨¡å‹ã€‚å¯¹è¿™äº›æ–­è¨€çš„è½¶äº‹æ”¯æŒæ¥è‡ª John Plattï¼ˆåŠ å·ç†å·¥å­¦é™¢ï¼‰çš„æœªå‘è¡¨å·¥ä½œï¼Œä»–åœ¨è®¡ç®—æœºä¸Šæ±‚è§£æ–¹ç¨‹ 5ï¼Œå¹¶ä»ä¸€ä¸ªæœ¬æ¥æ˜¯å¯¹ç§°çš„ $T$ ä¸­ç§»é™¤äº†ä¸€äº›éšæœº $T_{ij}$ï¼Œä»¥åŠ John Lambeï¼ˆå–·æ°”æ¨è¿›å®éªŒå®¤ï¼‰ã€David Feinsteinï¼ˆåŠ å·ç†å·¥å­¦é™¢ï¼‰å’Œ Platt çš„å®éªŒå·¥ä½œï¼Œä»–ä»¬é€šè¿‡åœ¨ä¸€ä¸ªç”±å…­ä¸ª &ldquo;ç¥ç»å…ƒ&rdquo; ç»„æˆçš„çœŸå®ç”µè·¯ä¸­ä½¿ç”¨ $T$ çš„åå¯¹ç§°éƒ¨åˆ†ç”ŸæˆçŠ¶æ€åºåˆ—ï¼ˆä¸ªäººé€šä¿¡ï¼‰ã€‚</p>
<h1 id="relation-between-the-stable-states-of-the-two-models">Relation Between the Stable States of the Two Models<a hidden class="anchor" aria-hidden="true" href="#relation-between-the-stable-states-of-the-two-models">#</a></h1>
<blockquote>
<p>For a given $T$, the stable states of the continuous system have a simple correspondence with the stable states of the stochastic system. We will work with a slightly simplified instance of the general equations to put a minimum of mathematics in the way of seeing the correspondence. The same basic idea carries over, with more arithmetic, to the general case.</p>
</blockquote>
<p>å¯¹äºç»™å®šçš„ $T$ï¼Œè¿ç»­ç³»ç»Ÿçš„ç¨³å®šçŠ¶æ€ä¸éšæœºç³»ç»Ÿçš„ç¨³å®šçŠ¶æ€æœ‰ä¸€ä¸ªç®€å•çš„å¯¹åº”å…³ç³»ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€èˆ¬æ–¹ç¨‹çš„ä¸€ä¸ªç¨å¾®ç®€åŒ–çš„å®ä¾‹ï¼Œä»¥å°½é‡å‡å°‘æ•°å­¦æ–¹é¢çš„éšœç¢ï¼Œä»è€Œçœ‹åˆ°è¿™ç§å¯¹åº”å…³ç³»ã€‚ç›¸åŒçš„åŸºæœ¬æ€æƒ³å¯ä»¥é€šè¿‡æ›´å¤šçš„ç®—æœ¯è¿ç®—æ¨å¹¿åˆ°ä¸€èˆ¬æƒ…å†µã€‚</p>
<blockquote>
<p>Consider the case in which $V_{i}^{0}&lt;0&lt;V_{i}^{1}$ for all $i$. Then the zero of voltage for each $V_{i}$ can be chosen such that $g_{i}(0) = 0$ for all $i$. Because the values of asymptotes are totally unimportant in all that follows, we will simplify notation by taking them as $\pm 1$ for all $i$. The second simplification is to treat the case in which $I_{i} = 0$ for all $i$. Finally, while the continuous case has an energy function with self-connections $T_{ii}$, the discrete case need not, so $T_{ii}=0$ will be assumed for the following analysis.</p>
</blockquote>
<p>è€ƒè™‘ $V_{i}^{0}&lt;0&lt;V_{i}^{1}$ å¯¹æ‰€æœ‰ $i$ çš„æƒ…å†µã€‚ç„¶åå¯ä»¥é€‰æ‹©æ¯ä¸ª $V_{i}$ çš„ç”µå‹é›¶ç‚¹ï¼Œä½¿å¾— $g_{i}(0) = 0$ å¯¹æ‰€æœ‰ $i$ æˆç«‹ã€‚ç”±äºæ¸è¿‘çº¿çš„å€¼åœ¨æ¥ä¸‹æ¥çš„æ‰€æœ‰å†…å®¹ä¸­éƒ½æ˜¯å®Œå…¨ä¸é‡è¦çš„ï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†å®ƒä»¬ç®€åŒ–ä¸ºå¯¹æ‰€æœ‰ $i$ å– $\pm 1$ æ¥ç®€åŒ–ç¬¦å·ã€‚ç¬¬äºŒä¸ªç®€åŒ–æ˜¯å¤„ç† $I_{i} = 0$ å¯¹æ‰€æœ‰ $i$ çš„æƒ…å†µã€‚æœ€åï¼Œè™½ç„¶è¿ç»­æƒ…å†µæœ‰ä¸€ä¸ªå…·æœ‰è‡ªè¿æ¥ $T_{ii}$ çš„èƒ½é‡å‡½æ•°ï¼Œä½†ç¦»æ•£æƒ…å†µä¸éœ€è¦ï¼Œå› æ­¤åœ¨ä»¥ä¸‹åˆ†æä¸­å°†å‡è®¾ $T_{ii}=0$ã€‚</p>
<blockquote>
<p>This continuous system has for symmetric $T$ the underlying energy function</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j\neq i}T_{ij}V_{i}V_{j} + \sum\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V.
$$</p>
</blockquote>
<p>å¯¹äºå¯¹ç§°çš„ $T$ï¼Œè¿™ä¸ªè¿ç»­ç³»ç»Ÿçš„åŸºæœ¬èƒ½é‡å‡½æ•°ä¸º</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j\neq i}T_{ij}V_{i}V_{j} + \sum\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V.
$$</p>
<blockquote>
<p>Where are the maxima and minima of the first term of Eq. 11 in the domain of the hypercube $-1\leq V_{i}\leq 1$ for all $i$? In the usual case, all extrema lie at corners of the $N$-dimensional hypercube space. [In the pathological case that $T$ is a positive or negative definite matrix, an extrermum is also possible in the interior of the space. This is not the case for information storage matrices of the usual type.]</p>
</blockquote>
<p>åœ¨å¯¹æ‰€æœ‰ $i$ çš„è¶…ç«‹æ–¹ä½“ $-1\leq V_{i}\leq 1$ çš„é¢†åŸŸä¸­ï¼Œæ–¹ç¨‹ 11 çš„ç¬¬ä¸€é¡¹çš„æœ€å¤§å€¼å’Œæœ€å°å€¼åœ¨å“ªé‡Œï¼Ÿåœ¨é€šå¸¸æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æå€¼éƒ½ä½äº $N$ ç»´è¶…ç«‹æ–¹ä½“ç©ºé—´çš„è§’è½å¤„ã€‚[åœ¨ç—…æ€æƒ…å†µä¸‹ï¼Œå¦‚æœ $T$ æ˜¯æ­£å®šæˆ–è´Ÿå®šçŸ©é˜µï¼Œæå€¼ä¹Ÿå¯èƒ½å‡ºç°åœ¨ç©ºé—´çš„å†…éƒ¨ã€‚è¿™ä¸æ˜¯é€šå¸¸ç±»å‹çš„ä¿¡æ¯å­˜å‚¨çŸ©é˜µçš„æƒ…å†µã€‚]</p>
<blockquote>
<p>The discrete, stochastic algorithm searches for minimal states at the corners of the hypercube-corners that are lower than adjacent corners. Since $E$ is a linear function of a single $V_{i}$ along any cube edge, the energy minima (or maxima) of</p>
<p>$$
E = -\frac{1}{2}\sum_{i}\sum_{j\neq i}T_{ij}V_{i}V_{j}
$$</p>
<p>for the discrete space $V_{i} = \pm 1$ are exactly the same corners as the energy maxima and minima for the continuous case  $-1\leq V_{i}\leq 1$.</p>
</blockquote>
<p>ç¦»æ•£çš„éšæœºç®—æ³•åœ¨è¶…ç«‹æ–¹ä½“çš„è§’è½å¤„æœç´¢æœ€å°çŠ¶æ€â€”â€”è¿™äº›è§’è½æ¯”ç›¸é‚»çš„è§’è½æ›´ä½ã€‚ç”±äº $E$ æ²¿ä»»ä½•ç«‹æ–¹ä½“è¾¹ç¼˜æ˜¯å•ä¸ª $V_{i}$ çš„çº¿æ€§å‡½æ•°ï¼Œå› æ­¤å¯¹äºç¦»æ•£ç©ºé—´ $V_{i} = \pm 1$ï¼Œ</p>
<blockquote>
<p>The second term in Eq. 11 alters the overall picture somewhat. To understand that alteration most easily, the gain $g$ can be scaled, replacing</p>
<p>$$
V_{i} = g_{i}(u_{i}) \text{ by }  V_{i} = g_{i}(\lambda u_{i})
$$</p>
<p>and</p>
<p>$$
u_{i} = g_{i}^{-1}(V_{i})\text{ by } u_{i} = \frac{1}{\lambda}g_{i}^{-1}(V_{i})
$$</p>
<p>This scaling changes the steepness of the sigmoid gain curve without altering the output asymptotes, as indicated in Fig. lb. $g_{i}(x)$ now represents a standard form in which the scale factor $\lambda = 1$ corresponds to a standard gain, $\lambda\gg 1$ to a system with very high gain and step-like gain curve, and $\lambda$ small corresponds to a low gain and flat sigmoid curve (Fig. lb). The second term in $E$ is now</p>
<p>$$
+\frac{1}{\lambda}\sum_{i}\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V.
$$</p>
<p>The integral is zero for $V_{i} = 0$ and positive otherwise, getting very large as $V_{i}$ approaches $\pm 1$ because of the slowness with which $g(V)$ approaches its asymptotes (Fig. 1d). However, in the high-gain limit $\lambda\rightarrow \infty$ this second term becomes negligible, and the locations of the maxima and minima of the full energy expression become the same as that of Eq. 12 or Eq. 3 in the absence of inputs and zero thresholds. The only stable points of the very high gain, continuous, deterministic system therefore correspond to the stable points of the stochastic system.</p>
</blockquote>
<p>æ–¹ç¨‹ 11 ä¸­çš„ç¬¬äºŒé¡¹ç¨å¾®æ”¹å˜äº†æ•´ä½“æƒ…å†µã€‚ä¸ºäº†æœ€å®¹æ˜“ç†è§£è¿™ç§å˜åŒ–ï¼Œå¯ä»¥ç¼©æ”¾å¢ç›Šï¼Œæ›¿æ¢</p>
<p>$$
V_{i} = g_{i}(u_{i}) \text{ ä»¥ }  V_{i} = g_{i}(\lambda u_{i})
$$</p>
<p>å’Œ</p>
<p>$$
u_{i} = g_{i}^{-1}(V_{i})\text{ ä»¥ } u_{i} = \frac{1}{\lambda}g_{i}^{-1}(V_{i})
$$</p>
<p>è¿™ç§ç¼©æ”¾æ”¹å˜äº†è¥¿æ ¼ç›å¢ç›Šæ›²çº¿çš„é™¡å³­åº¦ï¼Œè€Œä¸æ”¹å˜è¾“å‡ºæ¸è¿‘çº¿ï¼Œå¦‚å›¾ 1b æ‰€ç¤ºã€‚$g_{i}(x)$ ç°åœ¨è¡¨ç¤ºä¸€ä¸ªæ ‡å‡†å½¢å¼ï¼Œå…¶ä¸­æ¯”ä¾‹å› å­ $\lambda = 1$ å¯¹åº”äºæ ‡å‡†å¢ç›Šï¼Œ$\lambda\gg 1$ å¯¹åº”äºå…·æœ‰éå¸¸é«˜å¢ç›Šå’Œé˜¶è·ƒçŠ¶å¢ç›Šæ›²çº¿çš„ç³»ç»Ÿï¼Œè€Œ $\lambda$ å°å¯¹åº”äºä½å¢ç›Šå’Œå¹³å¦çš„è¥¿æ ¼ç›æ›²çº¿ï¼ˆå›¾ 1bï¼‰ã€‚$E$ ä¸­çš„ç¬¬äºŒé¡¹ç°åœ¨æ˜¯</p>
<p>$$
+\frac{1}{\lambda}\sum_{i}\frac{1}{R_{i}}\int_{0}^{V_{i}}g_{i}^{-1}(V)\mathrm{d}V.
$$</p>
<p>å½“ $V_{i} = 0$ æ—¶ï¼Œç§¯åˆ†ä¸ºé›¶ï¼Œå¦åˆ™ä¸ºæ­£ï¼Œå¹¶ä¸”å½“ $V_{i}$ æ¥è¿‘ $\pm 1$ æ—¶å˜å¾—éå¸¸å¤§ï¼Œå› ä¸º $g(V)$ æ¥è¿‘å…¶æ¸è¿‘çº¿çš„é€Ÿåº¦å¾ˆæ…¢ï¼ˆå›¾ 1dï¼‰ã€‚ç„¶è€Œï¼Œåœ¨é«˜å¢ç›Šæé™ $\lambda\rightarrow \infty$ ä¸‹ï¼Œè¿™ç¬¬äºŒé¡¹å˜å¾—å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå¹¶ä¸”å®Œæ•´èƒ½é‡è¡¨è¾¾å¼çš„æœ€å¤§å€¼å’Œæœ€å°å€¼çš„ä½ç½®ä¸æ–¹ç¨‹ 12 æˆ–æ–¹ç¨‹ 3 åœ¨æ²¡æœ‰è¾“å…¥å’Œé›¶é˜ˆå€¼çš„æƒ…å†µä¸‹çš„ä½ç½®ç›¸åŒã€‚å› æ­¤ï¼Œéå¸¸é«˜å¢ç›Šçš„è¿ç»­ç¡®å®šæ€§ç³»ç»Ÿçš„å”¯ä¸€ç¨³å®šç‚¹å¯¹åº”äºéšæœºç³»ç»Ÿçš„ç¨³å®šç‚¹ã€‚</p>
<blockquote>
<p>For large but finite $\lambda$, the second term in Eq. 11 begins to contribute. The form of $g_{i}(V_{i})$ leads to a large positive contribution near all surfaces, edges, and corners of the hypercube while it still contributes negligibly far from the surfaces. This leads to an energy surface that still has its maxima at corners but the minima become displaced slightly toward the interior of the space. As $\lambda$ decreases, each minimum moves further inward. As $\lambda$ is further decreased minima disappear one at a time, when the topology of the energy surface makes a minimum and a saddle point coalesce. Ultimately, for very small $\lambda$, the second term in Eq. 11 dominates, and the only minimum is at $V_{i} = 0$. When the gain is large enough that there are many minima, each is associated with a well-defined minimum of the infinite gain case-as the gain is increased, each minimum will move until it reaches a particular cube corner when $\lambda\rightarrow \infty$. The same kind of mapping relation  holds in general between the continuous deterministic system with sigmoid response curves and the stochastic model.</p>
</blockquote>
<p>å¯¹äºå¤§ä½†æœ‰é™çš„ $\lambda$ï¼Œæ–¹ç¨‹ 11 ä¸­çš„ç¬¬äºŒé¡¹å¼€å§‹èµ·ä½œç”¨ã€‚$g_{i}(V_{i})$ çš„å½¢å¼å¯¼è‡´åœ¨è¶…ç«‹æ–¹ä½“çš„æ‰€æœ‰è¡¨é¢ã€è¾¹ç¼˜å’Œè§’è½é™„è¿‘æœ‰ä¸€ä¸ªå¤§çš„æ­£è´¡çŒ®ï¼Œè€Œåœ¨è¿œç¦»è¡¨é¢æ—¶ä»ç„¶è´¡çŒ®å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªèƒ½é‡è¡¨é¢ï¼Œå…¶æœ€å¤§å€¼ä»ç„¶ä½äºè§’è½ï¼Œä½†æœ€å°å€¼ç¨å¾®å‘ç©ºé—´å†…éƒ¨åç§»ã€‚éšç€ $\lambda$ çš„å‡å°ï¼Œæ¯ä¸ªæœ€å°å€¼è¿›ä¸€æ­¥å‘å†…ç§»åŠ¨ã€‚å½“èƒ½é‡è¡¨é¢çš„æ‹“æ‰‘ä½¿å¾—ä¸€ä¸ªæœ€å°å€¼å’Œä¸€ä¸ªéç‚¹åˆå¹¶æ—¶ï¼Œéšç€ $\lambda$ çš„è¿›ä¸€æ­¥å‡å°ï¼Œæœ€å°å€¼ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æ¶ˆå¤±ã€‚æœ€ç»ˆï¼Œå¯¹äºéå¸¸å°çš„ $\lambda$ï¼Œæ–¹ç¨‹ 11 ä¸­çš„ç¬¬äºŒé¡¹å ä¸»å¯¼åœ°ä½ï¼Œå”¯ä¸€çš„æœ€å°å€¼åœ¨ $V_{i} = 0$ å¤„ã€‚å½“å¢ç›Šè¶³å¤Ÿå¤§ä»¥è‡³äºå­˜åœ¨è®¸å¤šæœ€å°å€¼æ—¶ï¼Œæ¯ä¸ªæœ€å°å€¼éƒ½ä¸æ— é™å¢ç›Šæƒ…å†µä¸‹çš„ä¸€ä¸ªæ˜ç¡®å®šä¹‰çš„æœ€å°å€¼ç›¸å…³è”â€”â€”éšç€å¢ç›Šçš„å¢åŠ ï¼Œæ¯ä¸ªæœ€å°å€¼å°†ç§»åŠ¨ï¼Œç›´åˆ°åœ¨ $\lambda\rightarrow \infty$ æ—¶è¾¾åˆ°ä¸€ä¸ªç‰¹å®šçš„ç«‹æ–¹ä½“è§’è½ã€‚åœ¨å…·æœ‰è¥¿æ ¼ç›å“åº”æ›²çº¿çš„è¿ç»­ç¡®å®šæ€§ç³»ç»Ÿä¸éšæœºæ¨¡å‹ä¹‹é—´é€šå¸¸ä¹Ÿå­˜åœ¨åŒæ ·ç±»å‹çš„æ˜ å°„å…³ç³»ã€‚</p>
<blockquote>
<p>An energy contour map for a two-neuron (or two operational amplifier) system with two stable states is illustrated in Fig. 3. The two axes are the outputs of the two amplifiers. The upper left and lower right corners are stable minima for infinite gain, and the minima are displaced inward by the finite gain.</p>
</blockquote>
<p>å›¾ 3 å±•ç¤ºäº†å…·æœ‰ä¸¤ç§ç¨³å®šçŠ¶æ€çš„åŒç¥ç»å…ƒï¼ˆæˆ–åŒè¿ç®—æ”¾å¤§å™¨ï¼‰ç³»ç»Ÿçš„èƒ½é‡ç­‰å€¼çº¿å›¾ã€‚ä¸¤æ¡è½´çº¿æ˜¯ä¸¤ä¸ªæ”¾å¤§å™¨çš„è¾“å‡ºã€‚å·¦ä¸Šè§’å’Œå³ä¸‹è§’æ˜¯æ— é™å¢ç›Šæ—¶çš„ç¨³å®šæå°å€¼ï¼Œæå°å€¼å› æœ‰é™å¢ç›Šè€Œå‘å†…ç§»åŠ¨ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/uyn8N1e4okYJr6l.png" alt=""  /></p>
<p>FIG. 3. An energy contour map for a two-neuron, two-stablestate system. The ordinate and abscissa are the outputs of the two neurons. Stable states are located near the lower left and upper right corners, and unstable extrema at the other two corners. The arrows show the motion of the state from Eq. 5. This motion is not in general perpendicular to the energy contours. The system parameters are $T_{12} = T_{21} = 1$, $\lambda = 1.4$, and $g(u) = (2/\pi)\tan^{-1} (\pi\lambda u/2)$. Energy contours are $0.449$, $0.156$, $0.017$, $-0.003$, $-0.023$, and $-0.041$.</p>
</blockquote>
<p>å›¾ 3. ä¸€ä¸ªåŒç¥ç»å…ƒã€åŒç¨³å®šçŠ¶æ€ç³»ç»Ÿçš„èƒ½é‡ç­‰é«˜çº¿å›¾ã€‚çºµåæ ‡å’Œæ¨ªåæ ‡æ˜¯ä¸¤ä¸ªç¥ç»å…ƒçš„è¾“å‡ºã€‚ç¨³å®šçŠ¶æ€ä½äºå·¦ä¸‹è§’å’Œå³ä¸Šè§’é™„è¿‘ï¼Œä¸ç¨³å®šçš„æå€¼ä½äºå…¶ä»–ä¸¤ä¸ªè§’è½ã€‚ç®­å¤´æ˜¾ç¤ºäº†æ–¹ç¨‹ 5 ä¸­çŠ¶æ€çš„è¿åŠ¨ã€‚è¿™ç§è¿åŠ¨é€šå¸¸ä¸å‚ç›´äºèƒ½é‡ç­‰é«˜çº¿ã€‚ç³»ç»Ÿå‚æ•°ä¸º $T_{12} = T_{21} = 1$ï¼Œ$\lambda = 1.4$ï¼Œä¸” $g(u) = (2/\pi)\tan^{-1} (\pi\lambda u/2)$ã€‚èƒ½é‡ç­‰é«˜çº¿åˆ†åˆ«ä¸º $0.449$ï¼Œ$0.156$ï¼Œ$0.017$ï¼Œ$-0.003$ï¼Œ$-0.023$ å’Œ $-0.041$ã€‚</p>
</blockquote>
<blockquote>
<p>There are many general theorems about stability in networks of differential equations representing chemistry, circuits, and biology. The importance of this simple symmetric system is not merely its stability, but the fact that the correspondence with a discrete system lends it a special relation to elementary computational devices and concepts.</p>
</blockquote>
<p>å…³äºè¡¨ç¤ºåŒ–å­¦ã€ç”µè·¯å’Œç”Ÿç‰©å­¦çš„å¾®åˆ†æ–¹ç¨‹ç½‘ç»œçš„ç¨³å®šæ€§ï¼Œæœ‰è®¸å¤šä¸€èˆ¬å®šç†ã€‚è¿™ä¸ªç®€å•å¯¹ç§°ç³»ç»Ÿçš„é‡è¦æ€§ä¸ä»…åœ¨äºå®ƒçš„ç¨³å®šæ€§ï¼Œè¿˜åœ¨äºå®ƒä¸ç¦»æ•£ç³»ç»Ÿçš„å¯¹åº”å…³ç³»ä½¿å…¶ä¸åŸºæœ¬è®¡ç®—è®¾å¤‡å’Œæ¦‚å¿µå…·æœ‰ç‰¹æ®Šçš„è”ç³»ã€‚</p>
<h1 id="discussion-1">Discussion<a hidden class="anchor" aria-hidden="true" href="#discussion-1">#</a></h1>
<blockquote>
<p>Real neurons and real amplifiers have graded, continuous outputs as a function of their inputs (or sigmoid input-output curves of finite steepness) rather than steplike, two-state response curves. Our original stochastic model of CAM and other collective properties of assemblies of neurons was based on two-state neurons. A continuous, deterministic neuron network of interconnected neurons with graded responses has been analyzed in the previous two sections. It functions as a CAM in precisely the same collective way as did the original stochastic model of CAM. A set of memories can be nonlocally stored in a matrix of synaptic (or resistive) interconnections ih such a way that particular memories can be reconstructed from a starting state&rsquo;that gives partial information about one of them.</p>
</blockquote>
<p>çœŸå®çš„ç¥ç»å…ƒå’ŒçœŸå®çš„æ”¾å¤§å™¨å…·æœ‰éšå…¶è¾“å…¥å˜åŒ–çš„åˆ†çº§ã€è¿ç»­è¾“å‡ºï¼ˆæˆ–æœ‰é™é™¡å³­åº¦çš„è¥¿æ ¼ç›è¾“å…¥-è¾“å‡ºæ›²çº¿ï¼‰ï¼Œè€Œä¸æ˜¯é˜¶è·ƒçŠ¶çš„ä¸¤æ€å“åº”æ›²çº¿ã€‚æˆ‘ä»¬æœ€åˆçš„ CAM éšæœºæ¨¡å‹ä»¥åŠç¥ç»å…ƒé›†åˆçš„å…¶ä»–é›†ä½“å±æ€§æ˜¯åŸºäºä¸¤æ€ç¥ç»å…ƒçš„ã€‚å‰ä¸¤èŠ‚åˆ†æäº†ä¸€ä¸ªå…·æœ‰åˆ†çº§å“åº”çš„äº’è¿ç¥ç»å…ƒçš„è¿ç»­ç¡®å®šæ€§ç¥ç»ç½‘ç»œã€‚å®ƒä»¥ä¸åŸå§‹ CAM éšæœºæ¨¡å‹å®Œå…¨ç›¸åŒçš„é›†ä½“æ–¹å¼ä½œä¸º CAM è¿è¡Œã€‚ä¸€ç»„è®°å¿†å¯ä»¥éå±€éƒ¨åœ°å­˜å‚¨åœ¨è¿™æ ·çš„çªè§¦ï¼ˆæˆ–ç”µé˜»ï¼‰äº’è¿çŸ©é˜µä¸­ï¼Œä»¥ä¾¿å¯ä»¥ä»æä¾›éƒ¨åˆ†ä¿¡æ¯çš„èµ·å§‹çŠ¶æ€é‡å»ºç‰¹å®šè®°å¿†ã€‚</p>
<blockquote>
<p>The convergence of the neuronal state of the continuous, deterministic model to its stable states (memories) is based on the existence of an energy function that directs the flow in state space. Such a function can be constructed in the continuous, deterministic model when $T$ is symmetric, just as was the case for the original stochastic model with two-state neurons. Other interesting uses and interpretations of the behaviors of the original model based on the existence of an underlying energy function will also hold for the continuous (&ldquo;graded response&rdquo;) model.</p>
</blockquote>
<p>è¿ç»­ç¡®å®šæ€§æ¨¡å‹çš„ç¥ç»å…ƒçŠ¶æ€æ”¶æ•›åˆ°å…¶ç¨³å®šçŠ¶æ€ï¼ˆè®°å¿†ï¼‰æ˜¯åŸºäºå­˜åœ¨ä¸€ä¸ªèƒ½é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æŒ‡å¯¼çŠ¶æ€ç©ºé—´ä¸­çš„æµåŠ¨ã€‚å½“ $T$ æ˜¯å¯¹ç§°æ—¶ï¼Œå¯ä»¥åœ¨è¿ç»­ç¡®å®šæ€§æ¨¡å‹ä¸­æ„é€ è¿™æ ·çš„å‡½æ•°ï¼Œå°±åƒåŸå§‹çš„ä¸¤æ€ç¥ç»å…ƒéšæœºæ¨¡å‹çš„æƒ…å†µä¸€æ ·ã€‚åŸºäºå­˜åœ¨åŸºæœ¬èƒ½é‡å‡½æ•°çš„åŸå§‹æ¨¡å‹è¡Œä¸ºçš„å…¶ä»–æœ‰è¶£ç”¨é€”å’Œè§£é‡Šä¹Ÿé€‚ç”¨äºè¿ç»­ï¼ˆ&ldquo;åˆ†çº§å“åº”&rdquo;ï¼‰æ¨¡å‹ã€‚</p>
<blockquote>
<p>A direct correspondence between the stable states of the two models was shown. For steep response curves (high gain) there is a 1:1 correspondence between the memories of the two models. When the response is less steep (lower gain) the continuous-response model can have fewer stable states than the stochastic model with the same $T$ matrix, but the existing stable states will still correspond to particular stable states of the stochastic model. This simple correspondence is possible because of the quadratic form of the interaction between different neurons in the energy function. More complicated energy functions, which have occasionally been used in constraint satisfaction problems, may have in addition stable states within the interior of the domain of state space in the continuous model which have no correspondence within the discrete two-state model.</p>
</blockquote>
<p>ä¸¤ä¸ªæ¨¡å‹çš„ç¨³å®šçŠ¶æ€ä¹‹é—´æ˜¾ç¤ºäº†ç›´æ¥å¯¹åº”å…³ç³»ã€‚å¯¹äºé™¡å³­çš„å“åº”æ›²çº¿ï¼ˆé«˜å¢ç›Šï¼‰ï¼Œä¸¤ä¸ªæ¨¡å‹çš„è®°å¿†ä¹‹é—´å­˜åœ¨ 1:1 çš„å¯¹åº”å…³ç³»ã€‚å½“å“åº”ä¸é‚£ä¹ˆé™¡å³­ï¼ˆè¾ƒä½å¢ç›Šï¼‰æ—¶ï¼Œè¿ç»­å“åº”æ¨¡å‹å¯èƒ½å…·æœ‰æ¯”å…·æœ‰ç›¸åŒ $T$ çŸ©é˜µçš„éšæœºæ¨¡å‹æ›´å°‘çš„ç¨³å®šçŠ¶æ€ï¼Œä½†ç°æœ‰çš„ç¨³å®šçŠ¶æ€ä»ç„¶å¯¹åº”äºéšæœºæ¨¡å‹çš„ç‰¹å®šç¨³å®šçŠ¶æ€ã€‚è¿™ç§ç®€å•çš„å¯¹åº”å…³ç³»æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºèƒ½é‡å‡½æ•°ä¸­ä¸åŒç¥ç»å…ƒä¹‹é—´ç›¸äº’ä½œç”¨çš„äºŒæ¬¡å½¢å¼ã€‚æ›´å¤æ‚çš„èƒ½é‡å‡½æ•°ï¼Œæœ‰æ—¶åœ¨çº¦æŸæ»¡è¶³é—®é¢˜ä¸­ä½¿ç”¨ï¼Œå¯èƒ½åœ¨è¿ç»­æ¨¡å‹çš„çŠ¶æ€ç©ºé—´åŸŸå†…éƒ¨è¿˜æœ‰ç¨³å®šçŠ¶æ€ï¼Œè¿™äº›ç¨³å®šçŠ¶æ€åœ¨ç¦»æ•£ä¸¤æ€æ¨¡å‹ä¸­æ²¡æœ‰å¯¹åº”å…³ç³»ã€‚</p>
<blockquote>
<p>This analysis indicates that a real circuit of operational amplifiers, capacitors, and resistors should be able to operate as a CAM, reconstructing the stable states that have been designed into $T$. As long as $T$ is symmetric and the amplifiers are fast compared with the characteristic RC time of the input network, the system will converge to stable states and  cannot oscillate or display chaotic behavior. While the symmetry of the network is essential to the mathematics, a pragmatic view indicates that approximate symmetry will suffice, as was experimentally shown in the stochastic model. Equivalence of the gain curves and input capacitance of the amplifiers is not needed. For high-gain systems, the stable  states of the real circuit will be exactly those predicted by the stochastic model.</p>
</blockquote>
<p>è¯¥åˆ†æè¡¨æ˜ï¼Œä¸€ä¸ªç”±è¿ç®—æ”¾å¤§å™¨ã€ç”µå®¹å™¨å’Œç”µé˜»å™¨ç»„æˆçš„çœŸå®ç”µè·¯åº”è¯¥èƒ½å¤Ÿä½œä¸º CAM è¿è¡Œï¼Œé‡å»ºå·²è®¾è®¡åˆ° $T$ ä¸­çš„ç¨³å®šçŠ¶æ€ã€‚åªè¦ $T$ æ˜¯å¯¹ç§°çš„ï¼Œå¹¶ä¸”æ”¾å¤§å™¨ç›¸å¯¹äºè¾“å…¥ç½‘ç»œçš„ç‰¹å¾ RC æ—¶é—´è¶³å¤Ÿå¿«ï¼Œç³»ç»Ÿå°†æ”¶æ•›åˆ°ç¨³å®šçŠ¶æ€ï¼Œå¹¶ä¸”ä¸ä¼šæŒ¯è¡æˆ–æ˜¾ç¤ºæ··æ²Œè¡Œä¸ºã€‚è™½ç„¶ç½‘ç»œçš„å¯¹ç§°æ€§å¯¹äºæ•°å­¦æ˜¯å¿…ä¸å¯å°‘çš„ï¼Œä½†åŠ¡å®çš„è§‚ç‚¹è¡¨æ˜ï¼Œè¿‘ä¼¼å¯¹ç§°æ€§å°±è¶³å¤Ÿäº†ï¼Œæ­£å¦‚åœ¨éšæœºæ¨¡å‹ä¸­å®éªŒæ‰€ç¤ºã€‚æ”¾å¤§å™¨çš„å¢ç›Šæ›²çº¿å’Œè¾“å…¥ç”µå®¹çš„ç­‰æ•ˆæ€§ä¸æ˜¯å¿…éœ€çš„ã€‚å¯¹äºé«˜å¢ç›Šç³»ç»Ÿï¼ŒçœŸå®ç”µè·¯çš„ç¨³å®šçŠ¶æ€å°†å®Œå…¨ç¬¦åˆéšæœºæ¨¡å‹çš„é¢„æµ‹ã€‚</p>
<blockquote>
<p>Neuronal and electromagnetic signals have finite propagation velocities. A neural circuit that is to operate in the mode described must have propagation delays that are considerably shorter than the RC or chemical integration time of the  network. The same must be true for the slowness of amplifier response in the case of the electrical circuit.</p>
</blockquote>
<p>ç¥ç»å…ƒå’Œç”µç£ä¿¡å·å…·æœ‰æœ‰é™çš„ä¼ æ’­é€Ÿåº¦ã€‚è¦ä»¥æ‰€æè¿°çš„æ¨¡å¼è¿è¡Œçš„ç¥ç»ç”µè·¯å¿…é¡»å…·æœ‰æ¯”ç½‘ç»œçš„ RC æˆ–åŒ–å­¦ç§¯åˆ†æ—¶é—´çŸ­å¾—å¤šçš„ä¼ æ’­å»¶è¿Ÿã€‚å¯¹äºç”µè·¯ä¸­çš„æ”¾å¤§å™¨å“åº”çš„ç¼“æ…¢æ€§ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<blockquote>
<p>The continuous model supplements, rather than replaces,  the original stochastic description. The important properties of the original model are not due to its simplifications, but come from the general structure lying behind the model. Because the original model is very efficient to simulate on a digital computer, it will often be more practical to develop  ideas and simulations on that model even when use on biological neurons or analog circuits is intended. The interesting collective properties transcend the 0-1 stochastic simplifications.</p>
</blockquote>
<p>è¿ç»­æ¨¡å‹è¡¥å……äº†åŸå§‹çš„éšæœºæè¿°ï¼Œè€Œä¸æ˜¯å–ä»£å®ƒã€‚åŸå§‹æ¨¡å‹çš„é‡è¦å±æ€§ä¸æ˜¯ç”±äºå…¶ç®€åŒ–ï¼Œè€Œæ˜¯æ¥è‡ªæ¨¡å‹èƒŒåçš„æ€»ä½“ç»“æ„ã€‚ç”±äºåŸå§‹æ¨¡å‹åœ¨æ•°å­—è®¡ç®—æœºä¸Šéå¸¸é«˜æ•ˆï¼Œå› æ­¤å³ä½¿æ‰“ç®—åœ¨ç”Ÿç‰©ç¥ç»å…ƒæˆ–æ¨¡æ‹Ÿç”µè·¯ä¸Šä½¿ç”¨å®ƒï¼Œé€šå¸¸ä¹Ÿæ›´å®ç”¨åœ¨è¯¥æ¨¡å‹ä¸Šå¼€å‘æƒ³æ³•å’Œæ¨¡æ‹Ÿã€‚æœ‰è¶£çš„é›†ä½“å±æ€§è¶…è¶Šäº† 0-1 éšæœºç®€åŒ–ã€‚</p>
<blockquote>
<p>Neurons often communicate through action potentials. The output of such neurons consists of a series of sharp  spikes having a mean frequency (when averaged over a short time) that is described by the input-output relation of Fig.1a. In addition, the delivery of transmitter at a synapse is  quantized in vesicles. Thus Eq. 5 can be only an equation for  the behavior of a neural network neglecting the quantal noise due to action potentials and the releases of discrete vesicles.  Because the system operates by moving downhill on an energy surface, the injection of a small amount of quantal noise will not greatly change the minimum-seeking behavior.</p>
</blockquote>
<p>ç¥ç»å…ƒé€šå¸¸é€šè¿‡åŠ¨ä½œç”µä½è¿›è¡Œé€šä¿¡ã€‚è¿™äº›ç¥ç»å…ƒçš„è¾“å‡ºç”±ä¸€ç³»åˆ—å°–é”çš„è„‰å†²ç»„æˆï¼Œå…¶å¹³å‡é¢‘ç‡ï¼ˆåœ¨çŸ­æ—¶é—´å†…å¹³å‡ï¼‰ç”±å›¾ 1a çš„è¾“å…¥-è¾“å‡ºå…³ç³»æè¿°ã€‚æ­¤å¤–ï¼Œçªè§¦å¤„çš„é€’è´¨ä¼ é€’æ˜¯ä»¥å›Šæ³¡çš„å½¢å¼é‡åŒ–çš„ã€‚å› æ­¤ï¼Œæ–¹ç¨‹ 5 åªèƒ½æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œè¡Œä¸ºçš„æ–¹ç¨‹ï¼Œå¿½ç•¥äº†ç”±äºåŠ¨ä½œç”µä½å’Œç¦»æ•£å›Šæ³¡é‡Šæ”¾å¼•èµ·çš„å™ªå£°ã€‚ç”±äºç³»ç»Ÿé€šè¿‡åœ¨èƒ½é‡è¡¨é¢ä¸Šå‘ä¸‹ç§»åŠ¨æ¥è¿è¡Œï¼Œå› æ­¤æ³¨å…¥å°‘é‡å™ªå£°ä¸ä¼šå¤§å¤§æ”¹å˜å¯»æ±‚æœ€å°å€¼çš„è¡Œä¸ºã€‚</p>
<blockquote>
<p>Eq.5 has a generalization to include action potentials. Let all neurons have the same gain curves $g(u)$, input capacitance $C$, input impedance $R$, and maximum firing rate $F$. Let $g(u)$ have asymptotes 0 and 1.
When a neuron has an input $u$, it is presumed to produce action potentials $V_{0}\delta(t - t_{\text{firing}})$ in a stochastic fashion with a probability $Fg(u)$ of producing an action potential per unit time. This stochastic view preserves the basic idea of the input signal being transformed into a firing rate but does not allow precise timing of individual  action potentials. A synapse with strength $T_{ij}$ will deliver a quantal charge $V_{0}T_{ij}$ to the input capacitance of neuron $i$ when neuron $j$ produces an action potential. Let $P(u_{1}, u_{2}, \cdots, u_{i},\cdots, u_{N},t)\mathrm{d}u_{1}, \mathrm{d}u_{2}, &hellip;, \mathrm{d}u_{N}$ be the probability that input potential 1 has the value $u_{1},\cdots$ The evolution of the state of the network is described by</p>
<p>$$
\frac{\partial P}{\partial t} = \sum_{i}\frac{1}{RC}\frac{\partial(u_{i}P)}{\partial u_{i}} + \sum_{j} Fg(u_{j})[-P+P(u_{1}-T_{1j}V_{0}/C,\cdots,u_{i}-T_{ij}V_{0}/C,\cdots)].
$$</p>
<p>If $V_{0}$ is small, the term in brackets can be expanded in a Taylor series, yielding</p>
<p>$$
\frac{\partial P}{\partial t} = \sum_{i}\frac{1}{RC}\frac{\partial (u_{i}P)}{\partial u_{i}} - \sum_{j}\frac{\partial \dot{P}}{\partial u_{i}}\frac{V_{0}F}{C}\sum_{i}T_{ij}g(u_{j}) + \frac{V_{0}^{2}F}{2C^{2}}\sum_{ijk}g(u_{k})T_{ik}T_{jk}\frac{\partial^{2}P}{\partial u_{i}\partial u_{j}}.
$$</p>
<p>In the limit as $V_{0}\rightarrow 0$, $F\rightarrow \infty$ such that $FV_{0} =$ constant,  the second derivative term can be omitted. This simplification has the solutions that are identical to those of the continuous, deterministic model, namely</p>
<p>$$
P = \prod\delta(u_{i}-u_{i}(t))
$$</p>
<p>where $u_{i}(t)$ obeys Eq. 5.</p>
</blockquote>
<p>æ–¹ç¨‹ 5 æœ‰ä¸€ä¸ªåŒ…å«åŠ¨ä½œç”µä½çš„æ¨å¹¿ã€‚è®©æ‰€æœ‰ç¥ç»å…ƒå…·æœ‰ç›¸åŒçš„å¢ç›Šæ›²çº¿ $g(u)$ã€è¾“å…¥ç”µå®¹ $C$ã€è¾“å…¥é˜»æŠ— $R$ å’Œæœ€å¤§å‘æ”¾ç‡ $F$ã€‚è®© $g(u)$ å…·æœ‰æ¸è¿‘çº¿ 0 å’Œ 1ã€‚å½“ç¥ç»å…ƒå…·æœ‰è¾“å…¥ $u$ æ—¶ï¼Œå‡è®¾å®ƒä»¥éšæœºæ–¹å¼äº§ç”ŸåŠ¨ä½œç”µä½ $V_{0}\delta(t - t_{\text{firing}})$ï¼Œæ¯å•ä½æ—¶é—´äº§ç”ŸåŠ¨ä½œç”µä½çš„æ¦‚ç‡ä¸º $Fg(u)$ã€‚è¿™ç§éšæœºè§‚ç‚¹ä¿ç•™äº†è¾“å…¥ä¿¡å·è¢«è½¬æ¢ä¸ºå‘æ”¾ç‡çš„åŸºæœ¬æ€æƒ³ï¼Œä½†ä¸å…è®¸å•ä¸ªåŠ¨ä½œç”µä½çš„ç²¾ç¡®æ—¶åºã€‚å…·æœ‰å¼ºåº¦ $T_{ij}$ çš„çªè§¦å°†åœ¨ç¥ç»å…ƒ $j$ äº§ç”ŸåŠ¨ä½œç”µä½æ—¶å‘ç¥ç»å…ƒ $i$ çš„è¾“å…¥ç”µå®¹ä¼ é€’é‡åŒ–ç”µè· $V_{0}T_{ij}$ã€‚ä»¤ $P(u_{1}, u_{2}, \cdots, u_{i},\cdots, u_{N},t)\mathrm{d}u_{1}, \mathrm{d}u_{2}, &hellip;, \mathrm{d}u_{N}$ ä¸ºè¾“å…¥ç”µä½ 1 å…·æœ‰å€¼ $u_{1},\cdots$ çš„æ¦‚ç‡ã€‚ç½‘ç»œçŠ¶æ€çš„æ¼”åŒ–ç”±ä¸‹å¼æè¿°</p>
<p>$$
\frac{\partial P}{\partial t} = \sum_{i}\frac{1}{RC}\frac{\partial(u_{i}P)}{\partial u_{i}} + \sum_{j} Fg(u_{j})[-P+P(u_{1}-T_{1j}V_{0}/C,\cdots,u_{i}-T_{ij}V_{0}/C,\cdots)].
$$</p>
<p>å¦‚æœ $V_{0}$ å¾ˆå°ï¼Œåˆ™æ‹¬å·å†…çš„é¡¹å¯ä»¥å±•å¼€æˆæ³°å‹’çº§æ•°ï¼Œå¾—åˆ°</p>
<p>$$
\frac{\partial P}{\partial t} = \sum_{i}\frac{1}{RC}\frac{\partial (u_{i}P)}{\partial u_{i}} - \sum_{j}\frac{\partial \dot{P}}{\partial u_{i}}\frac{V_{0}F}{C}\sum_{i}T_{ij}g(u_{j}) + \frac{V_{0}^{2}F}{2C^{2}}\sum_{ijk}g(u_{k})T_{ik}T_{jk}\frac{\partial^{2}P}{\partial u_{i}\partial u_{j}}.
$$</p>
<p>åœ¨ $V_{0}\rightarrow 0$ï¼Œ$F\rightarrow \infty$ ä¸” $FV_{0} =$ å¸¸æ•°çš„æé™ä¸‹ï¼Œå¯ä»¥çœç•¥äºŒé˜¶å¯¼æ•°é¡¹ã€‚è¿™ç§ç®€åŒ–çš„è§£ä¸è¿ç»­ç¡®å®šæ€§æ¨¡å‹çš„è§£ç›¸åŒï¼Œå³</p>
<p>$$
P = \prod\delta(u_{i}-u_{i}(t))
$$</p>
<p>å…¶ä¸­ $u_{i}(t)$ éµå¾ªæ–¹ç¨‹ 5ã€‚</p>
<blockquote>
<p>In the model, stochastic noise from the action potentials disappears in this limit and the continuous model of Eq. 5 is recovered. The second derivative term in Eq. 16 produces noise in the system in the same fashion that diffusion produces broadening in mobility-diffusion equations. These equations permit the study of the effects of action potential noise on the continuous, deterministic system. Questions such as the duration of stability of nominal stable states of the continuous, deterministic model Eq. 5 in the presence of action potential noise should be directly answerable from analysis or simulations of Eq. 15 or 16. Unfortunately the steady-state solution of this problem is not equivalent to a thermal distribution-while Eq. 15 is a master equation, it does not have detailed balance even in the high-gain limit, and the quantal noise is not characterized by a temperature.</p>
</blockquote>
<p>åœ¨è¯¥æ¨¡å‹ä¸­ï¼Œæ¥è‡ªåŠ¨ä½œç”µä½çš„éšæœºå™ªå£°åœ¨æ­¤æé™ä¸‹æ¶ˆå¤±ï¼Œå¹¶ä¸”æ¢å¤äº†æ–¹ç¨‹ 5 çš„è¿ç»­æ¨¡å‹ã€‚æ–¹ç¨‹ 16 ä¸­çš„äºŒé˜¶å¯¼æ•°é¡¹ä»¥ä¸æ‰©æ•£åœ¨è¿ç§»-æ‰©æ•£æ–¹ç¨‹ä¸­äº§ç”Ÿå±•å®½ç›¸åŒçš„æ–¹å¼åœ¨ç³»ç»Ÿä¸­äº§ç”Ÿå™ªå£°ã€‚è¿™äº›æ–¹ç¨‹å…è®¸ç ”ç©¶åŠ¨ä½œç”µä½å™ªå£°å¯¹è¿ç»­ç¡®å®šæ€§ç³»ç»Ÿçš„å½±å“ã€‚åœ¨å­˜åœ¨åŠ¨ä½œç”µä½å™ªå£°çš„æƒ…å†µä¸‹ï¼Œè¿ç»­ç¡®å®šæ€§æ¨¡å‹æ–¹ç¨‹ 5 çš„åä¹‰ç¨³å®šçŠ¶æ€çš„ç¨³å®šæŒç»­æ—¶é—´ç­‰é—®é¢˜åº”è¯¥å¯ä»¥ç›´æ¥ä»æ–¹ç¨‹ 15 æˆ– 16 çš„åˆ†ææˆ–æ¨¡æ‹Ÿä¸­å¾—åˆ°è§£ç­”ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ä¸ªé—®é¢˜çš„ç¨³æ€è§£ä¸ç­‰åŒäºçƒ­åˆ†å¸ƒâ€”â€”è™½ç„¶æ–¹ç¨‹ 15 æ˜¯ä¸€ä¸ªä¸»æ–¹ç¨‹ï¼Œä½†å³ä½¿åœ¨é«˜å¢ç›Šæé™ä¸‹å®ƒä¹Ÿæ²¡æœ‰è¯¦ç»†å¹³è¡¡ï¼Œå¹¶ä¸”é‡åŒ–å™ªå£°æ²¡æœ‰ç”¨æ¸©åº¦æ¥è¡¨å¾ã€‚</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Muatyz.github.io/posts/phy/scmp/review-soft-matter-physics/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>è½¯ç‰©è´¨å¯¼è®º å¤ä¹ æçº²</span>
  </a>
  <a class="next" href="https://Muatyz.github.io/posts/read/reference/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>Neural networks and physical systems with emergent collective computational abilities</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>





<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-api-one-xi.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            region: 'ap-shanghai',  
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>Muartz</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script><script>

    let detail = document.getElementsByClassName('details')
   
    details = [].slice.call(detail);
   
    for (let index = 0; index < details.length; index++) {
   
    let element = details[index]
   
    const summary = element.getElementsByClassName('details-summary')[0];
   
    if (summary) {
   
    summary.addEventListener('click', () => {
   
    element.classList.toggle('open');
   
    }, false);
   
    }
   
    }
   
   </script>   

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>


<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        
        
        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        
        
        

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>


<script>
    
    document.addEventListener('keydown', function(event) {
      
      if (event.key === 'j') {
        
        var nextPageLink = document.querySelector('.pagination-item.pagination-next > a');
        if (nextPageLink) {
          nextPageLink.click();
        }
      } else if (event.key === 'k') {
        
        var prevPageLink = document.querySelector('.pagination-item.pagination-previous > a');
        if (prevPageLink) {
          prevPageLink.click();
        }
      }
    });
  </script>
  
</body>







<body>
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
</body>


</html>
