<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces | æ— å¤„æƒ¹å°˜åŸƒ</title>
<meta name="keywords" content="">
<meta name="description" content="è„‘æœºæ¥å£ä¸­ç¡¬ä»¶é«˜æ•ˆå®æ—¶ç¥ç»è§£ç çš„åŸºå‡†æµ‹è¯•">
<meta name="author" content="Muartz">
<link rel="canonical" href="https://Muatyz.github.io/posts/read/reference/benchmarking-of-hardware-efficient-real-time-neural-decoding-in-brain-computer-interfaces/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://Muatyz.github.io/img/Head16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Muatyz.github.io/img/Head32.png">
<link rel="apple-touch-icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="mask-icon" href="https://Muatyz.github.io/img/Head32.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Muatyz.github.io/posts/read/reference/benchmarking-of-hardware-efficient-real-time-neural-decoding-in-brain-computer-interfaces/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>







<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script><meta property="og:title" content="Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces" />
<meta property="og:description" content="è„‘æœºæ¥å£ä¸­ç¡¬ä»¶é«˜æ•ˆå®æ—¶ç¥ç»è§£ç çš„åŸºå‡†æµ‹è¯•" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Muatyz.github.io/posts/read/reference/benchmarking-of-hardware-efficient-real-time-neural-decoding-in-brain-computer-interfaces/" />
<meta property="og:image" content="https://s2.loli.net/2025/11/12/nEhjw2f9WD7VpAB.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-11-12T00:18:23+08:00" />
<meta property="article:modified_time" content="2025-11-12T00:18:23+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://s2.loli.net/2025/11/12/nEhjw2f9WD7VpAB.png" />
<meta name="twitter:title" content="Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces"/>
<meta name="twitter:description" content="è„‘æœºæ¥å£ä¸­ç¡¬ä»¶é«˜æ•ˆå®æ—¶ç¥ç»è§£ç çš„åŸºå‡†æµ‹è¯•"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Muatyz.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "ğŸ“• é˜…è¯»",
          "item": "https://Muatyz.github.io/posts/read/"
        },

        {
          "@type": "ListItem",
          "position":  3 ,
          "name": "ğŸ“• æ–‡çŒ®",
          "item": "https://Muatyz.github.io/posts/read/reference/"
        }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces",
      "item": "https://Muatyz.github.io/posts/read/reference/benchmarking-of-hardware-efficient-real-time-neural-decoding-in-brain-computer-interfaces/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces",
  "name": "Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces",
  "description": "è„‘æœºæ¥å£ä¸­ç¡¬ä»¶é«˜æ•ˆå®æ—¶ç¥ç»è§£ç çš„åŸºå‡†æµ‹è¯•",
  "keywords": [
    ""
  ],
  "articleBody": "Abstract Designing processors for implantable closed-loop neuromodulation systems presents a formidable challenge owing to the constrained operational environment, which requires low latency and high energy efficacy. Previous benchmarks have provided limited insights into power consumption and latency. However, this study introduces algorithmic metrics that capture the potential and limitations of neural decoders for closed-loop intra-cortical brainâ€“computer interfaces in the context of energy and hardware constraints. This study benchmarks common decoding methods for predicting a primateâ€™s finger kinematics from the motor cortex and explores their suitability for low latency and high energy efficient neural decoding. The study found that ANN-based decoders provide superior decoding accuracy, requiring high latency and many operations to effectively decode neural signals. Spiking neural networks (SNNs) have emerged as a solution, bridging this gap by achieving competitive decoding performance within sub-10 ms while utilizing a fraction of computational resources. These distinctive advantages of neuromorphic SNNs make them highly suitable for the challenging closed-loop neural modulation environment. Their capacity to balance decoding accuracy and operational efficiency offers immense potential in reshaping the landscape of neural decoders, fostering greater understanding, and opening new frontiers in closed-loop intra-cortical human-machine interaction.\nä¸ºå¯æ¤å…¥é—­ç¯ç¥ç»è°ƒèŠ‚ç³»ç»Ÿè®¾è®¡å¤„ç†å™¨æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶å—é™çš„æ“ä½œç¯å¢ƒéœ€è¦ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆã€‚ä»¥å¾€çš„åŸºå‡†æµ‹è¯•å¯¹åŠŸè€—å’Œå»¶è¿Ÿæä¾›äº†æœ‰é™çš„è§è§£ã€‚ç„¶è€Œï¼Œæœ¬ç ”ç©¶å¼•å…¥äº†ç®—æ³•æŒ‡æ ‡ï¼Œæ•æ‰äº†ç¥ç»è§£ç å™¨åœ¨èƒ½é‡å’Œç¡¬ä»¶çº¦æŸä¸‹ç”¨äºé—­ç¯çš®å±‚å†…è„‘æœºæ¥å£çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚æœ¬ç ”ç©¶åŸºå‡†æµ‹è¯•äº†å¸¸è§çš„è§£ç æ–¹æ³•ï¼Œä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©è¿åŠ¨çš®å±‚çš„æ‰‹æŒ‡è¿åŠ¨å­¦ï¼Œå¹¶æ¢è®¨äº†å®ƒä»¬åœ¨ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆç¥ç»è§£ç æ–¹é¢çš„é€‚ç”¨æ€§ã€‚ç ”ç©¶å‘ç°ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰çš„è§£ç å™¨æä¾›äº†æ›´ä¼˜çš„è§£ç ç²¾åº¦ï¼Œä½†éœ€è¦é«˜å»¶è¿Ÿå’Œå¤§é‡è¿ç®—æ‰èƒ½æœ‰æ•ˆè§£ç ç¥ç»ä¿¡å·ã€‚è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰å·²æˆä¸ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡åœ¨10æ¯«ç§’ä»¥ä¸‹å®ç°å…·æœ‰ç«äº‰åŠ›çš„è§£ç æ€§èƒ½ï¼ŒåŒæ—¶åˆ©ç”¨æå°‘çš„è®¡ç®—èµ„æºï¼Œå¼¥åˆäº†è¿™ä¸€å·®è·ã€‚ç¥ç»å½¢æ€ SNNs çš„è¿™äº›ç‹¬ç‰¹ä¼˜åŠ¿ä½¿å…¶éå¸¸é€‚åˆå…·æœ‰æŒ‘æˆ˜æ€§çš„é—­ç¯ç¥ç»è°ƒèŠ‚ç¯å¢ƒã€‚å®ƒä»¬åœ¨å¹³è¡¡è§£ç ç²¾åº¦å’Œæ“ä½œæ•ˆç‡æ–¹é¢çš„èƒ½åŠ›ä¸ºé‡å¡‘ç¥ç»è§£ç å™¨çš„æ ¼å±€æä¾›äº†å·¨å¤§çš„æ½œåŠ›ï¼Œä¿ƒè¿›äº†æ›´æ·±å…¥çš„ç†è§£ï¼Œå¹¶ä¸ºé—­ç¯çš®å±‚å†…äººæœºäº¤äº’å¼€è¾Ÿäº†æ–°çš„å‰æ²¿ã€‚\nIntroduction Brainâ€“computer interfaces (BCIs) have revolutionized the fields of neuroscience and medicine by enabling individuals with disabilities to interact with external devices and restore lost sensory, motor, or cognitive functions. Intra-cortical BCIs (iBCIs), a type of invasive BCI that involves placing electrodes directly into the cortex of the brain, have great potential for closed-loop neuromodulation (CLN). CLN alters neural activity using personalized and responsive therapeutic electrical neural modulation based on the subjectâ€™s neural activity. CLN has higher efficacy, and lower risk of side effects than fixed stimulation, that is open-loop neuromodulation as shown in figure 1. CLN requires neural decoders that interpret neural activity, such that BCI can provide real-time feedback stimulation or control external devices based on the subjectâ€™s neural activity.\n**è„‘æœºæ¥å£ï¼ˆBCIï¼‰é€šè¿‡ä½¿æ®‹ç–¾äººèƒ½å¤Ÿä¸å¤–éƒ¨è®¾å¤‡äº¤äº’å¹¶æ¢å¤ä¸§å¤±çš„æ„Ÿè§‰ã€è¿åŠ¨æˆ–è®¤çŸ¥åŠŸèƒ½ï¼Œå½»åº•æ”¹å˜äº†ç¥ç»ç§‘å­¦å’ŒåŒ»å­¦é¢†åŸŸã€‚çš®å±‚å†…è„‘æœºæ¥å£ï¼ˆiBCIï¼‰æ˜¯ä¸€ç§ä¾µå…¥æ€§ BCIï¼Œæ¶‰åŠå°†ç”µæç›´æ¥æ”¾ç½®åœ¨å¤§è„‘çš®å±‚ä¸­ï¼Œå…·æœ‰é—­ç¯ç¥ç»è°ƒèŠ‚ï¼ˆCLNï¼‰**çš„å·¨å¤§æ½œåŠ›ã€‚CLN ä½¿ç”¨åŸºäºå—è¯•è€…ç¥ç»æ´»åŠ¨çš„ä¸ªæ€§åŒ–å’Œå“åº”æ€§æ²»ç–—æ€§ç”µç¥ç»è°ƒèŠ‚æ¥æ”¹å˜ç¥ç»æ´»åŠ¨ã€‚ä¸å›ºå®šåˆºæ¿€ï¼ˆå³å¼€ç¯ç¥ç»è°ƒèŠ‚ï¼‰ç›¸æ¯”ï¼ŒCLN å…·æœ‰æ›´é«˜çš„ç–—æ•ˆå’Œæ›´ä½çš„å‰¯ä½œç”¨é£é™©ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚CLN éœ€è¦è§£é‡Šç¥ç»æ´»åŠ¨çš„ç¥ç»è§£ç å™¨ï¼Œä»¥ä¾¿ BCI èƒ½å¤Ÿæ ¹æ®å—è¯•è€…çš„ç¥ç»æ´»åŠ¨æä¾›å®æ—¶åé¦ˆåˆºæ¿€æˆ–æ§åˆ¶å¤–éƒ¨è®¾å¤‡ã€‚\nParadigm of a closed-loop and open-loop neuromodulations. (a) During open-loop neuromodulation, the subject receives predefined stimulation. (b) During closed-loop neuromodulation (CLN), the subject receives adaptive stimulation based on the recorded and decoded neural activities. CLN enables individualized, responsive therapeutic treatment improving the effectiveness of the treatment and reducing side effects.\né—­ç¯å’Œå¼€ç¯ç¥ç»è°ƒèŠ‚çš„èŒƒä¾‹ã€‚(a) åœ¨å¼€ç¯ç¥ç»è°ƒèŠ‚æœŸé—´ï¼Œå—è¯•è€…æ¥å—é¢„å®šä¹‰çš„åˆºæ¿€ã€‚(b) åœ¨é—­ç¯ç¥ç»è°ƒèŠ‚ (CLN) æœŸé—´ï¼Œå—è¯•è€…æ ¹æ®è®°å½•å’Œè§£ç çš„ç¥ç»æ´»åŠ¨æ¥æ”¶è‡ªé€‚åº”åˆºæ¿€ã€‚CLN å®ç°äº†ä¸ªæ€§åŒ–ã€å“åº”æ€§çš„æ²»ç–—ï¼Œæé«˜äº†æ²»ç–—æ•ˆæœå¹¶å‡å°‘äº†å‰¯ä½œç”¨ã€‚\nDesigning iBCIs for CLN is challenging because of the highly resource-constrained environment of the implants. Even a slight temperature increase of one degree can cause damage to neural cells. Moreover, a decoding time of a few milliseconds is required for CLN aimed at inter-areal interactions. This requires the development of energy-efficient and low-latency neural decoders that can overcome the constraints of low latency and energy consumption.\nä¸º CLN è®¾è®¡ iBCI å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ¤å…¥ç‰©çš„èµ„æºå—é™ç¯å¢ƒéå¸¸ä¸¥é‡ã€‚å³ä½¿æ¸©åº¦ç•¥å¾®å‡é«˜ä¸€åº¦ä¹Ÿä¼šå¯¹ç¥ç»ç»†èƒé€ æˆæŸå®³ã€‚æ­¤å¤–ï¼ŒCLN æ—¨åœ¨å®ç°åŒºåŸŸé—´äº¤äº’ï¼Œéœ€è¦å‡ æ¯«ç§’çš„è§£ç æ—¶é—´ã€‚è¿™éœ€è¦å¼€å‘èƒ½å¤Ÿå…‹æœä½å»¶è¿Ÿå’Œèƒ½è€—é™åˆ¶çš„é«˜èƒ½æ•ˆã€ä½å»¶è¿Ÿç¥ç»è§£ç å™¨ã€‚\nBenchmarking neural decoders for online in vivo iBCIs is crucial to ensure their optimal performance within the resource-constrained environment of implantable systems. By evaluating various decoders based on their fidelity, latency, and power consumption, researchers can identify the most suitable options that satisfy clinical safety requirements and ensure effective real-time operation, ultimately improving the efficacy of CLN.\nåœ¨ä½“å†… iBCI åœ¨çº¿åŸºå‡†æµ‹è¯•ç¥ç»è§£ç å™¨å¯¹äºç¡®ä¿å…¶åœ¨å¯æ¤å…¥ç³»ç»Ÿçš„èµ„æºå—é™ç¯å¢ƒä¸­çš„æœ€ä½³æ€§èƒ½è‡³å…³é‡è¦ã€‚é€šè¿‡æ ¹æ®ä¿çœŸåº¦ã€å»¶è¿Ÿå’ŒåŠŸè€—è¯„ä¼°å„ç§è§£ç å™¨ï¼Œç ”ç©¶äººå‘˜å¯ä»¥ç¡®å®šæ»¡è¶³ä¸´åºŠå®‰å…¨è¦æ±‚å¹¶ç¡®ä¿æœ‰æ•ˆå®æ—¶æ“ä½œçš„æœ€åˆé€‚é€‰é¡¹ï¼Œä»è€Œæœ€ç»ˆæé«˜ CLN çš„ç–—æ•ˆã€‚\nTraditional benchmarks predominantly emphasize the accuracy and fidelity aspects of decoding methods. A recent addition, NeuroBench, expanded this focus to assess algorithm-hardware co-optimization, incorporating fidelity, efficiency, and performance metrics. While NeuroBench is well-suited for evaluating the operational cost of neural decoders, its algorithmic benchmark provides limited insights into power and latency, primarily relying on the effective operational cost as a proxy for hardware metrics. This paper, presents methods to extrapolate algorithmic-to-hardware metrics, addressing the gap encompassing all the essential constraints required to evaluate and compare the suitability of neural decoders for iBCIs in the context of CLN. Any benchmark designed to compare neural decoders for iBCI within the context of CLN must consider the co-optimization between hardware and software. Only then can we benchmark effectively and accurately evaluate power consumption, latency, and the fidelity of neural decoders, providing a holistic assessment of decoder suitability for real-time, low-energy applications.\nä¼ ç»ŸåŸºå‡†æµ‹è¯•ä¸»è¦å¼ºè°ƒè§£ç æ–¹æ³•çš„å‡†ç¡®æ€§å’Œä¿çœŸåº¦æ–¹é¢ã€‚æœ€è¿‘æ–°å¢çš„ NeuroBench æ‰©å±•äº†è¿™ä¸€é‡ç‚¹ï¼Œä»¥è¯„ä¼°ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œç»“åˆäº†ä¿çœŸåº¦ã€æ•ˆç‡å’Œæ€§èƒ½æŒ‡æ ‡ã€‚è™½ç„¶ NeuroBench éå¸¸é€‚åˆè¯„ä¼°ç¥ç»è§£ç å™¨çš„æ“ä½œæˆæœ¬ï¼Œä½†å…¶ç®—æ³•åŸºå‡†å¯¹åŠŸç‡å’Œå»¶è¿Ÿæä¾›çš„è§è§£æœ‰é™ï¼Œä¸»è¦ä¾èµ–äºæœ‰æ•ˆæ“ä½œæˆæœ¬ä½œä¸ºç¡¬ä»¶æŒ‡æ ‡çš„ä»£ç†ã€‚æœ¬æ–‡æå‡ºäº†å°†ç®—æ³•æŒ‡æ ‡å¤–æ¨åˆ°ç¡¬ä»¶æŒ‡æ ‡çš„æ–¹æ³•ï¼Œè§£å†³äº†è¯„ä¼°å’Œæ¯”è¾ƒç¥ç»è§£ç å™¨åœ¨ CLN èƒŒæ™¯ä¸‹ç”¨äº iBCI é€‚ç”¨æ€§æ‰€éœ€çš„æ‰€æœ‰åŸºæœ¬çº¦æŸä¹‹é—´çš„å·®è·ã€‚ä»»ä½•æ—¨åœ¨æ¯”è¾ƒ CLN èƒŒæ™¯ä¸‹ iBCI ç¥ç»è§£ç å™¨çš„åŸºå‡†éƒ½å¿…é¡»è€ƒè™‘ç¡¬ä»¶å’Œè½¯ä»¶ä¹‹é—´çš„ååŒä¼˜åŒ–ã€‚åªæœ‰è¿™æ ·ï¼Œæˆ‘ä»¬æ‰èƒ½æœ‰æ•ˆåœ°åŸºå‡†æµ‹è¯•å¹¶å‡†ç¡®è¯„ä¼°ç¥ç»è§£ç å™¨çš„åŠŸè€—ã€å»¶è¿Ÿå’Œä¿çœŸåº¦ï¼Œä¸ºå®æ—¶ã€ä½èƒ½è€—åº”ç”¨æä¾›å…¨é¢çš„è§£ç å™¨é€‚ç”¨æ€§è¯„ä¼°ã€‚\nThis paper will introduce metrics that researchers can use to avoid the complex co-optimization process by evaluating neural decoders algorithmically while incorporating hardware considerations. Section 3 presents metrics designed to suit the energy and hardware-constrained environment of iBCIs suitable for CLN. Section 4 introduces six neural decoders benchmarks their ability to predict a primateâ€™s finger movements. Finally, future directions and implications of this research will be discussed.\næœ¬æ–‡å°†ä»‹ç»ç ”ç©¶äººå‘˜å¯ä»¥ä½¿ç”¨çš„æŒ‡æ ‡ï¼Œé€šè¿‡åœ¨è€ƒè™‘ç¡¬ä»¶çš„åŒæ—¶å¯¹ç¥ç»è§£ç å™¨è¿›è¡Œç®—æ³•è¯„ä¼°ï¼Œä»è€Œé¿å…å¤æ‚çš„ååŒä¼˜åŒ–è¿‡ç¨‹ã€‚ç¬¬ 3 èŠ‚ä»‹ç»äº†æ—¨åœ¨é€‚åº”é€‚ç”¨äº CLN çš„ iBCI çš„èƒ½æºå’Œç¡¬ä»¶å—é™ç¯å¢ƒçš„æŒ‡æ ‡ã€‚ç¬¬ 4 èŠ‚ä»‹ç»äº†å…­ç§ç¥ç»è§£ç å™¨åŸºå‡†åŠå…¶é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©æ‰‹æŒ‡è¿åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼Œå°†è®¨è®ºè¯¥ç ”ç©¶çš„æœªæ¥æ–¹å‘å’Œå½±å“ã€‚\nBackground Intra-cortical neuronal recordings from the motor cortex have been pioneered by Delgado et al in 1952 and Evarts conducted further groundbreaking work capturing extracellular neural activity from single recording units in conscious primates engaged in diverse motor tasks. Today, almost 60 years later, neural recording has undergone a revolutionary evolution owing to innovative technologies such as high-density probes, high-density microelectrode array, and carbon nanotube yarn biosensors. These technologies have made it possible to record the activities of more neurons with a higher spatial resolution and coverage and have paved the way for more clinically viable and high-performance iBCIs. BCIs help subjects with disabilities to interact with external devices, such as neuroprosthetics, or restore lost sensory, motor, or cognitive functions by translating neural activity from the brain into control commands through neural decoding. In addition to therapeutic applications, iBCIs advance our understanding of the complex neural processes that underlie behavior, cognition, and perception.\nçš®å±‚å†…ç¥ç»å…ƒè®°å½•ç”± Delgado ç­‰äººåœ¨ 1952 å¹´å¼€åˆ›ï¼ŒEvarts åœ¨æ•æ‰å‚ä¸å„ç§è¿åŠ¨ä»»åŠ¡çš„æ¸…é†’çµé•¿ç±»åŠ¨ç‰©çš„å•ä¸ªè®°å½•å•å…ƒçš„ç»†èƒå¤–ç¥ç»æ´»åŠ¨æ–¹é¢è¿›è¡Œäº†è¿›ä¸€æ­¥çš„å¼€åˆ›æ€§å·¥ä½œã€‚ä»Šå¤©ï¼Œè¿‘ 60 å¹´åï¼Œç¥ç»è®°å½•ç»å†äº†ä¸€åœºé©å‘½æ€§çš„æ¼”å˜ï¼Œè¿™è¦å½’åŠŸäºé«˜å¯†åº¦æ¢é’ˆã€é«˜å¯†åº¦å¾®ç”µæé˜µåˆ—å’Œç¢³çº³ç±³ç®¡çº±çº¿ç”Ÿç‰©ä¼ æ„Ÿå™¨ç­‰åˆ›æ–°æŠ€æœ¯ã€‚è¿™äº›æŠ€æœ¯ä½¿å¾—ä»¥æ›´é«˜çš„ç©ºé—´åˆ†è¾¨ç‡å’Œè¦†ç›–èŒƒå›´è®°å½•æ›´å¤šç¥ç»å…ƒçš„æ´»åŠ¨æˆä¸ºå¯èƒ½ï¼Œå¹¶ä¸ºæ›´å…·ä¸´åºŠå¯è¡Œæ€§å’Œé«˜æ€§èƒ½çš„ iBCI é“ºå¹³äº†é“è·¯ã€‚BCI é€šè¿‡ç¥ç»è§£ç å°†å¤§è„‘ä¸­çš„ç¥ç»æ´»åŠ¨è½¬æ¢ä¸ºæ§åˆ¶å‘½ä»¤ï¼Œå¸®åŠ©æ®‹ç–¾äººç¾¤ä¸å¤–éƒ¨è®¾å¤‡ï¼ˆå¦‚ç¥ç»å‡ä½“ï¼‰äº¤äº’æˆ–æ¢å¤ä¸§å¤±çš„æ„Ÿè§‰ã€è¿åŠ¨æˆ–è®¤çŸ¥åŠŸèƒ½ã€‚é™¤äº†æ²»ç–—åº”ç”¨å¤–ï¼ŒiBCI è¿˜å¢è¿›äº†æˆ‘ä»¬å¯¹è¡Œä¸ºã€è®¤çŸ¥å’Œæ„ŸçŸ¥èƒŒåçš„å¤æ‚ç¥ç»è¿‡ç¨‹çš„ç†è§£ã€‚\nTwo types of BCIs can be distinguished: non-invasive and invasive. Invasive BCIs involve implanting electrodes into or on the cortex. iBCIs are a specific subtype of invasive BCIs, in which electrodes are inserted into the cortex, which is the outermost layer of the brain. They provide the finest spatial and temporal resolutions and excellent signal quality. Although iBCIs carry a higher risk owing to surgical implantation, their superior spatiotemporal resolution is crucial for high-precision neural decoding.\nå¯ä»¥åŒºåˆ†ä¸¤ç§ç±»å‹çš„ BCIï¼šéä¾µå…¥æ€§å’Œä¾µå…¥æ€§ã€‚ä¾µå…¥æ€§ BCI æ¶‰åŠå°†ç”µææ¤å…¥æˆ–æ”¾ç½®åœ¨çš®å±‚ä¸Šã€‚iBCI æ˜¯ä¾µå…¥æ€§ BCI çš„ä¸€ä¸ªç‰¹å®šäºšå‹ï¼Œå…¶ä¸­ç”µææ’å…¥å¤§è„‘çš„æœ€å¤–å±‚çš®å±‚ã€‚å®ƒä»¬æä¾›äº†æœ€ç²¾ç»†çš„ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ä»¥åŠå‡ºè‰²çš„ä¿¡å·è´¨é‡ã€‚å°½ç®¡ iBCI ç”±äºå¤–ç§‘æ‰‹æœ¯æ¤å…¥è€Œå¸¦æ¥æ›´é«˜çš„é£é™©ï¼Œä½†å…¶å“è¶Šçš„æ—¶ç©ºåˆ†è¾¨ç‡å¯¹äºé«˜ç²¾åº¦ç¥ç»è§£ç è‡³å…³é‡è¦ã€‚\nCLN One promising field for iBCI is neuromodulation. Traditionally, neuromodulation described the physiological processes by which neurons use neurotransmitters to regulate neural activity. More recently, neuromodulation has been adapted to refer to the process of altering neural activity via electrical stimulation to restore normal neurological functions or study intra-cortical interaction. Neuromodulation can be classified into open and closed-loop systems, as shown in figure 1. Open-loop neuromodulation involves delivering neural stimulation without real-time feedback from the targeted neural system with predefined and fixed stimulation parameters, such as strength or timing. In contrast, CLN with iBCI uses bi-directional communication between the brain and the computing devices, providing adaptive feedback to adapt and adjust the parameters of interventions, enabling personalized and responsive therapeutic neural modulation based on the subjectâ€™s neural activity. The adaptive and interactive nature of CLN enhances efficacy, i.e. maximizing the therapeutic impact and leading to more successful treatments, and reduces the side effects of neural stimulations (e.g. discomfort, headache, or worst case seizure). For the remainder of this paper, CLN refers exclusively to neuromodulation via iBCI.\niBCI çš„ä¸€ä¸ªæœ‰å‰é€”çš„é¢†åŸŸæ˜¯ç¥ç»è°ƒèŠ‚ã€‚ä¼ ç»Ÿä¸Šï¼Œç¥ç»è°ƒèŠ‚æè¿°äº†ç¥ç»å…ƒä½¿ç”¨ç¥ç»é€’è´¨è°ƒèŠ‚ç¥ç»æ´»åŠ¨çš„ç”Ÿç†è¿‡ç¨‹ã€‚æœ€è¿‘ï¼Œç¥ç»è°ƒèŠ‚å·²è¢«æ”¹ç¼–ä¸ºæŒ‡é€šè¿‡ç”µåˆºæ¿€æ”¹å˜ç¥ç»æ´»åŠ¨ä»¥æ¢å¤æ­£å¸¸ç¥ç»åŠŸèƒ½æˆ–ç ”ç©¶çš®å±‚å†…ç›¸äº’ä½œç”¨çš„è¿‡ç¨‹ã€‚ç¥ç»è°ƒèŠ‚å¯ä»¥åˆ†ä¸ºå¼€ç¯å’Œé—­ç¯ç³»ç»Ÿï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚å¼€ç¯ç¥ç»è°ƒèŠ‚æ¶‰åŠåœ¨æ²¡æœ‰æ¥è‡ªç›®æ ‡ç¥ç»ç³»ç»Ÿçš„å®æ—¶åé¦ˆçš„æƒ…å†µä¸‹æä¾›ç¥ç»åˆºæ¿€ï¼Œå…·æœ‰é¢„å®šä¹‰å’Œå›ºå®šçš„åˆºæ¿€å‚æ•°ï¼Œä¾‹å¦‚å¼ºåº¦æˆ–æ—¶é—´ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒiBCI çš„ CLN ä½¿ç”¨å¤§è„‘ä¸è®¡ç®—è®¾å¤‡ä¹‹é—´çš„åŒå‘é€šä¿¡ï¼Œæä¾›è‡ªé€‚åº”åé¦ˆä»¥è°ƒæ•´å¹²é¢„å‚æ•°ï¼Œå®ç°åŸºäºå—è¯•è€…ç¥ç»æ´»åŠ¨çš„ä¸ªæ€§åŒ–å’Œå“åº”æ€§æ²»ç–—æ€§ç¥ç»è°ƒèŠ‚ã€‚CLN çš„è‡ªé€‚åº”å’Œäº¤äº’æ€§è´¨æé«˜äº†ç–—æ•ˆï¼Œå³æœ€å¤§åŒ–æ²»ç–—æ•ˆæœå¹¶å¯¼è‡´æ›´æˆåŠŸçš„æ²»ç–—ï¼Œå¹¶å‡å°‘äº†ç¥ç»åˆºæ¿€çš„å‰¯ä½œç”¨ï¼ˆä¾‹å¦‚ä¸é€‚ã€å¤´ç—›æˆ–æœ€åæƒ…å†µç™«ç—«å‘ä½œï¼‰ã€‚åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ä¸­ï¼ŒCLN ä¸“é—¨æŒ‡é€šè¿‡ iBCI è¿›è¡Œçš„ç¥ç»è°ƒèŠ‚ã€‚\nConstraints of closed-loop neuromodulation CLN typically requires a powerful external computer to decode complex neural activities. More sophisticated neural tasks (e.g. sensory and motor cortex interaction) require high channel counts of neural recording with fine spatial and temporal resolutions, generating vast amounts of recording data, which impose significant limitations on the real-time applicability of neural decoders, see figure 2. Transferring data from the intra-cortical neural sensors to an external system requires energy-intensive wireless transmission, and limited wireless transmission bandwidth can increase the systemâ€™s latency. Moreover, the transfer of neural data for processing to an external computer raises privacy concerns. Many neural decoders for iBCI and CLN have been implemented in application-specific integrated circuit (ASICs), achieving low power consumption and miniature form factor, which demonstrates the feasibility of in vivo neural decoding.\né—­ç¯ç¥ç»è°ƒèŠ‚é€šå¸¸éœ€è¦å¼ºå¤§çš„å¤–éƒ¨è®¡ç®—æœºæ¥è§£ç å¤æ‚çš„ç¥ç»æ´»åŠ¨ã€‚æ›´å¤æ‚çš„ç¥ç»ä»»åŠ¡ï¼ˆä¾‹å¦‚æ„Ÿè§‰å’Œè¿åŠ¨çš®å±‚äº¤äº’ï¼‰éœ€è¦é«˜é€šé“æ•°çš„ç¥ç»è®°å½•ï¼Œå…·æœ‰ç²¾ç»†çš„ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ï¼Œç”Ÿæˆå¤§é‡çš„è®°å½•æ•°æ®ï¼Œè¿™å¯¹ç¥ç»è§£ç å™¨çš„å®æ—¶é€‚ç”¨æ€§æ–½åŠ äº†é‡å¤§é™åˆ¶ï¼Œè§å›¾ 2ã€‚ä»çš®å±‚å†…ç¥ç»ä¼ æ„Ÿå™¨å‘å¤–éƒ¨ç³»ç»Ÿä¼ è¾“æ•°æ®éœ€è¦è€—èƒ½çš„æ— çº¿ä¼ è¾“ï¼Œæœ‰é™çš„æ— çº¿ä¼ è¾“å¸¦å®½ä¼šå¢åŠ ç³»ç»Ÿçš„å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œå°†ç¥ç»æ•°æ®ä¼ è¾“åˆ°å¤–éƒ¨è®¡ç®—æœºè¿›è¡Œå¤„ç†ä¼šå¼•å‘éšç§é—®é¢˜ã€‚è®¸å¤šç”¨äº iBCI å’Œ CLN çš„ç¥ç»è§£ç å™¨å·²åœ¨ä¸“ç”¨é›†æˆç”µè·¯ (ASIC) ä¸­å®ç°ï¼Œå®ç°äº†ä½åŠŸè€—å’Œå¾®å‹åŒ–å½¢å¼å› ç´ ï¼Œå±•ç¤ºäº†ä½“å†…ç¥ç»è§£ç çš„å¯è¡Œæ€§ã€‚\nAdvantages and disadvantages of external and local processing. (a) External processing requires transferring neural data or extracted features to an external computing device. Wireless data transfer suffers from long latency, high transmission energy, and privacy concerns. (b) Local neural processing has the potential to be significantly faster, with low transmission energy, at the cost of little flexibility.\nå¤–éƒ¨å’Œæœ¬åœ°å¤„ç†çš„ä¼˜ç¼ºç‚¹ã€‚(a) å¤–éƒ¨å¤„ç†éœ€è¦å°†ç¥ç»æ•°æ®æˆ–æå–çš„ç‰¹å¾ä¼ è¾“åˆ°å¤–éƒ¨è®¡ç®—è®¾å¤‡ã€‚æ— çº¿æ•°æ®ä¼ è¾“å­˜åœ¨é•¿å»¶è¿Ÿã€é«˜ä¼ è¾“èƒ½è€—å’Œéšç§é—®é¢˜ã€‚(b) æœ¬åœ°ç¥ç»å¤„ç†æœ‰å¯èƒ½æ˜¾è‘—æ›´å¿«ï¼Œä¼ è¾“èƒ½è€—ä½ï¼Œä½†çµæ´»æ€§è¾ƒå·®ã€‚\nTo address these concerns, data transmission can be avoided by eliminating the need for external computing and decoding neural signals locally on the implant. This eliminates the necessity for intensive data communication collectively except for programming the implant or diagnostics. Valencia and Alimohammad highlighted the need for local processing in a fully implantable iBCI for in vivo closed-loop neural decoding, eliminating data transmission during inference and significantly reducing energy consumption, latency, and privacy concerns.\nä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡æ¶ˆé™¤å¯¹å¤–éƒ¨è®¡ç®—çš„éœ€æ±‚å¹¶åœ¨æ¤å…¥ç‰©ä¸Šæœ¬åœ°è§£ç ç¥ç»ä¿¡å·æ¥é¿å…æ•°æ®ä¼ è¾“ã€‚è¿™æ¶ˆé™¤äº†é™¤äº†å¯¹æ¤å…¥ç‰©è¿›è¡Œç¼–ç¨‹æˆ–è¯Šæ–­ä¹‹å¤–çš„å¯†é›†æ•°æ®é€šä¿¡çš„å¿…è¦æ€§ã€‚Valencia å’Œ Alimohammad å¼ºè°ƒäº†åœ¨ä½“å†…é—­ç¯ç¥ç»è§£ç çš„å…¨æ¤å…¥å¼ iBCI ä¸­è¿›è¡Œæœ¬åœ°å¤„ç†çš„å¿…è¦æ€§ï¼Œæ¶ˆé™¤äº†æ¨ç†è¿‡ç¨‹ä¸­çš„æ•°æ®ä¼ è¾“ï¼Œå¹¶æ˜¾è‘—é™ä½äº†èƒ½è€—ã€å»¶è¿Ÿå’Œéšç§é—®é¢˜ã€‚\nDesigning iBCIs for CLN is challenging because of the highly resource-constrained environment of implants. The implant volume should be minimized to reduce the invasiveness and risks of the surgery, and low power consumption is required to prevent tissue damage due to even a one degree temperature increase. However, iBCIs are required to process an exponentially growing amount of neural data, which adds to the complexity of the decoding task. Minimal heat diffusion is required to ensure safe local processing, without causing tissue damage. While Wolf initially cautiously recommended limiting the temperature of implant electronics to below 40 available at: heat flux and 2 â—¦C, a much lower bound of 1 â—¦C is vital to maintain long-term neural cell health. This means that a 10 mm2 of implant electronics cannot exceed a power dissipation of 400 Î¼W, which is âˆ¼10Ã— lower than that of smartphone processors (e.g. the microprocessor in iPhone concerns 100â€™s mW of power with an ASIC area of approximately 100 mm2). Given the conservative nature of these recommendations, minimizing power consumption beyond the stated limits is paramount. However, traditional processors cannot satisfy this power requirement, and low-power implants performing neural decoding algorithms is a major challenge to the successful clinical adoption of real-time closed-loop iBCIs.\nä¸º CLN è®¾è®¡ iBCI å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ¤å…¥ç‰©çš„èµ„æºæå…¶å—é™çš„ç¯å¢ƒã€‚ä¸ºäº†å‡å°‘æ‰‹æœ¯çš„ä¾µå…¥æ€§å’Œé£é™©ï¼Œåº”å°½é‡å‡å°‘æ¤å…¥ç‰©çš„ä½“ç§¯ï¼Œå¹¶ä¸”éœ€è¦ä½åŠŸè€—ä»¥é˜²æ­¢ç”±äºå³ä½¿æ¸©åº¦åªå‡é«˜ä¸€åº¦è€Œå¯¼è‡´çš„ç»„ç»‡æŸä¼¤ã€‚ç„¶è€Œï¼ŒiBCI éœ€è¦å¤„ç†æŒ‡æ•°å¢é•¿çš„ç¥ç»æ•°æ®é‡ï¼Œè¿™å¢åŠ äº†è§£ç ä»»åŠ¡çš„å¤æ‚æ€§ã€‚éœ€è¦æœ€å°çš„çƒ­æ‰©æ•£ä»¥ç¡®ä¿å®‰å…¨çš„æœ¬åœ°å¤„ç†ï¼Œè€Œä¸ä¼šé€ æˆç»„ç»‡æŸä¼¤ã€‚ è™½ç„¶ Wolf æœ€åˆè°¨æ…åœ°å»ºè®®å°†æ¤å…¥ç”µå­è®¾å¤‡çš„æ¸©åº¦é™åˆ¶åœ¨ 40 å¯ç”¨ï¼šçƒ­é€šé‡å’Œ 2 â—¦C ä»¥ä¸‹ï¼Œä½†ä¸ºäº†ç»´æŒé•¿æœŸç¥ç»ç»†èƒå¥åº·ï¼Œ1 â—¦C çš„æ›´ä½ç•Œé™è‡³å…³é‡è¦ã€‚è¿™æ„å‘³ç€ $10\\text{ mm}^{2}$ çš„æ¤å…¥ç”µå­è®¾å¤‡çš„åŠŸè€—ä¸èƒ½è¶…è¿‡ $400 \\mu\\text{W}$ï¼Œè¿™å¤§çº¦æ˜¯æ™ºèƒ½æ‰‹æœºå¤„ç†å™¨ï¼ˆä¾‹å¦‚ iPhone ä¸­çš„å¾®å¤„ç†å™¨ï¼ŒåŠŸç‡ä¸ºæ•°ç™¾æ¯«ç“¦ï¼ŒASIC é¢ç§¯çº¦ä¸º 100 mm2ï¼‰çš„ 10 å€ã€‚é‰´äºè¿™äº›å»ºè®®çš„ä¿å®ˆæ€§è´¨ï¼Œè¶…å‡ºè§„å®šé™åˆ¶çš„æœ€å°åŒ–åŠŸè€—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿå¤„ç†å™¨æ— æ³•æ»¡è¶³æ­¤åŠŸç‡è¦æ±‚ï¼Œæ‰§è¡Œç¥ç»è§£ç ç®—æ³•çš„ä½åŠŸè€—æ¤å…¥ç‰©æ˜¯å®æ—¶é—­ç¯ iBCI æˆåŠŸä¸´åºŠé‡‡ç”¨çš„ä¸€å¤§æŒ‘æˆ˜ã€‚\nReal-time processing is another crucial requirement for closed-loop iBCIs, in which continuous neural recording, decoding, and feedback occur in real time. This necessitates fast and efficient neural decoding algorithms to ensure timely and seamless interaction between the nervous system and the iBCI. Controlling a robotic prosthesis requires a latency of less than 150 ms between neural activity and arm movement for smooth and natural control, which is close to the biological delay for signal propagation between the brain and the arm. However, immediate feedback is crucial for the neural decoder to adjust the control system in real-time, allowing subjects to adapt and refine their actions in real-time. In this closed-loop iBCI, much lower latency of less than 10 ms is necessary for decoding inter-areal interactions (e.g. sensory and motor) in the brain.\nå®æ—¶å¤„ç†æ˜¯é—­ç¯ iBCI çš„å¦ä¸€ä¸ªå…³é”®è¦æ±‚ï¼Œå…¶ä¸­è¿ç»­çš„ç¥ç»è®°å½•ã€è§£ç å’Œåé¦ˆå®æ—¶å‘ç”Ÿã€‚è¿™éœ€è¦å¿«é€Ÿé«˜æ•ˆçš„ç¥ç»è§£ç ç®—æ³•ï¼Œä»¥ç¡®ä¿ç¥ç»ç³»ç»Ÿä¸ iBCI ä¹‹é—´çš„åŠæ—¶æ— ç¼äº¤äº’ã€‚æ§åˆ¶æœºå™¨äººå‡è‚¢éœ€è¦åœ¨ç¥ç»æ´»åŠ¨å’Œæ‰‹è‡‚è¿åŠ¨ä¹‹é—´çš„å»¶è¿Ÿå°äº 150 æ¯«ç§’ï¼Œä»¥å®ç°å¹³ç¨³è‡ªç„¶çš„æ§åˆ¶ï¼Œè¿™æ¥è¿‘å¤§è„‘ä¸æ‰‹è‡‚ä¹‹é—´ä¿¡å·ä¼ æ’­çš„ç”Ÿç‰©å­¦å»¶è¿Ÿã€‚ç„¶è€Œï¼Œç«‹å³åé¦ˆå¯¹äºç¥ç»è§£ç å™¨å®æ—¶è°ƒæ•´æ§åˆ¶ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œä½¿å—è¯•è€…èƒ½å¤Ÿå®æ—¶é€‚åº”å’Œå®Œå–„å…¶åŠ¨ä½œã€‚åœ¨è¿™ç§é—­ç¯ iBCI ä¸­ï¼Œå¯¹äºè§£ç å¤§è„‘ä¸­çš„åŒºåŸŸé—´äº¤äº’ï¼ˆä¾‹å¦‚æ„Ÿè§‰å’Œè¿åŠ¨ï¼‰ï¼Œéœ€è¦æ›´ä½çš„å»¶è¿Ÿï¼Œä½äº 10 æ¯«ç§’ã€‚\nMetrics Traditionally, neural decoders have been the primary evaluated on decoding performance. However, in hardware-constrained iBCIs, other factors, such as latency and power consumption, are crucial to ensure the tractability of neural decoders for applications such as CLN. Evaluating decoders solely on task performance often fails to capture their true potential but also limitations. This chapter introduces the need for comprehensive metrics for algorithmic evaluation that encompass fidelity (i.e. accuracy), latency, power consumption, and memory size for neural decoders. Table 1 presents an overview of the proposed evaluation metrics.\nä¼ ç»Ÿä¸Šï¼Œç¥ç»è§£ç å™¨ä¸»è¦è¯„ä¼°è§£ç æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨ç¡¬ä»¶å—é™çš„ iBCI ä¸­ï¼Œå»¶è¿Ÿå’ŒåŠŸè€—ç­‰å…¶ä»–å› ç´ å¯¹äºç¡®ä¿ç¥ç»è§£ç å™¨åœ¨ CLN ç­‰åº”ç”¨ä¸­çš„å¯å¤„ç†æ€§è‡³å…³é‡è¦ã€‚ä»…æ ¹æ®ä»»åŠ¡æ€§èƒ½è¯„ä¼°è§£ç å™¨é€šå¸¸æ— æ³•æ•æ‰å…¶çœŸæ­£çš„æ½œåŠ›ï¼Œä¹Ÿæ— æ³•æ•æ‰å…¶å±€é™æ€§ã€‚æœ¬ç« ä»‹ç»äº†å…¨é¢æŒ‡æ ‡çš„å¿…è¦æ€§ï¼Œç”¨äºæ¶µç›–ç¥ç»è§£ç å™¨çš„ä¿çœŸåº¦ï¼ˆå³å‡†ç¡®æ€§ï¼‰ã€å»¶è¿Ÿã€åŠŸè€—å’Œå†…å­˜å¤§å°çš„ç®—æ³•è¯„ä¼°ã€‚è¡¨ 1 æå‡ºäº†æ‰€å»ºè®®çš„è¯„ä¼°æŒ‡æ ‡çš„æ¦‚è¿°ã€‚\nMetric Explaination Fidelity $R^{2}\\\\r$ Proportion of explainable data variance $\\\\$ Temporal alignment of label and prediction Latency Binning latency $\\\\$ Processing latency Timespan of input data needed per inference $\\\\$ Operational delay optimized by the algorithm designer Power consumption Total eff. operations $\\\\$ Memory access Number of effective operations needed per inference $\\\\$ Number of effective memory access needed per inference Size Memory footprint Number of bits required to store the decoder æŒ‡æ ‡ è§£é‡Š ä¿çœŸåº¦ $R^{2}\\\\r$ å¯è§£é‡Šæ•°æ®æ–¹å·®çš„æ¯”ä¾‹ $\\\\$ æ ‡ç­¾å’Œé¢„æµ‹çš„æ—¶é—´å¯¹é½ å»¶è¿Ÿ åˆ†ç®±å»¶è¿Ÿ $\\\\$ å¤„ç†å»¶è¿Ÿ æ¯æ¬¡æ¨ç†æ‰€éœ€çš„è¾“å…¥æ•°æ®æ—¶é—´è·¨åº¦ $\\\\$ ç”±ç®—æ³•è®¾è®¡å¸ˆä¼˜åŒ–çš„æ“ä½œå»¶è¿Ÿ åŠŸè€— æ€»æœ‰æ•ˆæ“ä½œ $\\\\$ å†…å­˜è®¿é—® æ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆæ“ä½œæ•° $\\\\$ æ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆå†…å­˜è®¿é—®æ•° å¤§å° å†…å­˜å ç”¨ å­˜å‚¨è§£ç å™¨æ‰€éœ€çš„ä½æ•° Model fidelity The fidelity of a neural decoder in an iBCI is its ability to correctly classify or predict. In closed-loop iBCI, making accurate predictions is crucial for effective and reliable control of external devices or neural stimulations, which should closely reflect the subjectâ€™s intention or state.\niBCI ä¸­ç¥ç»è§£ç å™¨çš„ä¿çœŸåº¦æ˜¯å…¶æ­£ç¡®åˆ†ç±»æˆ–é¢„æµ‹çš„èƒ½åŠ›ã€‚åœ¨é—­ç¯ iBCI ä¸­ï¼Œåšå‡ºå‡†ç¡®çš„é¢„æµ‹å¯¹äºæœ‰æ•ˆå¯é åœ°æ§åˆ¶å¤–éƒ¨è®¾å¤‡æˆ–ç¥ç»åˆºæ¿€è‡³å…³é‡è¦ï¼Œè¿™åº”ä¸å—è¯•è€…çš„æ„å›¾æˆ–çŠ¶æ€å¯†åˆ‡ç›¸å…³ã€‚\nClassification accuracy has traditionally been used to assess neural decoding performance by determining the percentage of correct classifications of stimuli, such as odors, faces, or speech. However, these metrics do not consider the temporal continuity of neural data, which is critical for many neural decoding applications. Neural decoding tasks require metrics that incorporate the correction of the temporal regression to evaluate decoding accuracy. In such cases, the coefficient of determination ($R^2$) and the coefficient of correlation (Pearsonâ€™s $r$) are widely used to assess the performance of neural decoding algorithms.\nä¼ ç»Ÿä¸Šï¼Œåˆ†ç±»å‡†ç¡®æ€§å·²è¢«ç”¨æ¥è¯„ä¼°ç¥ç»è§£ç æ€§èƒ½ï¼Œé€šè¿‡ç¡®å®šå¯¹åˆºæ¿€ï¼ˆå¦‚æ°”å‘³ã€é¢å­”æˆ–è¯­è¨€ï¼‰çš„æ­£ç¡®åˆ†ç±»çš„ç™¾åˆ†æ¯”ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡æ²¡æœ‰è€ƒè™‘ç¥ç»æ•°æ®çš„æ—¶é—´è¿ç»­æ€§ï¼Œè€Œè¿™å¯¹äºè®¸å¤šç¥ç»è§£ç åº”ç”¨è‡³å…³é‡è¦ã€‚ç¥ç»è§£ç ä»»åŠ¡éœ€è¦ç»“åˆæ—¶é—´å›å½’æ ¡æ­£çš„æŒ‡æ ‡æ¥è¯„ä¼°è§£ç ç²¾åº¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå†³å®šç³»æ•° ($R^2$) å’Œç›¸å…³ç³»æ•°ï¼ˆPearson çš„ $r$ï¼‰è¢«å¹¿æ³›ç”¨äºè¯„ä¼°ç¥ç»è§£ç ç®—æ³•çš„æ€§èƒ½ã€‚\nThe $R^2$ measures the proportion of variance in the dependent variable explained by the modelâ€™s prediction, while Pearsonâ€™s $r$ evaluates the temporal alignment of the predictions and labels via a linear relationship. Both metrics should be reported to assess the temporal regression performance of the neural decoder comprehensively.\n$R^2$ è¡¡é‡æ¨¡å‹é¢„æµ‹è§£é‡Šçš„å› å˜é‡æ–¹å·®çš„æ¯”ä¾‹ï¼Œè€Œ Pearson çš„ $r$ é€šè¿‡çº¿æ€§å…³ç³»è¯„ä¼°é¢„æµ‹å’Œæ ‡ç­¾çš„æ—¶é—´å¯¹é½ã€‚åº”æŠ¥å‘Šè¿™ä¸¤ä¸ªæŒ‡æ ‡ï¼Œä»¥å…¨é¢è¯„ä¼°ç¥ç»è§£ç å™¨çš„æ—¶é—´å›å½’æ€§èƒ½ã€‚\nLatency The latency of the neural decoder, defined as the time delay between the first input stimulus and the output response, comprises two architecture-specific subcomponents: the binning latency and the processing latency (see figure 3(c)). This allows for a platform- and architecture-agnostic evaluation of neural decoders.\nç¥ç»è§£ç å™¨çš„å»¶è¿Ÿå®šä¹‰ä¸ºä»ç¬¬ä¸€ä¸ªè¾“å…¥åˆºæ¿€åˆ°è¾“å‡ºå“åº”ä¹‹é—´çš„æ—¶é—´å»¶è¿Ÿï¼ŒåŒ…æ‹¬ä¸¤ä¸ªç‰¹å®šäºæ¶æ„çš„å­ç»„ä»¶ï¼šåˆ†ç®±å»¶è¿Ÿ å’Œ å¤„ç†å»¶è¿Ÿï¼ˆè§å›¾ 3(c)ï¼‰ã€‚è¿™å…è®¸å¯¹ç¥ç»è§£ç å™¨è¿›è¡Œå¹³å°å’Œæ¶æ„æ— å…³çš„è¯„ä¼°ã€‚\nExperimental pipeline for evaluating closed-loop capability of neural decoders. (a) A primate consecutively reaches for black boxes on a grid. Neural activity is recorded using one or two UTAH arrays placed at the primary motor and sensorimotor cortices, while finger position is tracked through an electromagnetic position sensor. Finger velocity is computed and used as a decoding target. (b) Neural activity is processed as a spike train, binned, and processed by the neural decoding system to predict finger velocity. (c) The visualization illustrates the latency of the entire decoding system, composed of binning latency and processing latency.\nè¯„ä¼°ç¥ç»è§£ç å™¨é—­ç¯èƒ½åŠ›çš„å®éªŒæµç¨‹ã€‚(a) çµé•¿ç±»åŠ¨ç‰©è¿ç»­åœ°ä¼¸æ‰‹å»æŠ“ç½‘æ ¼ä¸Šçš„é»‘è‰²ç›’å­ã€‚ä½¿ç”¨æ”¾ç½®åœ¨åˆçº§è¿åŠ¨çš®å±‚å’Œæ„Ÿè§‰è¿åŠ¨çš®å±‚çš„ä¸€ä¸ªæˆ–ä¸¤ä¸ª UTAH é˜µåˆ—è®°å½•ç¥ç»æ´»åŠ¨ï¼ŒåŒæ—¶é€šè¿‡ç”µç£ä½ç½®ä¼ æ„Ÿå™¨è·Ÿè¸ªæ‰‹æŒ‡ä½ç½®ã€‚è®¡ç®—æ‰‹æŒ‡é€Ÿåº¦å¹¶ç”¨ä½œè§£ç ç›®æ ‡ã€‚(b) ç¥ç»æ´»åŠ¨è¢«å¤„ç†ä¸ºè„‰å†²åºåˆ—ï¼Œè¿›è¡Œåˆ†ç®±ï¼Œå¹¶ç”±ç¥ç»è§£ç ç³»ç»Ÿå¤„ç†ä»¥é¢„æµ‹æ‰‹æŒ‡é€Ÿåº¦ã€‚(c) å¯è§†åŒ–è¯´æ˜äº†æ•´ä¸ªè§£ç ç³»ç»Ÿçš„å»¶è¿Ÿï¼Œç”±åˆ†ç®±å»¶è¿Ÿå’Œå¤„ç†å»¶è¿Ÿç»„æˆã€‚\nThe binning latency corresponds to the time span of the input data required for each prediction. This equates to the binning time window or the history of binning windows in the case of multiple windows. Minimizing binning window size is crucial for limiting total latency.\nåˆ†ç®±å»¶è¿Ÿ å¯¹åº”äºæ¯æ¬¡é¢„æµ‹æ‰€éœ€çš„è¾“å…¥æ•°æ®çš„æ—¶é—´è·¨åº¦ã€‚è¿™ç›¸å½“äºåˆ†ç®±æ—¶é—´çª—å£ï¼Œæˆ–è€…åœ¨å¤šä¸ªçª—å£çš„æƒ…å†µä¸‹ä¸ºåˆ†ç®±çª—å£çš„å†å²ã€‚æœ€å°åŒ–åˆ†ç®±çª—å£å¤§å°å¯¹äºé™åˆ¶æ€»å»¶è¿Ÿè‡³å…³é‡è¦ã€‚\nThe processing latency is caused by the processing time for a neural decoder to produce a prediction. This combines the operational delay of preprocessing, network inference, and postprocessing. The processing time is bound by a function of the systemâ€™s required effective operations per inference, which can be assessed by computing the effective multiply-and-accumulate (MAC) operations of neural decoder algorithms. This definition ignores a potential speed-up of parallel processing, which would require binding the algorithm to hardware. Latency can be reported in wall time, such as absolute SI units, or relative system time, as the total number of clock cycles per inference. This paper reports latency in milliseconds, providing a more intuitive and user-centric perspective and allowing the reader to assess the systemâ€™s ability to deliver timely and accurate responses. Converting the processing latency into seconds requires platform-specific assumptions regarding the required clock cycles per operation, the clock frequency, and a systemâ€™s capability for parallel processing. For the remainder of this paper, a clock frequency of 1 MHz and 3 MAC operations per clock cycle were assumed, to provide a more intuitive comparison of the latency of the evaluated decoders. For simplicity, one addition corresponding to the sparse synaptic operation of neurons in the SNN is assumed to be equivalent to one MAC in terms of required clock cycles.\nå¤„ç†å»¶è¿Ÿ æ˜¯ç¥ç»è§£ç å™¨ç”Ÿæˆé¢„æµ‹æ‰€éœ€çš„å¤„ç†æ—¶é—´å¼•èµ·çš„ã€‚è¿™ç»“åˆäº†é¢„å¤„ç†ã€ç½‘ç»œæ¨ç†å’Œåå¤„ç†çš„æ“ä½œå»¶è¿Ÿã€‚å¤„ç†æ—¶é—´å—ç³»ç»Ÿæ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆæ“ä½œæ•°å‡½æ•°çš„çº¦æŸï¼Œå¯ä»¥é€šè¿‡è®¡ç®—ç¥ç»è§£ç å™¨ç®—æ³•çš„æœ‰æ•ˆä¹˜åŠ  (MAC) æ“ä½œæ¥è¯„ä¼°ã€‚ è¿™ä¸€å®šä¹‰å¿½ç•¥äº†å¹¶è¡Œå¤„ç†çš„æ½œåœ¨åŠ é€Ÿï¼Œè¿™å°†éœ€è¦å°†ç®—æ³•ç»‘å®šåˆ°ç¡¬ä»¶ã€‚å»¶è¿Ÿå¯ä»¥ä»¥å¢™æ—¶ï¼ˆä¾‹å¦‚ç»å¯¹ SI å•ä½ï¼‰æˆ–ç›¸å¯¹ç³»ç»Ÿæ—¶é—´ï¼ˆæ¯æ¬¡æ¨ç†çš„æ€»æ—¶é’Ÿå‘¨æœŸæ•°ï¼‰æŠ¥å‘Šã€‚æœ¬æ–‡ä»¥æ¯«ç§’ä¸ºå•ä½æŠ¥å‘Šå»¶è¿Ÿï¼Œæä¾›äº†æ›´ç›´è§‚å’Œä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è§†è§’ï¼Œå¹¶å…è®¸è¯»è€…è¯„ä¼°ç³»ç»Ÿæä¾›åŠæ—¶å‡†ç¡®å“åº”çš„èƒ½åŠ›ã€‚å°†å¤„ç†å»¶è¿Ÿè½¬æ¢ä¸ºç§’éœ€è¦å…³äºæ¯æ¬¡æ“ä½œæ‰€éœ€æ—¶é’Ÿå‘¨æœŸã€æ—¶é’Ÿé¢‘ç‡å’Œç³»ç»Ÿå¹¶è¡Œå¤„ç†èƒ½åŠ›çš„å¹³å°ç‰¹å®šå‡è®¾ã€‚ åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼Œå‡è®¾æ—¶é’Ÿé¢‘ç‡ä¸º 1 MHzï¼Œæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸ 3 æ¬¡ MAC æ“ä½œï¼Œä»¥æä¾›å¯¹è¯„ä¼°è§£ç å™¨å»¶è¿Ÿçš„æ›´ç›´è§‚æ¯”è¾ƒã€‚ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œå‡è®¾ä¸ SNN ä¸­ç¥ç»å…ƒç¨€ç–çªè§¦æ“ä½œå¯¹åº”çš„ä¸€æ¬¡åŠ æ³•åœ¨æ‰€éœ€æ—¶é’Ÿå‘¨æœŸæ–¹é¢ç­‰åŒäºä¸€æ¬¡ MACã€‚\nPower consumption Power consumption is vital to evaluating neural decoders, particularly in resource-constrained iBCIs suitable for CLN. Local neural processing, which is implemented directly on an embedded device, is usually preferable to external processing due to latency, communication bandwidth, and privacy issues. However, local neural processing requires low energy consumption to minimize tissue heating.\nåŠŸè€—å¯¹äºè¯„ä¼°ç¥ç»è§£ç å™¨è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨é€‚ç”¨äº CLN çš„èµ„æºå—é™ iBCI ä¸­ã€‚ç›´æ¥åœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šå®ç°çš„æœ¬åœ°ç¥ç»å¤„ç†é€šå¸¸ä¼˜äºå¤–éƒ¨å¤„ç†ï¼Œå› ä¸ºå­˜åœ¨å»¶è¿Ÿã€é€šä¿¡å¸¦å®½å’Œéšç§é—®é¢˜ã€‚ç„¶è€Œï¼Œæœ¬åœ°ç¥ç»å¤„ç†éœ€è¦ä½èƒ½è€—ä»¥æœ€å°åŒ–ç»„ç»‡åŠ çƒ­ã€‚\nTo compare the energy efficiency of different neural decoders in a hardware- and architecture-independent manner, one can benchmark with two hardware-agnostic metrics: total effective operations and memory accesses. This considers only algorithmic optimizations, such as reducing effective operational costs. Although algorithm-hardware co-optimizations can further improve latency, performance, and energy efficacy, they require binding the neural decoder to specific hardware and, thus, are not considered in this study.\nä¸ºäº†ä»¥ç¡¬ä»¶å’Œæ¶æ„æ— å…³çš„æ–¹å¼æ¯”è¾ƒä¸åŒç¥ç»è§£ç å™¨çš„èƒ½æ•ˆï¼Œå¯ä»¥ä½¿ç”¨ä¸¤ä¸ªç¡¬ä»¶æ— å…³çš„æŒ‡æ ‡è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼šæ€»æœ‰æ•ˆæ“ä½œå’Œå†…å­˜è®¿é—®ã€‚è¿™ä»…è€ƒè™‘ç®—æ³•ä¼˜åŒ–ï¼Œä¾‹å¦‚å‡å°‘æœ‰æ•ˆæ“ä½œæˆæœ¬ã€‚å°½ç®¡ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–å¯ä»¥è¿›ä¸€æ­¥æé«˜å»¶è¿Ÿã€æ€§èƒ½å’Œèƒ½é‡æ•ˆç‡ï¼Œä½†å®ƒä»¬éœ€è¦å°†ç¥ç»è§£ç å™¨ç»‘å®šåˆ°ç‰¹å®šç¡¬ä»¶ï¼Œå› æ­¤åœ¨æœ¬ç ”ç©¶ä¸­ä¸äºˆè€ƒè™‘ã€‚\nThe total effective operations are reported as the number of non-zero operations required per inference. This combines two relevant operations that dominate neural network operations: multiplication and addition. To estimate the energy consumption of a neural decoder, however, total operations should be reported instead of MAC and ACC since these operations are assumed to be optimized by vector accelerators, which is the bottleneck for latency but does not reflect well on the energy cost of a neural decoder. To reduce energy consumption, neural decoders can exploit the sparsity of the spiking data by distinguishing between effective and ineffective operations. This accounts for only non-zeros contributing to the products and, consequently, the accumulation, which can be leveraged by specialized hardware. Reporting the effective computational cost as the number of non-zero operations allows for hardware-agnostic comparison of different networks, considering computational primitives in neuromorphic neural networks. In the remainder of this paper, MAC denotes effective MAC operations.\næ€»æœ‰æ•ˆæ“ä½œæŠ¥å‘Šä¸ºæ¯æ¬¡æ¨ç†æ‰€éœ€çš„éé›¶æ“ä½œæ•°ã€‚è¿™ç»“åˆäº†ä¸»å¯¼ç¥ç»ç½‘ç»œæ“ä½œçš„ä¸¤ä¸ªç›¸å…³æ“ä½œï¼šä¹˜æ³•å’ŒåŠ æ³•ã€‚ç„¶è€Œï¼Œä¸ºäº†ä¼°è®¡ç¥ç»è§£ç å™¨çš„èƒ½è€—ï¼Œåº”æŠ¥å‘Šæ€»æ“ä½œæ•°è€Œä¸æ˜¯ MAC å’Œ ACCï¼Œå› ä¸ºè¿™äº›æ“ä½œå‡å®šç”±å‘é‡åŠ é€Ÿå™¨ä¼˜åŒ–ï¼Œè¿™æ˜¯å»¶è¿Ÿçš„ç“¶é¢ˆï¼Œä½†ä¸èƒ½å¾ˆå¥½åœ°åæ˜ ç¥ç»è§£ç å™¨çš„èƒ½é‡æˆæœ¬ã€‚ä¸ºäº†é™ä½èƒ½è€—ï¼Œç¥ç»è§£ç å™¨å¯ä»¥é€šè¿‡åŒºåˆ†æœ‰æ•ˆå’Œæ— æ•ˆæ“ä½œæ¥åˆ©ç”¨è„‰å†²æ•°æ®çš„ç¨€ç–æ€§ã€‚è¿™ä»…è€ƒè™‘å¯¹ä¹˜ç§¯å’Œå› æ­¤ç´¯ç§¯æœ‰è´¡çŒ®çš„éé›¶é¡¹ï¼Œè¿™å¯ä»¥è¢«ä¸“ç”¨ç¡¬ä»¶åˆ©ç”¨ã€‚å°†æœ‰æ•ˆè®¡ç®—æˆæœ¬æŠ¥å‘Šä¸ºéé›¶æ“ä½œæ•°å…è®¸å¯¹ä¸åŒç½‘ç»œè¿›è¡Œç¡¬ä»¶æ— å…³çš„æ¯”è¾ƒï¼Œè€ƒè™‘ç¥ç»å½¢æ€ç¥ç»ç½‘ç»œä¸­çš„è®¡ç®—åŸè¯­ã€‚åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼ŒMAC è¡¨ç¤ºæœ‰æ•ˆ MAC æ“ä½œã€‚\nReporting memory access is crucial for comprehensively estimating the energy consumption of neural decoders. Because a read-and-write operation to the memory requires one to two orders of magnitude more energy than operations of arithmetic linear units, it is insufficient to report only effective operations without including the memory access. Furthermore, Liao et al report âˆ¼10Ã— more reads than effective operations during inference, highlighting that most of the energy consumption of an architecture comes from the memory read-and-write operations. Following their approach, the number of memory accesses in a network is conservatively estimated by assuming that a MAC operation consists of three loads and one store. By contrast, an ACC consists of two loads and one store, which both, similarly to before, need to be combined with the sparseness of activity of the network.\næŠ¥å‘Šå†…å­˜è®¿é—®å¯¹äºå…¨é¢ä¼°è®¡ç¥ç»è§£ç å™¨çš„èƒ½è€—è‡³å…³é‡è¦ã€‚å› ä¸ºå¯¹å†…å­˜çš„è¯»å†™æ“ä½œæ‰€éœ€çš„èƒ½é‡æ¯”ç®—æœ¯çº¿æ€§å•å…ƒçš„æ“ä½œé«˜å‡ºä¸€ä¸ªåˆ°ä¸¤ä¸ªæ•°é‡çº§ï¼Œä»…æŠ¥å‘Šæœ‰æ•ˆæ“ä½œè€Œä¸åŒ…æ‹¬å†…å­˜è®¿é—®æ˜¯ä¸å¤Ÿçš„ã€‚æ­¤å¤–ï¼ŒLiao ç­‰äººåœ¨æ¨ç†è¿‡ç¨‹ä¸­æŠ¥å‘Šäº†å¤§çº¦ 10 å€äºæœ‰æ•ˆæ“ä½œçš„è¯»å–æ¬¡æ•°ï¼Œå¼ºè°ƒäº†æ¶æ„çš„å¤§éƒ¨åˆ†èƒ½è€—æ¥è‡ªå†…å­˜è¯»å†™æ“ä½œã€‚éµå¾ªä»–ä»¬çš„æ–¹æ³•ï¼Œé€šè¿‡å‡è®¾ MAC æ“ä½œç”±ä¸‰æ¬¡åŠ è½½å’Œä¸€æ¬¡å­˜å‚¨ç»„æˆï¼Œä¿å®ˆåœ°ä¼°è®¡ç½‘ç»œä¸­çš„å†…å­˜è®¿é—®æ¬¡æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒACC ç”±ä¸¤æ¬¡åŠ è½½å’Œä¸€æ¬¡å­˜å‚¨ç»„æˆï¼Œä¸ä¹‹å‰ç±»ä¼¼ï¼Œéƒ½éœ€è¦ä¸ç½‘ç»œæ´»åŠ¨çš„ç¨€ç–æ€§ç›¸ç»“åˆã€‚\nMemory footprint Due to space volume constraints of iBCIs, the memory size, which in comparison to other function blocks consumes far more ASIC area, should be reported. If the memory requirements of the neural decoder are too large, external memory is required, which can consume more than 100Ã— more energy than on-chip memory. Estimating the memory footprint of a neural decoder involves calculating the sum of the networkâ€™s parameters and variables, as well as the memory requirements of input data from binning windows. The memory size should be reported in bits to provide credit to architectures that limit the precision of weights.\nç”±äº iBCI çš„ç©ºé—´ä½“ç§¯é™åˆ¶ï¼Œå†…å­˜å¤§å°åº”äºˆä»¥æŠ¥å‘Šï¼Œå› ä¸ºä¸å…¶ä»–åŠŸèƒ½å—ç›¸æ¯”ï¼Œå®ƒæ¶ˆè€—äº†æ›´å¤šçš„ ASIC é¢ç§¯ã€‚å¦‚æœç¥ç»è§£ç å™¨çš„å†…å­˜éœ€æ±‚è¿‡å¤§ï¼Œåˆ™éœ€è¦å¤–éƒ¨å†…å­˜ï¼Œå…¶èƒ½è€—å¯èƒ½è¶…è¿‡ç‰‡ä¸Šå†…å­˜çš„ 100 å€ã€‚ä¼°è®¡ç¥ç»è§£ç å™¨çš„å†…å­˜å ç”¨æ¶‰åŠè®¡ç®—ç½‘ç»œå‚æ•°å’Œå˜é‡çš„æ€»å’Œï¼Œä»¥åŠæ¥è‡ªåˆ†ç®±çª—å£çš„è¾“å…¥æ•°æ®çš„å†…å­˜éœ€æ±‚ã€‚å†…å­˜å¤§å°åº”ä»¥ä½ä¸ºå•ä½æŠ¥å‘Šï¼Œä»¥è¡¨å½°é™åˆ¶æƒé‡ç²¾åº¦çš„æ¶æ„ã€‚\nMethods The methodology is structured into five subsections, addressing how this study evaluates and benchmarks various neural decoders within the context of iBCI for CLN. The first subsection provides an overview of the neural data utilized in this benchmark, which comprises neural activity recorded from non-human primates, representing a relevant scenario for closed-loop iBCI applications. Decoders are categorized into three main groups: traditional neural decoders, artificial neural networks (ANN)-based neural decoders, and neuromorphic spiking neural network (SNN)-based decoders. The selection of traditional and ANN decoders was based on existing literature, while the long short-term memory (LSTM) and SNN-based decoders were optimized for this study. The presented decoders are non-exhaustive (the interested reader is referred to recently proposed models), yet the decoders aim to represent commonly used neural decoding methods. The final subsection outlines the experimental setup and details the conditions and parameters under which the benchmark was conducted. These methodological components provide a detailed pipeline for evaluating neural decoding methods for closed-loop iBCI applications.\nè¯¥æ–¹æ³•åˆ†ä¸ºäº”ä¸ªå­éƒ¨åˆ†ï¼Œè§£å†³äº†æœ¬ç ”ç©¶å¦‚ä½•åœ¨ CLN çš„ iBCI èƒŒæ™¯ä¸‹è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•å„ç§ç¥ç»è§£ç å™¨ã€‚ç¬¬ä¸€ä¸ªå­éƒ¨åˆ†æ¦‚è¿°äº†æœ¬åŸºå‡†æµ‹è¯•ä¸­ä½¿ç”¨çš„ç¥ç»æ•°æ®ï¼Œè¿™äº›æ•°æ®åŒ…æ‹¬ä»éäººç±»çµé•¿ç±»åŠ¨ç‰©è®°å½•çš„ç¥ç»æ´»åŠ¨ï¼Œä»£è¡¨äº†é—­ç¯ iBCI åº”ç”¨çš„ç›¸å…³åœºæ™¯ã€‚è§£ç å™¨åˆ†ä¸ºä¸‰å¤§ç±»ï¼šä¼ ç»Ÿç¥ç»è§£ç å™¨ã€åŸºäºäººå·¥ç¥ç»ç½‘ç»œ (ANN) çš„ç¥ç»è§£ç å™¨å’ŒåŸºäºç¥ç»å½¢æ€è„‰å†²ç¥ç»ç½‘ç»œ (SNN) çš„è§£ç å™¨ã€‚ä¼ ç»Ÿå’Œ ANN è§£ç å™¨çš„é€‰æ‹©åŸºäºç°æœ‰æ–‡çŒ®ï¼Œè€Œé•¿çŸ­æœŸè®°å¿† (LSTM) å’Œ SNN åŸºè§£ç å™¨åˆ™é’ˆå¯¹æœ¬ç ”ç©¶è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ‰€å‘ˆç°çš„è§£ç å™¨å¹¶éè¯¦å°½æ— é—ï¼ˆæœ‰å…´è¶£çš„è¯»è€…å¯å‚è€ƒæœ€è¿‘æå‡ºçš„æ¨¡å‹ï¼‰ï¼Œä½†è¿™äº›è§£ç å™¨æ—¨åœ¨ä»£è¡¨å¸¸ç”¨çš„ç¥ç»è§£ç æ–¹æ³•ã€‚æœ€åä¸€ä¸ªå­éƒ¨åˆ†æ¦‚è¿°äº†å®éªŒè®¾ç½®ï¼Œå¹¶è¯¦ç»†è¯´æ˜äº†è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„æ¡ä»¶å’Œå‚æ•°ã€‚è¿™äº›æ–¹æ³•è®ºç»„ä»¶ä¸ºè¯„ä¼°é—­ç¯ iBCI åº”ç”¨çš„ç¥ç»è§£ç æ–¹æ³•æä¾›äº†è¯¦ç»†çš„æµç¨‹ã€‚\nNeural recording dataset The ANN and SNN neural decoders were trained and benchmarked on the â€˜primate reaching taskâ€™ of the neuromorphic benchmark NeuroBench, as visualized in figures 3(a) and (b). This benchmark employs the same data as Makin et al, which previously were used to evaluate their traditional decoders. The $R^{2}$ value published by Makin et al is reported here, and the metrics for power consumption and latency are calculated conservatively based on the most time-consuming and energy-intensive matrix operations, as defined in Chapters 4.2 and Chapter 4.3.\nANN å’Œ SNN ç¥ç»è§£ç å™¨åœ¨ç¥ç»å½¢æ€åŸºå‡† NeuroBench çš„â€œçµé•¿ç±»åŠ¨ç‰©ä¼¸æ‰‹ä»»åŠ¡â€ä¸Šè¿›è¡Œäº†è®­ç»ƒå’ŒåŸºå‡†æµ‹è¯•ï¼Œå¦‚å›¾ 3(a) å’Œ (b) æ‰€ç¤ºã€‚è¯¥åŸºå‡†æµ‹è¯•ä½¿ç”¨ä¸ Makin ç­‰äººç›¸åŒçš„æ•°æ®ï¼Œä¹‹å‰ç”¨äºè¯„ä¼°ä»–ä»¬çš„ä¼ ç»Ÿè§£ç å™¨ã€‚è¿™é‡ŒæŠ¥å‘Šäº† Makin ç­‰äººå‘å¸ƒçš„ $R^{2}$ å€¼ï¼Œå¹¶æ ¹æ®ç¬¬ 4.2 ç« å’Œç¬¬ 4.3 ç« ä¸­å®šä¹‰çš„æœ€è€—æ—¶å’Œæœ€è€—èƒ½çš„çŸ©é˜µæ“ä½œï¼Œä¿å®ˆåœ°è®¡ç®—äº†åŠŸè€—å’Œå»¶è¿Ÿçš„æŒ‡æ ‡ã€‚\nThe dataset is a subset of 6 out of 33 recording sessions of 2 Rhesus primates during subsequent reaching tasks as shown in figure 3(a), which was released by Dyer et al. These sessions encompassed two non-human primates (NHPs) and the entire recording period. Three NHP â€˜Iâ€™ sessions were recorded using a 96-channel Utah array from Blackrock Neurotech implanted in the primary motor cortex. The three NHP â€˜Lâ€™ sessions had an additional Utah array in the sensorimotor cortex, enabling the simultaneous recording of 192 channels. Each recording session comprises 354â€“819 individual reaches, and those longer than 8 s were discarded as they indicate the primateâ€™s inattention.\nè¯¥æ•°æ®é›†æ˜¯ Dyer ç­‰äººå‘å¸ƒçš„ 2 åªæ’æ²³çŒ´åœ¨éšåçš„ä¼¸æ‰‹ä»»åŠ¡æœŸé—´çš„ 33 ä¸ªè®°å½•ä¼šè¯ä¸­çš„ 6 ä¸ªå­é›†ï¼Œå¦‚å›¾ 3(a) æ‰€ç¤ºã€‚è¿™äº›ä¼šè¯æ¶µç›–äº†ä¸¤åªéäººç±»çµé•¿ç±»åŠ¨ç‰© (NHPs) å’Œæ•´ä¸ªè®°å½•æœŸã€‚ä¸‰æ¬¡ NHPâ€œIâ€ä¼šè¯ä½¿ç”¨ Blackrock Neurotech æ¤å…¥åˆçº§è¿åŠ¨çš®å±‚çš„ 96 é€šé“ Utah é˜µåˆ—è¿›è¡Œè®°å½•ã€‚ä¸‰æ¬¡ NHPâ€œLâ€ä¼šè¯åœ¨æ„Ÿè§‰è¿åŠ¨çš®å±‚ä¸­å¢åŠ äº†ä¸€ä¸ª Utah é˜µåˆ—ï¼Œå®ç°äº† 192 é€šé“çš„åŒæ—¶è®°å½•ã€‚æ¯ä¸ªè®°å½•ä¼šè¯åŒ…æ‹¬ 354-819 æ¬¡å•ç‹¬çš„ä¼¸æ‰‹åŠ¨ä½œï¼Œè¶…è¿‡ 8 ç§’çš„åŠ¨ä½œè¢«ä¸¢å¼ƒï¼Œå› ä¸ºå®ƒä»¬è¡¨æ˜çµé•¿ç±»åŠ¨ç‰©ä¸ä¸“å¿ƒã€‚\nSpikes were detected from the raw neural data using a threshold of 3.5â€“4 times the root-mean-square (RMS) noise. The finger position was recorded using an electromagnetic position sensor at 250 Hz, and the velocity was computed as the discrete gradient of the position. Predicting the translation invariant finger velocity better aligns with the natural dynamics of limb movements and corresponds to how neural activity encodes kinematics. Makin et al, and Dyer et al report the detailed experimental setup and the data acquisition.\nä»åŸå§‹ç¥ç»æ•°æ®ä¸­ä½¿ç”¨ 3.5-4 å€å‡æ–¹æ ¹ (RMS) å™ªå£°çš„é˜ˆå€¼æ£€æµ‹è„‰å†²ã€‚æ‰‹æŒ‡ä½ç½®ä½¿ç”¨ç”µç£ä½ç½®ä¼ æ„Ÿå™¨ä»¥ 250 Hz çš„é¢‘ç‡è®°å½•ï¼Œå¹¶è®¡ç®—ä¸ºä½ç½®çš„ç¦»æ•£æ¢¯åº¦ã€‚é¢„æµ‹å¹³ç§»ä¸å˜çš„æ‰‹æŒ‡é€Ÿåº¦æ›´å¥½åœ°ç¬¦åˆè‚¢ä½“è¿åŠ¨çš„è‡ªç„¶åŠ¨æ€ï¼Œå¹¶ä¸”ä¸ç¥ç»æ´»åŠ¨å¦‚ä½•ç¼–ç è¿åŠ¨å­¦ç›¸å¯¹åº”ã€‚Makin ç­‰äººå’Œ Dyer ç­‰äººæŠ¥å‘Šäº†è¯¦ç»†çš„å®éªŒè®¾ç½®å’Œæ•°æ®é‡‡é›†ã€‚\nTraditional neural decoders Classic neural decoding methods have been extensively used in brain-computer interfacing. Of the six decoders Makin et al presented, the three best-performing models were selected to represent traditional neural decoders. Those decoders are the â€˜unscentedâ€™ Kalman Filter (UKF), the static, and the dynamic â€˜recurrent exponential-family harmoniumâ€™ (rEFH), and they are evaluated due to their established performance and versatility in handling various neural data modalities. Makin et al also considered linear regression, conventional KF, and Wiener filter. However, since these decoders had worse $R^{2}$ performance and scaled poorly with decreasing binning windows, they were not considered suitable for this neural decoding benchmark for closed-loop iBCIs suitable for CLN.\nç»å…¸ç¥ç»è§£ç æ–¹æ³•å·²è¢«å¹¿æ³›ç”¨äºè„‘æœºæ¥å£ã€‚åœ¨ Makin ç­‰äººæå‡ºçš„å…­ç§è§£ç å™¨ä¸­ï¼Œé€‰æ‹©äº†è¡¨ç°æœ€å¥½çš„ä¸‰ç§æ¨¡å‹æ¥ä»£è¡¨ä¼ ç»Ÿç¥ç»è§£ç å™¨ã€‚è¿™äº›è§£ç å™¨æ˜¯â€œæ— è¿¹â€å¡å°”æ›¼æ»¤æ³¢å™¨ (UKF)ã€é™æ€å’ŒåŠ¨æ€â€œé€’å½’æŒ‡æ•°æ—è°æŒ¯å™¨â€ (rEFH)ï¼Œç”±äºå…¶åœ¨å¤„ç†å„ç§ç¥ç»æ•°æ®æ¨¡æ€æ–¹é¢çš„æ—¢å®šæ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§è€Œè¿›è¡Œè¯„ä¼°ã€‚Makin ç­‰äººè¿˜è€ƒè™‘äº†çº¿æ€§å›å½’ã€ä¼ ç»Ÿ KF å’Œ Wiener æ»¤æ³¢å™¨ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›è§£ç å™¨çš„ $R^{2}$ æ€§èƒ½è¾ƒå·®ï¼Œå¹¶ä¸”éšç€åˆ†ç®±çª—å£çš„å‡å°è€Œæ‰©å±•æ€§å·®ï¼Œå› æ­¤å®ƒä»¬ä¸é€‚åˆç”¨äºé€‚ç”¨äº CLN çš„é—­ç¯ iBCI çš„ç¥ç»è§£ç åŸºå‡†æµ‹è¯•ã€‚\nThe UKF approximates the state distribution by applying a full nonlinearity to a minimal set of carefully selected representative points. It was designed as an extension of the KF to address the problem of its exploding residuals on the true posterior mean and covariance. The UKF solves this by replacing the normal sampled state distribution with a deterministic sampling of this distribution. The UKF, as described by Makin et al and Wan et al, has a state space of deterministically sampled 40 variables, which requires $O (n^3/6)$ operations due to Cholesky decomposition. As a conservative estimate of the processing latency and the operational cost, only matrix multiplications required during inference and the computationally intensive matrix inversion were considered. This large-scale matrix inversion was assumed to require at least 200 ms.\nUKF é€šè¿‡å¯¹ç²¾å¿ƒé€‰æ‹©çš„ä»£è¡¨ç‚¹é›†åº”ç”¨å®Œæ•´çš„éçº¿æ€§æ¥è¿‘ä¼¼çŠ¶æ€åˆ†å¸ƒã€‚å®ƒè¢«è®¾è®¡ä¸º KF çš„æ‰©å±•ï¼Œä»¥è§£å†³å…¶åœ¨çœŸå®åéªŒå‡å€¼å’Œåæ–¹å·®ä¸Šçš„æ®‹å·®çˆ†ç‚¸é—®é¢˜ã€‚UKF é€šè¿‡ç”¨è¯¥åˆ†å¸ƒçš„ç¡®å®šæ€§é‡‡æ ·æ›¿æ¢æ­£å¸¸é‡‡æ ·çš„çŠ¶æ€åˆ†å¸ƒæ¥è§£å†³æ­¤é—®é¢˜ã€‚æ­£å¦‚ Makin ç­‰äººå’Œ Wan ç­‰äººæ‰€æè¿°çš„é‚£æ ·ï¼ŒUKF å…·æœ‰ç¡®å®šæ€§é‡‡æ ·çš„ 40 ä¸ªå˜é‡çš„çŠ¶æ€ç©ºé—´ï¼Œç”±äº Cholesky åˆ†è§£éœ€è¦ $O (n^3/6)$ æ“ä½œã€‚ä½œä¸ºå¤„ç†å»¶è¿Ÿå’Œæ“ä½œæˆæœ¬çš„ä¿å®ˆä¼°è®¡ï¼Œä»…è€ƒè™‘äº†æ¨ç†è¿‡ç¨‹ä¸­æ‰€éœ€çš„çŸ©é˜µä¹˜æ³•å’Œè®¡ç®—å¯†é›†å‹çŸ©é˜µæ±‚é€†ã€‚å‡è®¾è¿™ç§å¤§è§„æ¨¡çŸ©é˜µæ±‚é€†è‡³å°‘éœ€è¦ 200 æ¯«ç§’ã€‚\nThe rEFH, instead of assuming Gaussian state variables, models the state variables as a variant of a restricted Boltzmann Machine (RBM) and explicitly samples the spike count from a Poisson distribution. The static variant converts the latent space of the RBM into kinematics via static mapping, that is, a matrix multiplication, whereas the dynamic version uses a KF. For the static and the dynamic rEFH models, only the forward pass of the RBM uses higher-dimensional matrix multiplications, and thus is considered. There are four times as many hidden neurons in the RBM than there are input channels and 1800 output neurons mapped to the kinematic output via either a matrix multiplication or a KF. All traditional decoders were evaluated using binning windows of 16 ms, 32 ms, 64 ms, and 128 ms.\nrEFH ä¸å‡è®¾é«˜æ–¯çŠ¶æ€å˜é‡ï¼Œè€Œæ˜¯å°†çŠ¶æ€å˜é‡å»ºæ¨¡ä¸ºå—é™ç»å°”å…¹æ›¼æœº (RBM) çš„å˜ä½“ï¼Œå¹¶æ˜ç¡®åœ°ä»æ³Šæ¾åˆ†å¸ƒä¸­é‡‡æ ·è„‰å†²è®¡æ•°ã€‚é™æ€å˜ä½“é€šè¿‡é™æ€æ˜ å°„ï¼ˆå³çŸ©é˜µä¹˜æ³•ï¼‰å°† RBM çš„æ½œåœ¨ç©ºé—´è½¬æ¢ä¸ºè¿åŠ¨å­¦ï¼Œè€ŒåŠ¨æ€ç‰ˆæœ¬åˆ™ä½¿ç”¨ KFã€‚å¯¹äºé™æ€å’ŒåŠ¨æ€ rEFH æ¨¡å‹ï¼Œä»… RBM çš„å‰å‘ä¼ é€’ä½¿ç”¨æ›´é«˜ç»´çš„çŸ©é˜µä¹˜æ³•ï¼Œå› æ­¤äºˆä»¥è€ƒè™‘ã€‚RBM ä¸­çš„éšè—ç¥ç»å…ƒæ•°é‡æ˜¯è¾“å…¥é€šé“æ•°é‡çš„å››å€ï¼Œ1800 ä¸ªè¾“å‡ºç¥ç»å…ƒé€šè¿‡çŸ©é˜µä¹˜æ³•æˆ– KF æ˜ å°„åˆ°è¿åŠ¨å­¦è¾“å‡ºã€‚æ‰€æœ‰ä¼ ç»Ÿè§£ç å™¨å‡ä½¿ç”¨ 16 æ¯«ç§’ã€32 æ¯«ç§’ã€64 æ¯«ç§’å’Œ 128 æ¯«ç§’çš„åˆ†ç®±çª—å£è¿›è¡Œè¯„ä¼°ã€‚\nANNs This study used two ANN-based decoders as baselines owing to their established history of high-accuracy predictions. Previous studies have demonstrated that ANN-based decoders perform on par or better than traditional decoders. One fully connected ANN, published as a baseline for the NeuroBench benchmark, and one LSTM network were evaluated.\næœ¬ç ”ç©¶ä½¿ç”¨äº†ä¸¤ä¸ªåŸºäº ANN çš„è§£ç å™¨ä½œä¸ºåŸºçº¿ï¼Œå› å…¶åœ¨é«˜ç²¾åº¦é¢„æµ‹æ–¹é¢çš„æ—¢å®šå†å²ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäº ANN çš„è§£ç å™¨çš„æ€§èƒ½ä¸ä¼ ç»Ÿè§£ç å™¨ç›¸å½“æˆ–æ›´å¥½ã€‚è¯„ä¼°äº†ä¸€ä¸ªä½œä¸º NeuroBench åŸºå‡†åŸºçº¿å‘å¸ƒçš„å…¨è¿æ¥ ANN å’Œä¸€ä¸ª LSTM ç½‘ç»œã€‚\nThe ANN is a conventional 3-layer feedforward network with 32 and 48 hidden and two output neurons, respectively. This implementation uses a history of multiple non-overlapping binning windows that are flattened and processed as input data. The default implementation, including the history of 7 binning windows, is shown in figure 4(a). To explore the latency versus fidelity trade-off, a history of 4, 7, and 14 binning windows of 28 ms was considered, and the number of neurons in the hidden layers halved and doubled.\nANN æ˜¯ä¸€ä¸ªä¼ ç»Ÿçš„ä¸‰å±‚å‰é¦ˆç½‘ç»œï¼Œåˆ†åˆ«å…·æœ‰ 32 ä¸ªå’Œ 48 ä¸ªéšè—ç¥ç»å…ƒä»¥åŠä¸¤ä¸ªè¾“å‡ºç¥ç»å…ƒã€‚è¯¥å®ç°ä½¿ç”¨å¤šä¸ªä¸é‡å åˆ†ç®±çª—å£çš„å†å²è®°å½•ï¼Œè¿™äº›çª—å£è¢«å±•å¹³å¹¶ä½œä¸ºè¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ã€‚é»˜è®¤å®ç°åŒ…æ‹¬ 7 ä¸ªåˆ†ç®±çª—å£çš„å†å²ï¼Œå¦‚å›¾ 4(a) æ‰€ç¤ºã€‚ä¸ºäº†æ¢ç´¢å»¶è¿Ÿä¸ä¿çœŸåº¦çš„æƒè¡¡ï¼Œè€ƒè™‘äº† 28 æ¯«ç§’çš„ 4ã€7 å’Œ 14 ä¸ªåˆ†ç®±çª—å£çš„å†å²è®°å½•ï¼Œå¹¶å°†éšè—å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡å‡åŠå’ŒåŠ å€ã€‚\nArchitecture of three neural network-based decoders. The data extraction and binning are visualized in red, and the network architecture in blue. Each layerâ€™s dimensions and type are stated above and below, respectively. (a) The ANN uses seven binning windows spanning 28 ms as input. These extracted windows are flattened and processed by two hidden layers with 32 and 48 Neurons, respectively. (b) The LSTM extracts spikes with a temporal resolution of 4 milliseconds, effectively representing the neural data as a spike train. Then, the data undergoes dimensionality reduction via a fully connected (FC) layer with 16 neurons, after which a long short-term memory (LSTM) cell is employed. (c) Similarly, the SNN decoder extracts the spike train and processes it through a network featuring 50 hidden Leaky Integrate-and-Fire (LIF) neurons. The final output of this network comprises the membrane potential of two LIF neurons.\nä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨çš„æ¶æ„ã€‚æ•°æ®æå–å’Œåˆ†ç®±ä»¥çº¢è‰²å¯è§†åŒ–ï¼Œç½‘ç»œæ¶æ„ä»¥è“è‰²å¯è§†åŒ–ã€‚æ¯ä¸€å±‚çš„ç»´åº¦å’Œç±»å‹åˆ†åˆ«åœ¨ä¸Šæ–¹å’Œä¸‹æ–¹è¯´æ˜ã€‚ (a) ANN ä½¿ç”¨è·¨è¶Š 28 æ¯«ç§’çš„ä¸ƒä¸ªåˆ†ç®±çª—å£ä½œä¸ºè¾“å…¥ã€‚è¿™äº›æå–çš„çª—å£è¢«å±•å¹³ï¼Œå¹¶åˆ†åˆ«ç”±ä¸¤ä¸ªå…·æœ‰ 32 å’Œ 48 ä¸ªç¥ç»å…ƒçš„éšè—å±‚å¤„ç†ã€‚ (b) LSTM ä»¥ 4 æ¯«ç§’çš„æ—¶é—´åˆ†è¾¨ç‡æå–è„‰å†²ï¼Œæœ‰æ•ˆåœ°å°†ç¥ç»æ•°æ®è¡¨ç¤ºä¸ºè„‰å†²åºåˆ—ã€‚ç„¶åï¼Œæ•°æ®é€šè¿‡å…·æœ‰ 16 ä¸ªç¥ç»å…ƒçš„å…¨è¿æ¥ (FC) å±‚è¿›è¡Œé™ç»´ï¼Œä¹‹åä½¿ç”¨é•¿çŸ­æœŸè®°å¿† (LSTM) å•å…ƒã€‚ (c) ç±»ä¼¼åœ°ï¼ŒSNN è§£ç å™¨æå–è„‰å†²åºåˆ—ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå…·æœ‰ 50 ä¸ªéšè—æ³„æ¼ç§¯åˆ†ä¸å‘æ”¾ (LIF) ç¥ç»å…ƒçš„ç½‘ç»œè¿›è¡Œå¤„ç†ã€‚è¯¥ç½‘ç»œçš„æœ€ç»ˆè¾“å‡ºåŒ…æ‹¬ä¸¤ä¸ª LIF ç¥ç»å…ƒçš„è†œç”µä½ã€‚\nThe LSTM, as shown in figure 4(b), uses a fully connected layer to reduce the input dimensionality to 16, followed by a single LSTM cell with 16 hidden neurons. A feedforward layer returns the predicted kinematics. Similar to the ANN, binning windows of 4 ms, 8 ms, and 16 ms and wider networks, with 64 and 128 hidden neurons, were examined. The networks use batch normalization (BatchNorm) and layer normalization (LayerNorm), respectively, and use Dropout.\nLSTM å¦‚å›¾ 4(b) æ‰€ç¤ºï¼Œä½¿ç”¨å…¨è¿æ¥å±‚å°†è¾“å…¥ç»´åº¦é™ä½åˆ° 16ï¼Œéšåæ˜¯ä¸€ä¸ªå…·æœ‰ 16 ä¸ªéšè—ç¥ç»å…ƒçš„å•ä¸ª LSTM å•å…ƒã€‚ä¸€ä¸ªå‰é¦ˆå±‚è¿”å›é¢„æµ‹çš„è¿åŠ¨å­¦ã€‚ä¸ ANN ç±»ä¼¼ï¼Œæ£€æŸ¥äº† 4 æ¯«ç§’ã€8 æ¯«ç§’å’Œ 16 æ¯«ç§’çš„åˆ†ç®±çª—å£ä»¥åŠå…·æœ‰ 64 å’Œ 128 ä¸ªéšè—ç¥ç»å…ƒçš„æ›´å®½ç½‘ç»œã€‚ç½‘ç»œåˆ†åˆ«ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ– (BatchNorm) å’Œå±‚å½’ä¸€åŒ– (LayerNorm)ï¼Œå¹¶ä½¿ç”¨ Dropoutã€‚\nSNN SNNs are a variant of neural networks that attempt to mimic the properties, processes, and functions of biological neurons. This makes them inherently recurrent and allows them to exploit sparsity to achieve lower latency and power consumption. SNNs, at their core consist of stateful spiking neurons, a more bio-plausible variant of the Perceptron, with the leaky integrate-and-fire (LIF) being the most widely used neuron model. As the Perceptron, the LIF weighs and accumulates the input, but instead of returning this weighted accumulation, it is added to the neuronâ€™s membrane potential. If the membrane potential exceeds a threshold, the neuron produces a binary output, that is, a spike, and the membrane potential is reset; otherwise, it decays per time step, as conceptually illustrated in figure 5. This enables the neuron to combine information over multiple time steps, making it inherently recurrent. In addition to their binary output, LIF neurons exploit binary input data, enabling sparsity in networks built around these neurons. The binary input separates the operations into effective and ineffective because multiplications by zero do not contribute to the accumulation. Therefore, the multiplication of weights times input can be forgone by adding only non-zero weights.\nSNN æ˜¯ç¥ç»ç½‘ç»œçš„ä¸€ç§å˜ä½“ï¼Œè¯•å›¾æ¨¡ä»¿ç”Ÿç‰©ç¥ç»å…ƒçš„å±æ€§ã€è¿‡ç¨‹å’ŒåŠŸèƒ½ã€‚è¿™ä½¿å®ƒä»¬æœ¬è´¨ä¸Šæ˜¯é€’å½’çš„ï¼Œå¹¶å…è®¸å®ƒä»¬åˆ©ç”¨ç¨€ç–æ€§æ¥å®ç°æ›´ä½çš„å»¶è¿Ÿå’ŒåŠŸè€—ã€‚SNN çš„æ ¸å¿ƒç”±æœ‰çŠ¶æ€çš„è„‰å†²ç¥ç»å…ƒç»„æˆï¼Œè¿™æ˜¯ä¸€ç§æ›´ç¬¦åˆç”Ÿç‰©å­¦çš„æ„ŸçŸ¥å™¨å˜ä½“ï¼Œå…¶ä¸­æ³„æ¼ç§¯åˆ†ä¸å‘æ”¾ (LIF) æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„ç¥ç»å…ƒæ¨¡å‹ã€‚ä¸æ„ŸçŸ¥å™¨ä¸€æ ·ï¼ŒLIF å¯¹è¾“å…¥è¿›è¡ŒåŠ æƒå’Œç´¯ç§¯ï¼Œä½†ä¸æ˜¯è¿”å›è¿™ç§åŠ æƒç´¯ç§¯ï¼Œè€Œæ˜¯å°†å…¶æ·»åŠ åˆ°ç¥ç»å…ƒçš„è†œç”µä½ä¸­ã€‚å¦‚æœè†œç”µä½è¶…è¿‡é˜ˆå€¼ï¼Œç¥ç»å…ƒä¼šäº§ç”ŸäºŒè¿›åˆ¶è¾“å‡ºï¼Œå³è„‰å†²ï¼Œå¹¶ä¸”è†œç”µä½ä¼šè¢«é‡ç½®ï¼›å¦åˆ™ï¼Œå®ƒä¼šéšç€æ—¶é—´æ­¥é•¿è€Œè¡°å‡ï¼Œå¦‚å›¾ 5 æ‰€ç¤ºçš„æ¦‚å¿µæ€§è¯´æ˜ã€‚è¿™ä½¿å¾—ç¥ç»å…ƒèƒ½å¤Ÿåœ¨å¤šä¸ªæ—¶é—´æ­¥é•¿ä¸Šç»“åˆä¿¡æ¯ï¼Œä½¿å…¶æœ¬è´¨ä¸Šæ˜¯é€’å½’çš„ã€‚é™¤äº†å®ƒä»¬çš„äºŒè¿›åˆ¶è¾“å‡ºå¤–ï¼ŒLIF ç¥ç»å…ƒè¿˜åˆ©ç”¨äºŒè¿›åˆ¶è¾“å…¥æ•°æ®ï¼Œä½¿å›´ç»•è¿™äº›ç¥ç»å…ƒæ„å»ºçš„ç½‘ç»œå…·æœ‰ç¨€ç–æ€§ã€‚äºŒè¿›åˆ¶è¾“å…¥å°†æ“ä½œåˆ†ä¸ºæœ‰æ•ˆå’Œæ— æ•ˆï¼Œå› ä¸ºä¹˜ä»¥é›¶ä¸ä¼šå¯¹ç´¯ç§¯äº§ç”Ÿè´¡çŒ®ã€‚å› æ­¤ï¼Œå¯ä»¥é€šè¿‡ä»…æ·»åŠ éé›¶æƒé‡æ¥çœç•¥æƒé‡ä¹˜ä»¥è¾“å…¥çš„ä¹˜æ³•ã€‚\nA scheme of the LIF neuron. In this neuron model, incoming neural signals are integrated into the membrane potential, and if the accumulated value surpasses a specified threshold, the neuron generates a binary output signal. The â€˜leakyâ€™ property allows for the gradual decay of the accumulated charge, further contributing to the modelâ€™s simplicity. The intrinsic recurrent nature of the LIF neuron originates in the updated membrane potential.\nLIF ç¥ç»å…ƒçš„ç¤ºæ„å›¾ã€‚åœ¨è¿™ç§ç¥ç»å…ƒæ¨¡å‹ä¸­ï¼Œä¼ å…¥çš„ç¥ç»ä¿¡å·è¢«æ•´åˆåˆ°è†œç”µä½ä¸­ï¼Œå¦‚æœç´¯ç§¯å€¼è¶…è¿‡æŒ‡å®šçš„é˜ˆå€¼ï¼Œç¥ç»å…ƒä¼šäº§ç”ŸäºŒè¿›åˆ¶è¾“å‡ºä¿¡å·ã€‚â€œæ³„æ¼â€å±æ€§å…è®¸ç´¯ç§¯ç”µè·é€æ¸è¡°å‡ï¼Œè¿›ä¸€æ­¥æœ‰åŠ©äºæ¨¡å‹çš„ç®€åŒ–ã€‚LIF ç¥ç»å…ƒçš„å†…åœ¨é€’å½’æ€§è´¨æºäºæ›´æ–°çš„è†œç”µä½ã€‚\nThe implemented neuromorphic SNN decoder is a simplified version of the model proposed by Liao et al with fewer learnable parameters. In a preliminary exploration, reducing the complexity of the network only marginally impacted the accuracy while significantly improving the operational cost. Each hidden layer is decreased to 50 LIF-neurons without a bias term and a fixed decay ($\\tau = 0.96$). The BatchNorm layer is removed because combining BatchNorm and Dropout leads to models with different feature variances inside the network during training and testing. The threshold of the LIF neurons is set to one. To further push for lower latency and power consumption and explore the various tradeoffs against accuracy, the number of hidden layers is decreased from three to two and one (SNN3, SNN2, and SNN1, respectively). SNN1 is a baseline model for the â€˜primate reaching taskâ€™ of NeuroBench and is depicted in figure 4(c).\næ‰€å®ç°çš„ç¥ç»å½¢æ€ SNN è§£ç å™¨æ˜¯ Liao ç­‰äººæå‡ºçš„æ¨¡å‹çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå…·æœ‰æ›´å°‘çš„å¯å­¦ä¹ å‚æ•°ã€‚åœ¨åˆæ­¥æ¢ç´¢ä¸­ï¼Œå‡å°‘ç½‘ç»œçš„å¤æ‚æ€§ä»…å¯¹å‡†ç¡®æ€§äº§ç”Ÿäº†è¾¹é™…å½±å“ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†æ“ä½œæˆæœ¬ã€‚æ¯ä¸ªéšè—å±‚å‡å°‘åˆ° 50 ä¸ªæ²¡æœ‰åç½®é¡¹ä¸”å…·æœ‰å›ºå®šè¡°å‡ ($\\tau = 0.96$) çš„ LIF ç¥ç»å…ƒã€‚åˆ é™¤äº† BatchNorm å±‚ï¼Œå› ä¸ºå°† BatchNorm å’Œ Dropout ç»“åˆä¼šå¯¼è‡´è®­ç»ƒå’Œæµ‹è¯•æœŸé—´ç½‘ç»œå†…éƒ¨å…·æœ‰ä¸åŒç‰¹å¾æ–¹å·®çš„æ¨¡å‹ã€‚LIF ç¥ç»å…ƒçš„é˜ˆå€¼è®¾ç½®ä¸º 1ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¨åŠ¨æ›´ä½çš„å»¶è¿Ÿå’ŒåŠŸè€—ï¼Œå¹¶æ¢ç´¢ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å„ç§æƒè¡¡ï¼Œå°†éšè—å±‚çš„æ•°é‡ä»ä¸‰ä¸ªå‡å°‘åˆ°ä¸¤ä¸ªå’Œä¸€ä¸ªï¼ˆåˆ†åˆ«ä¸º SNN3ã€SNN2 å’Œ SNN1ï¼‰ã€‚SNN1 æ˜¯ NeuroBench â€œçµé•¿ç±»åŠ¨ç‰©ä¼¸æ‰‹ä»»åŠ¡â€ çš„åŸºçº¿æ¨¡å‹ï¼Œå¦‚å›¾ 4(c) æ‰€ç¤ºã€‚\nExperimental setup The spike train was binned according to the window requirements of the respective network, and a sliding window with a stride of 4 ms extracted the spiking data. The RNNs and the SNNs used a sliding window of 50 bins to extract temporal information from the data and the non-recurrent ANNs extracted the bins individually. The neural decoders were trained to predict the finger velocity as visualized in figure 3.\nè„‰å†²åºåˆ—æ ¹æ®å„è‡ªç½‘ç»œçš„çª—å£è¦æ±‚è¿›è¡Œåˆ†ç®±ï¼Œå¹¶ä½¿ç”¨æ­¥å¹…ä¸º 4 æ¯«ç§’çš„æ»‘åŠ¨çª—å£æå–è„‰å†²æ•°æ®ã€‚RNN å’Œ SNN ä½¿ç”¨ 50 ä¸ªåˆ†ç®±çš„æ»‘åŠ¨çª—å£ä»æ•°æ®ä¸­æå–æ—¶é—´ä¿¡æ¯ï¼Œè€Œéé€’å½’ ANN åˆ™å•ç‹¬æå–åˆ†ç®±ã€‚ç¥ç»è§£ç å™¨ç»è¿‡è®­ç»ƒä»¥é¢„æµ‹å›¾ 3 ä¸­æ‰€ç¤ºçš„æ‰‹æŒ‡é€Ÿåº¦ã€‚\nRNNs and SNNs notoriously suffer from difficulties when learning long-term dependencies from data. To improve the gradient flow, the SNN was trained to predict the time window of the primateâ€™s finger kinematics and, for consistency, was tested to predict individual finger velocities as the ANNs. The Loss for this setup was a linearly weighted mean squared error (MSE) from zero to one to account for warm-up steps. The ANN and LSTM were trained using the conventional MSE Loss.\nRNN å’Œ SNN åœ¨ä»æ•°æ®ä¸­å­¦ä¹ é•¿æœŸä¾èµ–å…³ç³»æ—¶è‡­åæ˜­è‘—åœ°å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†æ”¹å–„æ¢¯åº¦æµï¼ŒSNN è¢«è®­ç»ƒä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©æ‰‹æŒ‡è¿åŠ¨å­¦çš„æ—¶é—´çª—å£ï¼Œå¹¶ä¸”ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œåƒ ANN ä¸€æ ·æµ‹è¯•ä»¥é¢„æµ‹å•ä¸ªæ‰‹æŒ‡é€Ÿåº¦ã€‚è¯¥è®¾ç½®çš„æŸå¤±æ˜¯ä»é›¶åˆ°ä¸€çš„çº¿æ€§åŠ æƒå‡æ–¹è¯¯å·® (MSE)ï¼Œä»¥è€ƒè™‘é¢„çƒ­æ­¥éª¤ã€‚ANN å’Œ LSTM ä½¿ç”¨ä¼ ç»Ÿçš„ MSE æŸå¤±è¿›è¡Œè®­ç»ƒã€‚\nEach session was divided into the first 75% of the reaches shuffled and, in contrast to the Neurobench-proposed evaluation pipeline, was used for model selection using 10-fold group cross-validation with early stopping and the last 25% for testing. This allows for finding the optimal hyperparameters and the number of training epochs while reporting more robust performance.\næ¯ä¸ªä¼šè¯è¢«åˆ’åˆ†ä¸ºå‰ 75% çš„ä¼¸æ‰‹åŠ¨ä½œè¿›è¡Œæ´—ç‰Œï¼Œå¹¶ä¸ Neurobench æå‡ºçš„è¯„ä¼°æµç¨‹å½¢æˆå¯¹æ¯”ï¼Œç”¨äºä½¿ç”¨ 10 æŠ˜ç»„äº¤å‰éªŒè¯å’Œæå‰åœæ­¢è¿›è¡Œæ¨¡å‹é€‰æ‹©ï¼Œæœ€å 25% ç”¨äºæµ‹è¯•ã€‚è¿™å…è®¸æ‰¾åˆ°æœ€ä½³çš„è¶…å‚æ•°å’Œè®­ç»ƒå‘¨æœŸæ•°ï¼ŒåŒæ—¶æŠ¥å‘Šæ›´ç¨³å¥çš„æ€§èƒ½ã€‚\nResults We considered six decoders trained on reconstructing a primateâ€™s finger velocity given binned neural activity with metrics that allow assessing a decoderâ€™s latency and power consumption. The results in table 2 offer a complete overview of the performance of all decoders. The performance of the decoders is in line with previous literature given the reduced dataset, different training paradigms and different metrics.\næˆ‘ä»¬è€ƒè™‘äº†å…­ç§è§£ç å™¨ï¼Œè¿™äº›è§£ç å™¨ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥æ ¹æ®åˆ†ç®±çš„ç¥ç»æ´»åŠ¨é‡å»ºçµé•¿ç±»åŠ¨ç‰©çš„æ‰‹æŒ‡é€Ÿåº¦ï¼Œå¹¶å…·æœ‰å…è®¸è¯„ä¼°è§£ç å™¨å»¶è¿Ÿå’ŒåŠŸè€—çš„æŒ‡æ ‡ã€‚è¡¨ 2 ä¸­çš„ç»“æœæä¾›äº†æ‰€æœ‰è§£ç å™¨æ€§èƒ½çš„å®Œæ•´æ¦‚è¿°ã€‚é‰´äºæ•°æ®é›†çš„å‡å°‘ã€ä¸åŒçš„è®­ç»ƒèŒƒå¼å’Œä¸åŒçš„æŒ‡æ ‡ï¼Œè§£ç å™¨çš„æ€§èƒ½ä¸å…ˆå‰çš„æ–‡çŒ®ä¸€è‡´ã€‚\nLatency vs. fidelity A higher $R^2$ performance can typically be achieved using deeper and more complex architectures or by better estimating the neural firing rate with a longer binning window. Both approaches negatively impact the latency and, thus, the capability of the neural decoder to facilitate real-time closed-loop feedback. The performance tradeoff of the six decoders is visualized in figure 6.\né€šå¸¸å¯ä»¥ä½¿ç”¨æ›´æ·±å’Œæ›´å¤æ‚çš„æ¶æ„æˆ–é€šè¿‡æ›´é•¿çš„åˆ†ç®±çª—å£æ›´å¥½åœ°ä¼°è®¡ç¥ç»å‘æ”¾ç‡æ¥å®ç°æ›´é«˜çš„ $R^2$ æ€§èƒ½ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½ä¼šå¯¹å»¶è¿Ÿäº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä»è€Œå½±å“ç¥ç»è§£ç å™¨ä¿ƒè¿›å®æ—¶é—­ç¯åé¦ˆçš„èƒ½åŠ›ã€‚å…­ç§è§£ç å™¨çš„æ€§èƒ½æƒè¡¡å¦‚å›¾ 6 æ‰€ç¤ºã€‚\nThe accuracy versus latency trade-off of the six evaluated decoders. The R2 fidelity is plotted on the horizontal axis, and the vertical axis is the millisecond latency. In the plot, traditional decoders are represented as squares, artificial neural network-based decoders as triangles, and spiking neural networks (SNNs) as circles. The decoders with the best trade-off are in the bottom right corner. Recurrent decoders such as LSTM and SNN achieve substantially lower latency while maintaining competitive accuracy.\nå…­ç§è¯„ä¼°è§£ç å™¨çš„å‡†ç¡®æ€§ä¸å»¶è¿Ÿæƒè¡¡ã€‚æ°´å¹³è½´ä¸Šç»˜åˆ¶äº† $R^2$ ä¿çœŸåº¦ï¼Œå‚ç›´è½´ä¸ºæ¯«ç§’å»¶è¿Ÿã€‚åœ¨å›¾ä¸­ï¼Œä¼ ç»Ÿè§£ç å™¨è¡¨ç¤ºä¸ºæ–¹å—ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œçš„è§£ç å™¨è¡¨ç¤ºä¸ºä¸‰è§’å½¢ï¼Œè„‰å†²ç¥ç»ç½‘ç»œ (SNN) è¡¨ç¤ºä¸ºåœ†åœˆã€‚å…·æœ‰æœ€ä½³æƒè¡¡çš„è§£ç å™¨ä½äºå³ä¸‹è§’ã€‚è¯¸å¦‚ LSTM å’Œ SNN ä¹‹ç±»çš„é€’å½’è§£ç å™¨åœ¨ä¿æŒç«äº‰åŠ›çš„å‡†ç¡®æ€§çš„åŒæ—¶å®ç°äº†æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿã€‚\nThe UKF requires computationally intense matrix operations and a matrix inverse, making it significantly slower than the other decoders and achieving lower fidelity. Contrary to the rEFH filters, the $R^2$ score improved with decreasing binning windows. The best-performing rEFH filter had an $R^2$ of 63.19% (std = 0.17) with a latency of 129 ms, significantly outperforming the UKF with an $R^2$ of 45.10% (std = 0.12) and a latency of 270 ms both in terms of fidelity and latency.\nUKF éœ€è¦è®¡ç®—å¯†é›†å‹çš„çŸ©é˜µæ“ä½œå’ŒçŸ©é˜µæ±‚é€†ï¼Œä½¿å…¶æ¯”å…¶ä»–è§£ç å™¨æ˜¾è‘—æ›´æ…¢ä¸”å®ç°è¾ƒä½çš„ä¿çœŸåº¦ã€‚ä¸ rEFH æ»¤æ³¢å™¨ç›¸åï¼Œéšç€åˆ†ç®±çª—å£çš„å‡å°ï¼Œ$R^2$ åˆ†æ•°æœ‰æ‰€æé«˜ã€‚è¡¨ç°æœ€å¥½çš„ rEFH æ»¤æ³¢å™¨çš„ $R^2$ ä¸º 63.19%ï¼ˆæ ‡å‡†å·® = 0.17ï¼‰ï¼Œå»¶è¿Ÿä¸º 129 æ¯«ç§’ï¼Œåœ¨ä¿çœŸåº¦å’Œå»¶è¿Ÿæ–¹é¢å‡æ˜¾è‘—ä¼˜äº UKFï¼Œå…¶ $R^2$ ä¸º 45.10%ï¼ˆæ ‡å‡†å·® = 0.12ï¼‰ï¼Œå»¶è¿Ÿä¸º 270 æ¯«ç§’ã€‚\nThe rEFH filters can achieve comparable $R^2$ scores to NN-based decoders. However, they require long binning windows to approximate the state distribution and experience a stark drop in the $R^2$ scores with smaller binning windows. Nevertheless, the trendlines of the rEFH and ANN models indicate that the rEFH can achieve a better latency versus fidelity tradeoff than the ANN. This stems from the ANN requiring a considerable history of binning windows to extract temporal information, which result in high latency. For the ANN, reducing the number of binning windows led to a significant decrease in fidelity. The shallow LSTM attains a much lower latency versus fidelity tradeoff than the traditional decoders and ANNs, indicated by the trendlines, achieving peak $R^2$ scores above 60% while having a latency between 4.05 ms and 16.05 ms. Notably, the fidelity drops significantly when using a longer binning window of 16 ms, indicating that the LSTM relies on the temporal dimension of the neural data to extract information about neural dynamics. The SNN achieved the best tradeoff with competitive $R^2$ scores and lower latency for all three models examined. The latency scales only marginally with an increasing number of layers.\nrEFH æ»¤æ³¢å™¨å¯ä»¥å®ç°ä¸åŸºäº NN çš„è§£ç å™¨ç›¸å½“çš„ $R^2$ åˆ†æ•°ã€‚ç„¶è€Œï¼Œå®ƒä»¬éœ€è¦è¾ƒé•¿çš„åˆ†ç®±çª—å£æ¥è¿‘ä¼¼çŠ¶æ€åˆ†å¸ƒï¼Œå¹¶ä¸”åœ¨è¾ƒå°çš„åˆ†ç®±çª—å£ä¸‹ç»å†äº† $R^2$ åˆ†æ•°çš„æ˜¾è‘—ä¸‹é™ã€‚å°½ç®¡å¦‚æ­¤ï¼ŒrEFH å’Œ ANN æ¨¡å‹çš„è¶‹åŠ¿çº¿è¡¨æ˜ï¼ŒrEFH å¯ä»¥å®ç°æ¯” ANN æ›´å¥½çš„å»¶è¿Ÿä¸ä¿çœŸåº¦æƒè¡¡ã€‚è¿™æºäº ANN éœ€è¦å¤§é‡çš„åˆ†ç®±çª—å£å†å²æ¥æå–æ—¶é—´ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´é«˜å»¶è¿Ÿã€‚å¯¹äº ANNï¼Œå‡å°‘åˆ†ç®±çª—å£çš„æ•°é‡ä¼šå¯¼è‡´ä¿çœŸåº¦æ˜¾è‘—ä¸‹é™ã€‚æµ…å±‚ LSTM å®ç°äº†æ¯”ä¼ ç»Ÿè§£ç å™¨å’Œ ANN æ›´ä½çš„å»¶è¿Ÿä¸ä¿çœŸåº¦æƒè¡¡ï¼Œå¦‚è¶‹åŠ¿çº¿æ‰€ç¤ºï¼Œå®ç°äº†è¶…è¿‡ 60% çš„å³°å€¼ $R^2$ åˆ†æ•°ï¼ŒåŒæ—¶å»¶è¿Ÿä»‹äº 4.05 æ¯«ç§’å’Œ 16.05 æ¯«ç§’ä¹‹é—´ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨ 16 æ¯«ç§’çš„è¾ƒé•¿åˆ†ç®±çª—å£æ—¶ï¼Œä¿çœŸåº¦æ˜¾è‘—ä¸‹é™ï¼Œè¿™è¡¨æ˜ LSTM ä¾èµ–äºç¥ç»æ•°æ®çš„æ—¶é—´ç»´åº¦æ¥æå–æœ‰å…³ç¥ç»åŠ¨æ€çš„ä¿¡æ¯ã€‚SNN åœ¨æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹ä¸­éƒ½å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„ $R^2$ åˆ†æ•°å’Œæ›´ä½å»¶è¿Ÿçš„æœ€ä½³æƒè¡¡ã€‚éšç€å±‚æ•°çš„å¢åŠ ï¼Œå»¶è¿Ÿä»…ç•¥æœ‰å¢åŠ ã€‚\nThe overall trend of the six decoders shows that recurrent neural networks (RNNs), such as the SNN and the LSTM, can achieve competitive fidelity to non-recurrent ones while extracting neural dynamics from intra-cortical spike data and having significantly lower latency, with SNNs maintaining lower latency for higher fidelity than LSTMs.\næ•´ä½“è¶‹åŠ¿æ˜¾ç¤ºï¼Œé€’å½’ç¥ç»ç½‘ç»œ (RNN)ï¼Œå¦‚ SNN å’Œ LSTMï¼Œå¯ä»¥å®ç°ä¸éé€’å½’ç½‘ç»œç›¸å½“çš„ä¿çœŸåº¦ï¼ŒåŒæ—¶ä»çš®å±‚å†…è„‰å†²æ•°æ®ä¸­æå–ç¥ç»åŠ¨æ€ï¼Œå¹¶å…·æœ‰æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿï¼ŒSNN åœ¨è¾ƒé«˜ä¿çœŸåº¦ä¸‹ä¿æŒæ¯” LSTM æ›´ä½çš„å»¶è¿Ÿã€‚\nPower consumption vs. fidelity MACs, reported as the number of inner products of matrix-vector multiplications, are indifferent to the length of the vectors in the inner product. This makes them inadequate for assessing power consumption. Instead, the total number of required operations during inference provides a better estimate of the actual energy cost. Figure 7 shows the operational cost versus fidelity tradeoff of the neural decoders.\nMAC ä½œä¸ºçŸ©é˜µ-å‘é‡ä¹˜æ³•çš„å†…ç§¯æ¬¡æ•°è¿›è¡ŒæŠ¥å‘Šï¼Œå¯¹å†…ç§¯ä¸­å‘é‡çš„é•¿åº¦æ— åŠ¨äºè¡·ã€‚è¿™ä½¿å¾—å®ƒä»¬ä¸é€‚åˆè¯„ä¼°åŠŸè€—ã€‚ç›¸åï¼Œæ¨ç†è¿‡ç¨‹ä¸­æ‰€éœ€çš„æ€»æ“ä½œæ•°æä¾›äº†å¯¹å®é™…èƒ½é‡æˆæœ¬çš„æ›´å¥½ä¼°è®¡ã€‚å›¾ 7 æ˜¾ç¤ºäº†ç¥ç»è§£ç å™¨çš„æ“ä½œæˆæœ¬ä¸ä¿çœŸåº¦æƒè¡¡ã€‚\nVisualized trade-off between $R^2$ score and total operations. The specific closed-loop setting requires neural decoders in the bottom right corner. ANN-based decoders, such as the ANN and the LSTM depicted as triangles, are an improvement compared to traditional decoders, represented as squares. Yet, the SNN, denoted by circles, achieves the lowest operational cost while maintaining competitive $R^2$ scores. Comparing memory access instead of total operations shows the same trend and is redundant.\n$R^2$ åˆ†æ•°ä¸æ€»æ“ä½œæ•°ä¹‹é—´çš„æƒè¡¡å¯è§†åŒ–ã€‚ç‰¹å®šçš„é—­ç¯è®¾ç½®éœ€è¦ä½äºå³ä¸‹è§’çš„ç¥ç»è§£ç å™¨ã€‚åŸºäº ANN çš„è§£ç å™¨ï¼ˆå¦‚å›¾ä¸­çš„ ANN å’Œ LSTMï¼Œè¡¨ç¤ºä¸ºä¸‰è§’å½¢ï¼‰ç›¸æ¯”ä¼ ç»Ÿè§£ç å™¨ï¼ˆè¡¨ç¤ºä¸ºæ–¹å—ï¼‰æœ‰æ‰€æ”¹è¿›ã€‚ç„¶è€Œï¼ŒSNNï¼ˆè¡¨ç¤ºä¸ºåœ†åœˆï¼‰åœ¨ä¿æŒç«äº‰åŠ›çš„ $R^2$ åˆ†æ•°çš„åŒæ—¶å®ç°äº†æœ€ä½çš„æ“ä½œæˆæœ¬ã€‚æ¯”è¾ƒå†…å­˜è®¿é—®è€Œä¸æ˜¯æ€»æ“ä½œæ•°æ˜¾ç¤ºäº†ç›¸åŒçš„è¶‹åŠ¿ï¼Œå› æ­¤æ˜¯å¤šä½™çš„ã€‚\nAll traditional decoders require matrix operations with large inner products, leading to, by far, the most operations to effectively decode neural signals. The average number of operations for traditional decoders across the experiments was between 700 000 and 2300 000. The three decoders have the same high number of total operations across the various binning windows because unlike the other models, the length of the binning window does not affect the operational cost. Traditional decoders had the most extensive range of $R^2$ scores, ranging from 23% to 66%. NN-based decoders represent a shift towards more computationally efficient decoding algorithms. Our experiments demonstrated significantly reduced power consumption compared to traditional decoders. The LSTM with 16 hidden neurons required 4700 operations, whereas the ANN with seven binned windows required approximately 34 000 operations. Compared to the traditional decoders, this significant improvement comes with consistently high fidelity, with $R^2$ values of ANN-based decoders ranging from 50% to 65%. The SNN decoders exhibited the highest energy efficacy among the decoder types considered in this study. On average, SNN decoders required 200 operations while achieving competitive fidelity levels, with $R^2$ values ranging from 60% to 63%.\næ‰€æœ‰ä¼ ç»Ÿè§£ç å™¨éƒ½éœ€è¦å…·æœ‰å¤§å†…ç§¯çš„çŸ©é˜µæ“ä½œï¼Œä»è€Œå¯¼è‡´è¿„ä»Šä¸ºæ­¢è§£ç ç¥ç»ä¿¡å·æ‰€éœ€çš„æ“ä½œæœ€å¤šã€‚ä¼ ç»Ÿè§£ç å™¨åœ¨å®éªŒä¸­çš„å¹³å‡æ“ä½œæ¬¡æ•°åœ¨ 700,000 åˆ° 2,300,000 ä¹‹é—´ã€‚è¿™ä¸‰ç§è§£ç å™¨åœ¨å„ç§åˆ†ç®±çª—å£ä¸­å…·æœ‰ç›¸åŒçš„é«˜æ€»æ“ä½œæ•°ï¼Œå› ä¸ºä¸å…¶ä»–æ¨¡å‹ä¸åŒï¼Œåˆ†ç®±çª—å£çš„é•¿åº¦ä¸ä¼šå½±å“æ“ä½œæˆæœ¬ã€‚ä¼ ç»Ÿè§£ç å™¨å…·æœ‰æœ€å¹¿æ³›çš„ $R^2$ åˆ†æ•°èŒƒå›´ï¼ŒèŒƒå›´ä» 23% åˆ° 66%ã€‚åŸºäº NN çš„è§£ç å™¨ä»£è¡¨äº†å‘æ›´é«˜æ•ˆè®¡ç®—è§£ç ç®—æ³•çš„è½¬å˜ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”ï¼ŒåŠŸè€—æ˜¾è‘—é™ä½ã€‚å…·æœ‰ 16 ä¸ªéšè—ç¥ç»å…ƒçš„ LSTM éœ€è¦ 4700 æ¬¡æ“ä½œï¼Œè€Œå…·æœ‰ä¸ƒä¸ªåˆ†ç®±çª—å£çš„ ANN å¤§çº¦éœ€è¦ 34,000 æ¬¡æ“ä½œã€‚ä¸ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”ï¼Œè¿™ä¸€æ˜¾è‘—æ”¹è¿›ä¼´éšç€å§‹ç»ˆå¦‚ä¸€çš„é«˜ä¿çœŸåº¦ï¼ŒåŸºäº ANN çš„è§£ç å™¨çš„ $R^2$ å€¼èŒƒå›´ä» 50% åˆ° 65%ã€‚SNN è§£ç å™¨åœ¨æœ¬ç ”ç©¶è€ƒè™‘çš„è§£ç å™¨ç±»å‹ä¸­è¡¨ç°å‡ºæœ€é«˜çš„èƒ½é‡æ•ˆç‡ã€‚SNN è§£ç å™¨å¹³å‡éœ€è¦ 200 æ¬¡æ“ä½œï¼ŒåŒæ—¶å®ç°å…·æœ‰ç«äº‰åŠ›çš„ä¿çœŸåº¦æ°´å¹³ï¼Œ$R^2$ å€¼èŒƒå›´ä» 60% åˆ° 63%ã€‚\nComparing memory access instead of total effective operations reveals the same tradeoff and is not reiterated. A comparison of the power consumption and fidelity metrics reveals an intriguing trade-off among the three decoder types. While traditional decoders require substantial operations, they offer a range of $R^2$ scores. In contrast, ANN-based and SNN-based decoders provide the advantage of reduced energy costs, with SNN decoders exhibiting the lowest computational load while maintaining competitive fidelity levels.\næ¯”è¾ƒå†…å­˜è®¿é—®è€Œä¸æ˜¯æ€»æœ‰æ•ˆæ“ä½œæ­ç¤ºäº†ç›¸åŒçš„æƒè¡¡ï¼Œå¹¶æœªé‡ç”³ã€‚åŠŸè€—å’Œä¿çœŸåº¦æŒ‡æ ‡çš„æ¯”è¾ƒæ­ç¤ºäº†ä¸‰ç§è§£ç å™¨ç±»å‹ä¹‹é—´æœ‰è¶£çš„æƒè¡¡ã€‚è™½ç„¶ä¼ ç»Ÿè§£ç å™¨éœ€è¦å¤§é‡æ“ä½œï¼Œä½†å®ƒä»¬æä¾›äº†ä¸€ç³»åˆ— $R^2$ åˆ†æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäº ANN å’Œ SNN çš„è§£ç å™¨æä¾›äº†é™ä½èƒ½é‡æˆæœ¬çš„ä¼˜åŠ¿ï¼ŒSNN è§£ç å™¨åœ¨ä¿æŒç«äº‰åŠ›çš„ä¿çœŸåº¦æ°´å¹³çš„åŒæ—¶è¡¨ç°å‡ºæœ€ä½çš„è®¡ç®—è´Ÿè½½ã€‚\nBayesian information criterion (BIC) The BIC serves as a valuable instrument for the comparing various neural networks, effectively addressing the concern of increased model complexity and its potential impact on performance enhancement. The BIC introduces a penalization term for the number of model parameters, thereby discouraging the adoption of overly complex models with excessive weights and biases. This penalty term effectively balances fidelity and model complexity, enabling us to discern whether a modelâ€™s performance improvements stem from an increased number of learnable parameters or architectural design.\nBIC æ˜¯æ¯”è¾ƒå„ç§ç¥ç»ç½‘ç»œçš„æœ‰ä»·å€¼çš„å·¥å…·ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ¨¡å‹å¤æ‚æ€§å¢åŠ åŠå…¶å¯¹æ€§èƒ½æå‡çš„æ½œåœ¨å½±å“çš„é—®é¢˜ã€‚BIC ä¸ºæ¨¡å‹å‚æ•°çš„æ•°é‡å¼•å…¥äº†æƒ©ç½šé¡¹ï¼Œä»è€Œé˜»æ­¢é‡‡ç”¨å…·æœ‰è¿‡å¤šæƒé‡å’Œåç½®çš„è¿‡äºå¤æ‚çš„æ¨¡å‹ã€‚è¯¥æƒ©ç½šé¡¹æœ‰æ•ˆåœ°å¹³è¡¡äº†ä¿çœŸåº¦å’Œæ¨¡å‹å¤æ‚æ€§ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¾¨åˆ«æ¨¡å‹çš„æ€§èƒ½æ”¹è¿›æ˜¯æºäºå¯å­¦ä¹ å‚æ•°æ•°é‡çš„å¢åŠ è¿˜æ˜¯æ¶æ„è®¾è®¡ã€‚\nFigure 8 presents the BIC values for various configurations of the three neural network-based decoders. Notably, the single-layer SNN, characterized by its minimal complexity, attains the lowest BIC score. In contrast, SNN2 and SNN3 had significantly higher BIC scores despite exhibiting performance improvements. This discrepancy suggests that the performance improvements are disproportional to the increased number of learnable parameters in these models. All SNNs achieved much lower BIC scores than the traditional and ANN-based neural decoder.\nå›¾ 8 å±•ç¤ºäº†ä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨çš„å„ç§é…ç½®çš„ BIC å€¼ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå•å±‚ SNN ä»¥å…¶æœ€å°çš„å¤æ‚æ€§è·å¾—äº†æœ€ä½çš„ BIC åˆ†æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå°½ç®¡ SNN2 å’Œ SNN3 è¡¨ç°å‡ºæ€§èƒ½æå‡ï¼Œä½†å®ƒä»¬çš„ BIC åˆ†æ•°æ˜¾è‘—æ›´é«˜ã€‚è¿™ç§å·®å¼‚è¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹ä¸­çš„æ€§èƒ½æ”¹è¿›ä¸å¯å­¦ä¹ å‚æ•°æ•°é‡çš„å¢åŠ ä¸æˆæ¯”ä¾‹ã€‚æ‰€æœ‰ SNN çš„ BIC åˆ†æ•°éƒ½è¿œä½äºä¼ ç»Ÿå’ŒåŸºäº ANN çš„ç¥ç»è§£ç å™¨ã€‚\nThe evaluated NN-based decodersâ€™ Bayesian information criterion (BIC) shows that the SNN achieve far lower BIC scores than other decoders, suggesting that SNNs are more suitable for the constrained closed-loop setting. A low BIC indicates that a decoder can learn better, given its complexity. The lowest BIC score is achieved by SNN1. The various models appear in the same order as presented in table 2.\nè¯„ä¼°çš„åŸºäº NN çš„è§£ç å™¨çš„è´å¶æ–¯ä¿¡æ¯å‡†åˆ™ (BIC) æ˜¾ç¤ºï¼ŒSNN å®ç°äº†è¿œä½äºå…¶ä»–è§£ç å™¨çš„ BIC åˆ†æ•°ï¼Œè¿™è¡¨æ˜ SNN æ›´é€‚åˆå—é™çš„é—­ç¯è®¾ç½®ã€‚è¾ƒä½çš„ BIC è¡¨æ˜ï¼Œç»™å®šå…¶å¤æ‚æ€§ï¼Œè§£ç å™¨å¯ä»¥å­¦ä¹ å¾—æ›´å¥½ã€‚æœ€ä½çš„ BIC åˆ†æ•°ç”± SNN1 å®ç°ã€‚å„ç§æ¨¡å‹çš„å‡ºç°é¡ºåºä¸è¡¨ 2 ä¸­å‘ˆç°çš„é¡ºåºç›¸åŒã€‚\nDiscussions In conclusion, optimizing neural decoders for closed-loop iBCI systems capable of CLN presents a delicate balance, requiring careful consideration of the trade-offs between fidelity, latency, power consumption, and memory size. Our findings emphasize that although more complex and deeper neural architectures with more trainable parameters, hold the potential for improved decoding accuracy, optimizing only for fidelity by increasing the complexity of a network can result in reduced usability for closed-loop iBCIs. The decoding accuracy reaffirms the findings of Glaser et al that conventional neural network-based decoders can achieve the highest R2 scores. However, we observe that this comes at the cost of increased latency and power consumption. Even when only considering fidelity, evaluating the BIC across the three NN-based decoders showed that SNNs consistently outperformed the ANN and the LSTM, achieving significantly lower BIC scores. This indicates that the performance improvement of the ANN is due to disproportionally more learnable parameters. Remarkably, the single-layer SNN emerged as the top performer out of the models we benchmarked in this paper, signifying its suitability for effectively learning data variance, particularly when considering the number of learnable parameters. This highlights that the shallow SNN is preferable for robust and energy-efficient neural decoding, given its complexity among the three neural network-based decoder types we evaluated.\næ€»ä¹‹ï¼Œä¸ºèƒ½å¤Ÿå®ç° CLN çš„é—­ç¯ iBCI ç³»ç»Ÿä¼˜åŒ–ç¥ç»è§£ç å™¨éœ€è¦åœ¨ä¿çœŸåº¦ã€å»¶è¿Ÿã€åŠŸè€—å’Œå†…å­˜å¤§å°ä¹‹é—´è¿›è¡Œå¾®å¦™çš„å¹³è¡¡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œå°½ç®¡å…·æœ‰æ›´å¤šå¯è®­ç»ƒå‚æ•°çš„æ›´å¤æ‚å’Œæ›´æ·±çš„ç¥ç»æ¶æ„å…·æœ‰æé«˜è§£ç å‡†ç¡®æ€§çš„æ½œåŠ›ï¼Œä½†ä»…é€šè¿‡å¢åŠ ç½‘ç»œçš„å¤æ‚æ€§æ¥ä¼˜åŒ–ä¿çœŸåº¦å¯èƒ½ä¼šé™ä½é—­ç¯ iBCI çš„å¯ç”¨æ€§ã€‚è§£ç å‡†ç¡®æ€§é‡ç”³äº† Glaser ç­‰äººçš„å‘ç°ï¼Œå³ä¼ ç»Ÿçš„åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨å¯ä»¥å®ç°æœ€é«˜çš„ $R^2$ åˆ†æ•°ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œè¿™ä»¥å¢åŠ å»¶è¿Ÿå’ŒåŠŸè€—ä¸ºä»£ä»·ã€‚å³ä½¿ä»…è€ƒè™‘ä¿çœŸåº¦ï¼Œè¯„ä¼°ä¸‰ç§åŸºäº NN çš„è§£ç å™¨çš„ BIC ä¹Ÿæ˜¾ç¤º SNN å§‹ç»ˆä¼˜äº ANN å’Œ LSTMï¼Œå®ç°äº†æ˜¾è‘—è¾ƒä½çš„ BIC åˆ†æ•°ã€‚è¿™è¡¨æ˜ ANN çš„æ€§èƒ½æå‡æ˜¯ç”±äºä¸æˆæ¯”ä¾‹åœ°æ›´å¤šçš„å¯å­¦ä¹ å‚æ•°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå•å±‚ SNN æˆä¸ºæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­åŸºå‡†æµ‹è¯•çš„æ¨¡å‹ä¸­çš„æœ€ä½³è¡¨ç°è€…ï¼Œè¡¨æ˜å…¶é€‚åˆæœ‰æ•ˆå­¦ä¹ æ•°æ®æ–¹å·®ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°å¯å­¦ä¹ å‚æ•°çš„æ•°é‡ã€‚è¿™çªæ˜¾å‡ºï¼Œåœ¨æˆ‘ä»¬è¯„ä¼°çš„ä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨ç±»å‹ä¸­ï¼Œè€ƒè™‘åˆ°å…¶å¤æ‚æ€§ï¼Œæµ…å±‚ SNN æ›´é€‚åˆè¿›è¡Œç¨³å¥ä¸”èŠ‚èƒ½çš„ç¥ç»è§£ç ã€‚\nThe ability of a neural decoder to effectively harness sparsity represents a crucial design consideration in closed-loop iBCI systems. Conventional neural data are characterized by their inherent sparsity and temporal encoding, with rate-based encoding accounting for a mere fraction of the neural activity in regions such as the visual cortex. The inherent sparsity of neural spikes provides SNNs with a distinct advantage, enabling them to capitalize on the spatiotemporal structure of the input data, which is less pronounced in non-neuromorphic ANNs.\nç¥ç»è§£ç å™¨æœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ€§çš„èƒ½åŠ›æ˜¯é—­ç¯ iBCI ç³»ç»Ÿä¸­çš„ä¸€ä¸ªå…³é”®è®¾è®¡è€ƒè™‘å› ç´ ã€‚ä¼ ç»Ÿçš„ç¥ç»æ•°æ®ä»¥å…¶å›ºæœ‰çš„ç¨€ç–æ€§å’Œæ—¶é—´ç¼–ç ä¸ºç‰¹å¾ï¼ŒåŸºäºé€Ÿç‡çš„ç¼–ç ä»…å è§†è§‰çš®å±‚ç­‰åŒºåŸŸç¥ç»æ´»åŠ¨çš„ä¸€å°éƒ¨åˆ†ã€‚ç¥ç»è„‰å†²çš„å›ºæœ‰ç¨€ç–æ€§ä¸º SNN æä¾›äº†ç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨è¾“å…¥æ•°æ®çš„æ—¶ç©ºç»“æ„ï¼Œè€Œè¿™ç§ç»“æ„åœ¨éç¥ç»å½¢æ€çš„ ANN ä¸­ä¸é‚£ä¹ˆæ˜æ˜¾ã€‚\nSNNs have previously demonstrated their potential for reduced power consumption and lower latency in various applications. In our study, we reaffirm and extend these prior findings, indicating that SNNs can extract neural dynamics from extracellular spiking data, while maintaining competitive fidelity and showing superior performance in terms of power consumption and latency.\nSNN å…ˆå‰å·²å±•ç¤ºäº†å…¶åœ¨å„ç§åº”ç”¨ä¸­é™ä½åŠŸè€—å’Œå»¶è¿Ÿçš„æ½œåŠ›ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é‡ç”³å¹¶æ‰©å±•äº†è¿™äº›å…ˆå‰çš„å‘ç°ï¼Œè¡¨æ˜ SNN å¯ä»¥ä»ç»†èƒå¤–è„‰å†²æ•°æ®ä¸­æå–ç¥ç»åŠ¨æ€ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›çš„ä¿çœŸåº¦ï¼Œå¹¶åœ¨åŠŸè€—å’Œå»¶è¿Ÿæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚\nThe latency metric introduced in our analysis operates under the assumption that the computation of an inner product is equivalent to a single addition in terms of clock cycles. Although this abstraction aligns with standard practices for MAC operations, it is essential to acknowledge that this assumption may only partially represent the potential hardware optimizations for vector accumulations. While the process of counting additions might initially appear as a potential disadvantage when comparing SNNs to ANNs in the context of latency, we observe that despite this methodological abstraction, SNNs consistently achieved substantially lower latency when compared to traditional decoders and the ANN. The longer latency of traditional decoders and ANNs is primarily attributed to their reliance on long binning windows for extracting temporal information and their high operational cost. Notably, the sole exception to this trend is the LSTM, which demonstrates a latency level comparable to that of SNNs. This observation reaffirms the findings of Zenke et al, who demonstrated the efficiency of RNNs, such as LSTMs and SNNs, in exploiting the temporal structure of neural data, emphasizing their capacity to achieve competitive fidelity with low latency in a closed-loop neural decoding system. These insights underscore that even without accounting for the potential hardware optimizations, SNNs can exhibit a marked advantage in terms of latency over traditional decoder models and non-recurrent ANNs, which require more extensive computational resources owing to their temporal information extraction procedures.\næˆ‘ä»¬åˆ†æä¸­å¼•å…¥çš„å»¶è¿ŸæŒ‡æ ‡å‡è®¾å†…ç§¯çš„è®¡ç®—åœ¨æ—¶é’Ÿå‘¨æœŸæ–¹é¢ç­‰åŒäºå•æ¬¡åŠ æ³•ã€‚å°½ç®¡è¿™ç§æŠ½è±¡ä¸ MAC æ“ä½œçš„æ ‡å‡†åšæ³•ä¸€è‡´ï¼Œä½†å¿…é¡»æ‰¿è®¤ï¼Œè¿™ä¸€å‡è®¾å¯èƒ½ä»…éƒ¨åˆ†ä»£è¡¨äº†å‘é‡ç´¯ç§¯çš„æ½œåœ¨ç¡¬ä»¶ä¼˜åŒ–ã€‚è™½ç„¶åœ¨å»¶è¿Ÿæ–¹é¢æ¯”è¾ƒ SNN å’Œ ANN æ—¶ï¼Œè®¡ç®—åŠ æ³•çš„è¿‡ç¨‹æœ€åˆä¼¼ä¹æ˜¯ä¸€ä¸ªæ½œåœ¨çš„åŠ£åŠ¿ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå°½ç®¡å­˜åœ¨è¿™ç§æ–¹æ³•è®ºæŠ½è±¡ï¼ŒSNN ä¸ä¼ ç»Ÿè§£ç å™¨å’Œ ANN ç›¸æ¯”ä»å§‹ç»ˆå®ç°äº†æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿã€‚ä¼ ç»Ÿè§£ç å™¨å’Œ ANN è¾ƒé•¿çš„å»¶è¿Ÿä¸»è¦å½’å› äºå®ƒä»¬ä¾èµ–äºé•¿åˆ†ç®±çª—å£æ¥æå–æ—¶é—´ä¿¡æ¯åŠå…¶é«˜æ“ä½œæˆæœ¬ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸€è¶‹åŠ¿çš„å”¯ä¸€ä¾‹å¤–æ˜¯ LSTMï¼Œå…¶æ˜¾ç¤ºå‡ºä¸ SNN ç›¸å½“çš„å»¶è¿Ÿæ°´å¹³ã€‚è¿™ä¸€è§‚å¯Ÿç»“æœé‡ç”³äº† Zenke ç­‰äººçš„å‘ç°ï¼Œä»–ä»¬å±•ç¤ºäº† RNNï¼ˆå¦‚ LSTM å’Œ SNNï¼‰åœ¨åˆ©ç”¨ç¥ç»æ•°æ®çš„æ—¶é—´ç»“æ„æ–¹é¢çš„æ•ˆç‡ï¼Œå¼ºè°ƒäº†å®ƒä»¬åœ¨é—­ç¯ç¥ç»è§£ç ç³»ç»Ÿä¸­ä»¥ä½å»¶è¿Ÿå®ç°ç«äº‰åŠ›ä¿çœŸåº¦çš„èƒ½åŠ›ã€‚è¿™äº›è§è§£å¼ºè°ƒï¼Œå³ä½¿ä¸è€ƒè™‘æ½œåœ¨çš„ç¡¬ä»¶ä¼˜åŒ–ï¼ŒSNN åœ¨å»¶è¿Ÿæ–¹é¢ä¹Ÿèƒ½è¡¨ç°å‡ºæ˜æ˜¾ä¼˜äºä¼ ç»Ÿè§£ç å™¨æ¨¡å‹å’Œéé€’å½’ ANN çš„ä¼˜åŠ¿ï¼Œåè€…ç”±äºå…¶æ—¶é—´ä¿¡æ¯æå–ç¨‹åºè€Œéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚\nThe advantages of employing neuromorphic SNNs for closed-loop iBCIs become more apparent when the energy cost is evaluated using the total number of operations. In this context, SNNs significantly outperform traditional and ANN-based decoders. Our results show that traditional and ANN-based decoders require several orders of magnitude more operations to attain performance levels comparable to SNNs. The remarkable reduction in the number of operations required by SNNs can be attributed to their constrained design, which minimizes the number of learnable parameters while still delivering competitive performance. However, the primary driving forces behind the substantially lower energy cost associated with SNNs lies in their ability to exploit sparsity and their more energy-efficient operations. This capacity allows for approximately 5% of the operations to be executed, emphasizing the exceptional efficiency achieved by SNNs while maintaining high fidelity. Following previously reported estimates of required energy per operation, we observe an approximate energy cost of around $2 \\mu\\text{W}$ per inference for the SNNs, which is 50 times lower than for the LSTM, 100 times lower for the ANN, and 10 000 times lower than for the UKF.\né‡‡ç”¨ç¥ç»å½¢æ€ SNN ç”¨äºé—­ç¯ iBCI çš„ä¼˜åŠ¿åœ¨ä½¿ç”¨æ€»æ“ä½œæ•°è¯„ä¼°èƒ½é‡æˆæœ¬æ—¶å˜å¾—æ›´åŠ æ˜æ˜¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒSNN æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå’ŒåŸºäº ANN çš„è§£ç å™¨ã€‚æˆ‘ä»¬çš„ç»“æœæ˜¾ç¤ºï¼Œä¼ ç»Ÿå’ŒåŸºäº ANN çš„è§£ç å™¨éœ€è¦å¤šä¸ªæ•°é‡çº§çš„æ›´å¤šæ“ä½œæ‰èƒ½è¾¾åˆ°ä¸ SNN ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚SNN æ‰€éœ€æ“ä½œæ•°çš„æ˜¾è‘—å‡å°‘å¯å½’å› äºå…¶å—é™çš„è®¾è®¡ï¼Œè¯¥è®¾è®¡åœ¨æœ€å°åŒ–å¯å­¦ä¹ å‚æ•°æ•°é‡çš„åŒæ—¶ä»æä¾›ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¸ SNN ç›¸å…³çš„æ˜¾è‘—è¾ƒä½èƒ½é‡æˆæœ¬çš„ä¸»è¦é©±åŠ¨åŠ›åœ¨äºå®ƒä»¬åˆ©ç”¨ç¨€ç–æ€§å’Œæ›´èŠ‚èƒ½æ“ä½œçš„èƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›ä½¿å¾—å¤§çº¦ 5% çš„æ“ä½œå¾—ä»¥æ‰§è¡Œï¼Œå¼ºè°ƒäº† SNN åœ¨ä¿æŒé«˜ä¿çœŸåº¦çš„åŒæ—¶å®ç°çš„å“è¶Šæ•ˆç‡ã€‚æ ¹æ®å…ˆå‰æŠ¥å‘Šçš„æ¯æ¬¡æ“ä½œæ‰€éœ€èƒ½é‡çš„ä¼°è®¡ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ° SNN æ¯æ¬¡æ¨ç†çš„å¤§çº¦èƒ½é‡æˆæœ¬çº¦ä¸º $2 \\mu\\text{W}$ï¼Œè¿™æ¯” LSTM ä½ 50 å€ï¼Œæ¯” ANN ä½ 100 å€ï¼Œæ¯” UKF ä½ 10,000 å€ã€‚\nThe field of neurotechnology and BCIs are rapidly expanding. New advancements and technologies enable the development of more effective, user-friendly, and versatile BCIs. This paper discusses two main challenges in designing processors for implantable closed-loop neural decoders: low energy consumption to minimize heat diffusion, and low latency to enable real-time CLN. We defined metrics for neural decoders and benchmarked common decoding methods to predict a primateâ€™s finger kinematics. This study explores the suitability of low latency and low computing neural decoders and highlights the potential advantages of neuromorphic SNNs for CLN. Our results show that SNNs can balance decoding accuracy and operational efficiency, offering immense potential for reshaping the landscape of neural decoders and opening new frontiers in closed-loop intracortical human-brain interaction.\nç¥ç»æŠ€æœ¯å’Œ BCI é¢†åŸŸæ­£åœ¨è¿…é€Ÿæ‰©å±•ã€‚æ–°çš„è¿›å±•å’ŒæŠ€æœ¯ä½¿å¾—å¼€å‘æ›´æœ‰æ•ˆã€ç”¨æˆ·å‹å¥½ä¸”å¤šåŠŸèƒ½çš„ BCI æˆä¸ºå¯èƒ½ã€‚æœ¬æ–‡è®¨è®ºäº†ä¸ºå¯æ¤å…¥é—­ç¯ç¥ç»è§£ç å™¨è®¾è®¡å¤„ç†å™¨çš„ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šä½èƒ½è€—ä»¥æœ€å°åŒ–çƒ­æ‰©æ•£ï¼Œä»¥åŠä½å»¶è¿Ÿä»¥å®ç°å®æ—¶ CLNã€‚æˆ‘ä»¬ä¸ºç¥ç»è§£ç å™¨å®šä¹‰äº†æŒ‡æ ‡ï¼Œå¹¶åŸºå‡†æµ‹è¯•äº†å¸¸è§çš„è§£ç æ–¹æ³•ä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©çš„æ‰‹æŒ‡è¿åŠ¨å­¦ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä½å»¶è¿Ÿå’Œä½è®¡ç®—ç¥ç»è§£ç å™¨çš„é€‚ç”¨æ€§ï¼Œå¹¶å¼ºè°ƒäº†ç¥ç»å½¢æ€ SNN åœ¨ CLN ä¸­çš„æ½œåœ¨ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSNN å¯ä»¥å¹³è¡¡è§£ç å‡†ç¡®æ€§å’Œæ“ä½œæ•ˆç‡ï¼Œä¸ºé‡å¡‘ç¥ç»è§£ç å™¨çš„æ ¼å±€æä¾›äº†å·¨å¤§çš„æ½œåŠ›ï¼Œå¹¶ä¸ºé—­ç¯çš®å±‚å†…äººè„‘äº¤äº’å¼€è¾Ÿäº†æ–°çš„å‰æ²¿ã€‚\nUsing neuromorphic SNNs for CLN is an area of research with great promise, as indicated by successfully predicting an NHP finger kinematic in this study. However, the list of evaluated decoders is non-exhaustive, and only a single neural decoder, the SNN, was optimized for latency and power consumption. This allows for comparing commonly used decoders, yet it favors inherently efficient and fast neuromorphic decoders. Additionally, only one exemplary dataset was evaluated as representative of closed-loop iBCI tasks requiring low latency and power consumption. Therefore, this study highlights the potential of SNN for iBCI for CLN, however, further studies are required to explore the suitability of these networks for other types of neural decoding tasks and to optimize their performance to meet the requirements of CLN systems. Developing fully implantable iBCIs with local processing capabilities is crucial for reducing energy consumption and latency and improving the real-time applicability of CLN systems.\nåœ¨æœ¬ç ”ç©¶ä¸­æˆåŠŸé¢„æµ‹ NHP æ‰‹æŒ‡è¿åŠ¨å­¦è¡¨æ˜ï¼Œä½¿ç”¨ç¥ç»å½¢æ€ SNN è¿›è¡Œ CLN æ˜¯ä¸€ä¸ªå……æ»¡å¸Œæœ›çš„ç ”ç©¶é¢†åŸŸã€‚ç„¶è€Œï¼Œè¯„ä¼°çš„è§£ç å™¨åˆ—è¡¨å¹¶ä¸è¯¦å°½ï¼Œåªæœ‰å•ä¸ªç¥ç»è§£ç å™¨ SNN é’ˆå¯¹å»¶è¿Ÿå’ŒåŠŸè€—è¿›è¡Œäº†ä¼˜åŒ–ã€‚è¿™å…è®¸æ¯”è¾ƒå¸¸ç”¨çš„è§£ç å™¨ï¼Œä½†æœ‰åˆ©äºæœ¬è´¨ä¸Šé«˜æ•ˆä¸”å¿«é€Ÿçš„ç¥ç»å½¢æ€è§£ç å™¨ã€‚æ­¤å¤–ï¼Œä»…è¯„ä¼°äº†ä¸€ä¸ªå…¸å‹æ•°æ®é›†ï¼Œä½œä¸ºéœ€è¦ä½å»¶è¿Ÿå’ŒåŠŸè€—çš„é—­ç¯ iBCI ä»»åŠ¡çš„ä»£è¡¨ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶çªæ˜¾äº† SNN åœ¨ CLN iBCI ä¸­çš„æ½œåŠ›ï¼Œä½†éœ€è¦è¿›ä¸€æ­¥çš„ç ”ç©¶æ¥æ¢ç´¢è¿™äº›ç½‘ç»œåœ¨å…¶ä»–ç±»å‹ç¥ç»è§£ç ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¼˜åŒ–å…¶æ€§èƒ½ä»¥æ»¡è¶³ CLN ç³»ç»Ÿçš„è¦æ±‚ã€‚å¼€å‘å…·æœ‰æœ¬åœ°å¤„ç†èƒ½åŠ›çš„å®Œå…¨å¯æ¤å…¥ iBCI å¯¹äºé™ä½èƒ½è€—å’Œå»¶è¿Ÿä»¥åŠæé«˜ CLN ç³»ç»Ÿçš„å®æ—¶é€‚ç”¨æ€§è‡³å…³é‡è¦ã€‚\nOverall, the outlook for neural engineering and BCIs is bright. New developments will improve neural recording and decoding technologies, ultimately enhancing our understanding of the brain and its complex neural processes.\næ€»ä½“è€Œè¨€ï¼Œç¥ç»å·¥ç¨‹å’Œ BCI çš„å‰æ™¯å…‰æ˜ã€‚æ–°çš„å‘å±•å°†æ”¹å–„ç¥ç»è®°å½•å’Œè§£ç æŠ€æœ¯ï¼Œæœ€ç»ˆå¢å¼ºæˆ‘ä»¬å¯¹å¤§è„‘åŠå…¶å¤æ‚ç¥ç»è¿‡ç¨‹çš„ç†è§£ã€‚\nConclusion Our study introduces methods to extrapolate algorithmic-to-hardware metrics that allow evaluating the low latency and high energy efficacy requirements of iBCI suitable for CLN. We present six commonly used neural decoders and compare them in predicting an NHP fine motor kinematics from binned neural activity. Our results highlight the potential advantages of neuromorphic SNNs in the context of iBCIs capable of CLN. In our benchmark, we observe that SNNs outperform other commonly used decoders, with evident performance differences when compared against benchmarked traditional decoders. Notably, the exceptionally low latency of SNNs and LSTMs, surpassing that of traditional decoders and non-RNNs, arises from their innate ability to extract temporal information from spiking neural data. The power efficiency can be attributed to the adeptness of SNNs in exploiting sparsity and their deliberately constrained architectural design. Our results show that SNNs can achieve competitive decoding performance in less than 5 ms, using less than 1% of computational resources, and more than 50 times less energy than other neural decoding methods in this benchmark. This makes them highly suitable candidates for closed-loop iBCI challenges and positions them as a game-changing technology for reshaping the landscape of neural decoders. Significant advancements in CLN can be achieved by adopting SNNs as the preferred neural decoder. Their capacity for efficient and accurate neural signal processing holds the potential to revolutionize BCI applications, enhancing our ability to interact with and understand the intricacies of the human brain.\næˆ‘ä»¬çš„ç ”ç©¶å¼•å…¥äº†å°†ç®—æ³•æŒ‡æ ‡å¤–æ¨åˆ°ç¡¬ä»¶æŒ‡æ ‡çš„æ–¹æ³•ï¼Œä½¿å¾—è¯„ä¼°é€‚ç”¨äº CLN çš„ iBCI çš„ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆè¦æ±‚æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†å…­ç§å¸¸ç”¨çš„ç¥ç»è§£ç å™¨ï¼Œå¹¶æ¯”è¾ƒäº†å®ƒä»¬åœ¨æ ¹æ®åˆ†ç®±ç¥ç»æ´»åŠ¨é¢„æµ‹ NHP ç²¾ç»†è¿åŠ¨å­¦æ–¹é¢çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†ç¥ç»å½¢æ€ SNN åœ¨èƒ½å¤Ÿå®ç° CLN çš„ iBCI èƒŒæ™¯ä¸‹çš„æ½œåœ¨ä¼˜åŠ¿ã€‚åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ° SNN ä¼˜äºå…¶ä»–å¸¸ç”¨è§£ç å™¨ï¼Œä¸åŸºå‡†ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒSNN å’Œ LSTM çš„å¼‚å¸¸ä½å»¶è¿Ÿè¶…è¿‡äº†ä¼ ç»Ÿè§£ç å™¨å’Œé RNNï¼Œè¿™æºäºå®ƒä»¬ä»è„‰å†²ç¥ç»æ•°æ®ä¸­æå–æ—¶é—´ä¿¡æ¯çš„å¤©ç”Ÿèƒ½åŠ›ã€‚åŠŸç‡æ•ˆç‡å¯å½’å› äº SNN åœ¨åˆ©ç”¨ç¨€ç–æ€§æ–¹é¢çš„ç†Ÿç»ƒç¨‹åº¦åŠå…¶æœ‰æ„å—é™çš„æ¶æ„è®¾è®¡ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSNN å¯ä»¥åœ¨ä¸åˆ° 5 æ¯«ç§’å†…å®ç°å…·æœ‰ç«äº‰åŠ›çš„è§£ç æ€§èƒ½ï¼Œä½¿ç”¨ä¸åˆ° 1% çš„è®¡ç®—èµ„æºï¼Œå¹¶ä¸”æ¯”æœ¬åŸºå‡†ä¸­çš„å…¶ä»–ç¥ç»è§£ç æ–¹æ³•èŠ‚çœè¶…è¿‡ 50 å€çš„èƒ½é‡ã€‚è¿™ä½¿å¾—å®ƒä»¬æˆä¸ºé—­ç¯ iBCI æŒ‘æˆ˜çš„é«˜åº¦åˆé€‚å€™é€‰è€…ï¼Œå¹¶å°†å…¶å®šä½ä¸ºé‡å¡‘ç¥ç»è§£ç å™¨æ ¼å±€çš„å˜é©æ€§æŠ€æœ¯ã€‚é€šè¿‡é‡‡ç”¨ SNN ä½œä¸ºé¦–é€‰ç¥ç»è§£ç å™¨ï¼Œå¯ä»¥åœ¨ CLN æ–¹é¢å–å¾—é‡å¤§è¿›å±•ã€‚å®ƒä»¬é«˜æ•ˆä¸”å‡†ç¡®å¤„ç†ç¥ç»ä¿¡å·çš„èƒ½åŠ›æœ‰æœ›å½»åº•æ”¹å˜ BCI åº”ç”¨ï¼Œå¢å¼ºæˆ‘ä»¬ä¸äººç±»å¤§è„‘å¤æ‚æ€§äº’åŠ¨å’Œç†è§£çš„èƒ½åŠ›ã€‚\n",
  "wordCount" : "20455",
  "inLanguage": "zh",
  "image":"https://s2.loli.net/2025/11/12/nEhjw2f9WD7VpAB.png","datePublished": "2025-11-12T00:18:23+08:00",
  "dateModified": "2025-11-12T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "Muartz"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Muatyz.github.io/posts/read/reference/benchmarking-of-hardware-efficient-real-time-neural-decoding-in-brain-computer-interfaces/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "æ— å¤„æƒ¹å°˜åŸƒ",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Muatyz.github.io/img/Head32.png"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  CommonHTML: {
  scale: 100
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
  
  
  
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script>

<style>
  code.has-jax {
      font: "LXGW WenKai Screen", sans-serif, Arial;
      scale: 1;
      background: "LXGW WenKai Screen", sans-serif, Arial;
      border: "LXGW WenKai Screen", sans-serif, Arial;
      color: #515151;
  }
</style>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Muatyz.github.io/" accesskey="h" title="è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿— (Alt + H)">
            <img src="https://Muatyz.github.io/img/Head64.png" alt="logo" aria-label="logo"
                 height="35">è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿—</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Muatyz.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Muatyz.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/">ğŸ“• é˜…è¯»</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/reference/">ğŸ“• æ–‡çŒ®</a></div>
            <h1 class="post-title">
                Benchmarking of hardware-efficient real-time neural decoding in brainâ€“computer interfaces
            </h1>
            <div class="post-description">
                è„‘æœºæ¥å£ä¸­ç¡¬ä»¶é«˜æ•ˆå®æ—¶ç¥ç»è§£ç çš„åŸºå‡†æµ‹è¯•
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-11-12
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>20455å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>41åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Muartz
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://Muatyz.github.io/tags/physics/" style="color: var(--secondary)!important;">Physics</a>
                &nbsp;<a href="https://Muatyz.github.io/tags/numerical-calculation/" style="color: var(--secondary)!important;">Numerical Calculation</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Muatyz.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId: "Admin", 
                                region: "ap-shanghai", 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://s2.loli.net/2025/11/12/nEhjw2f9WD7VpAB.png" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#background" aria-label="Background">Background</a><ul>
                        
                <li>
                    <a href="#cln" aria-label="CLN">CLN</a></li>
                <li>
                    <a href="#constraints-of-closed-loop-neuromodulation" aria-label="Constraints of closed-loop neuromodulation">Constraints of closed-loop neuromodulation</a></li></ul>
                </li>
                <li>
                    <a href="#metrics" aria-label="Metrics">Metrics</a><ul>
                        
                <li>
                    <a href="#model-fidelity" aria-label="Model fidelity">Model fidelity</a></li>
                <li>
                    <a href="#latency" aria-label="Latency">Latency</a></li>
                <li>
                    <a href="#power-consumption" aria-label="Power consumption">Power consumption</a></li>
                <li>
                    <a href="#memory-footprint" aria-label="Memory footprint">Memory footprint</a></li></ul>
                </li>
                <li>
                    <a href="#methods" aria-label="Methods">Methods</a><ul>
                        
                <li>
                    <a href="#neural-recording-dataset" aria-label="Neural recording dataset">Neural recording dataset</a></li>
                <li>
                    <a href="#traditional-neural-decoders" aria-label="Traditional neural decoders">Traditional neural decoders</a></li>
                <li>
                    <a href="#anns" aria-label="ANNs">ANNs</a></li>
                <li>
                    <a href="#snn" aria-label="SNN">SNN</a></li>
                <li>
                    <a href="#experimental-setup" aria-label="Experimental setup">Experimental setup</a></li></ul>
                </li>
                <li>
                    <a href="#results" aria-label="Results">Results</a><ul>
                        
                <li>
                    <a href="#latency-vs-fidelity" aria-label="Latency vs. fidelity">Latency vs. fidelity</a></li>
                <li>
                    <a href="#power-consumption-vs-fidelity" aria-label="Power consumption vs. fidelity">Power consumption vs. fidelity</a></li>
                <li>
                    <a href="#bayesian-information-criterion-bic" aria-label="Bayesian information criterion (BIC)">Bayesian information criterion (BIC)</a></li></ul>
                </li>
                <li>
                    <a href="#discussions" aria-label="Discussions">Discussions</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h1>
<blockquote>
<p>Designing processors for implantable closed-loop neuromodulation systems presents a formidable challenge owing to the constrained operational environment, which requires low latency and high energy efficacy. Previous benchmarks have provided limited insights into power consumption and latency. However, this study introduces algorithmic metrics that capture the potential and limitations of neural decoders for closed-loop intra-cortical brainâ€“computer interfaces in the context of energy and hardware constraints. This study benchmarks common decoding methods for predicting a primateâ€™s finger kinematics from the motor cortex and explores their suitability for low latency and high energy efficient neural decoding. The study found that ANN-based decoders provide superior decoding accuracy, requiring high latency and many operations to effectively decode neural signals. Spiking neural networks (SNNs) have emerged as a solution, bridging this gap by achieving competitive decoding performance within sub-10 ms while utilizing a fraction of computational resources. These distinctive advantages of neuromorphic SNNs make them highly suitable for the challenging closed-loop neural modulation environment. Their capacity to balance decoding accuracy and operational efficiency offers immense potential in reshaping the landscape of neural decoders, fostering greater understanding, and opening new frontiers in closed-loop intra-cortical human-machine interaction.</p>
</blockquote>
<p>ä¸ºå¯æ¤å…¥é—­ç¯ç¥ç»è°ƒèŠ‚ç³»ç»Ÿè®¾è®¡å¤„ç†å™¨æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶å—é™çš„æ“ä½œç¯å¢ƒéœ€è¦ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆã€‚ä»¥å¾€çš„åŸºå‡†æµ‹è¯•å¯¹åŠŸè€—å’Œå»¶è¿Ÿæä¾›äº†æœ‰é™çš„è§è§£ã€‚ç„¶è€Œï¼Œæœ¬ç ”ç©¶å¼•å…¥äº†ç®—æ³•æŒ‡æ ‡ï¼Œæ•æ‰äº†ç¥ç»è§£ç å™¨åœ¨èƒ½é‡å’Œç¡¬ä»¶çº¦æŸä¸‹ç”¨äºé—­ç¯çš®å±‚å†…è„‘æœºæ¥å£çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚æœ¬ç ”ç©¶åŸºå‡†æµ‹è¯•äº†å¸¸è§çš„è§£ç æ–¹æ³•ï¼Œä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©è¿åŠ¨çš®å±‚çš„æ‰‹æŒ‡è¿åŠ¨å­¦ï¼Œå¹¶æ¢è®¨äº†å®ƒä»¬åœ¨ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆç¥ç»è§£ç æ–¹é¢çš„é€‚ç”¨æ€§ã€‚ç ”ç©¶å‘ç°ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰çš„è§£ç å™¨æä¾›äº†æ›´ä¼˜çš„è§£ç ç²¾åº¦ï¼Œä½†éœ€è¦é«˜å»¶è¿Ÿå’Œå¤§é‡è¿ç®—æ‰èƒ½æœ‰æ•ˆè§£ç ç¥ç»ä¿¡å·ã€‚è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰å·²æˆä¸ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡åœ¨10æ¯«ç§’ä»¥ä¸‹å®ç°å…·æœ‰ç«äº‰åŠ›çš„è§£ç æ€§èƒ½ï¼ŒåŒæ—¶åˆ©ç”¨æå°‘çš„è®¡ç®—èµ„æºï¼Œå¼¥åˆäº†è¿™ä¸€å·®è·ã€‚ç¥ç»å½¢æ€ SNNs çš„è¿™äº›ç‹¬ç‰¹ä¼˜åŠ¿ä½¿å…¶éå¸¸é€‚åˆå…·æœ‰æŒ‘æˆ˜æ€§çš„é—­ç¯ç¥ç»è°ƒèŠ‚ç¯å¢ƒã€‚å®ƒä»¬åœ¨å¹³è¡¡è§£ç ç²¾åº¦å’Œæ“ä½œæ•ˆç‡æ–¹é¢çš„èƒ½åŠ›ä¸ºé‡å¡‘ç¥ç»è§£ç å™¨çš„æ ¼å±€æä¾›äº†å·¨å¤§çš„æ½œåŠ›ï¼Œä¿ƒè¿›äº†æ›´æ·±å…¥çš„ç†è§£ï¼Œå¹¶ä¸ºé—­ç¯çš®å±‚å†…äººæœºäº¤äº’å¼€è¾Ÿäº†æ–°çš„å‰æ²¿ã€‚</p>
<h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<blockquote>
<p><strong>Brainâ€“computer interfaces (BCIs)</strong> have revolutionized the fields of neuroscience and medicine by enabling individuals with disabilities to interact with external devices and restore lost sensory, motor, or cognitive functions. Intra-cortical BCIs (iBCIs), a type of invasive BCI that involves placing electrodes directly into the cortex of the brain, have great potential for <strong>closed-loop neuromodulation (CLN)</strong>. CLN alters neural activity using personalized and responsive therapeutic electrical neural modulation based on the subjectâ€™s neural activity. CLN has higher efficacy, and lower risk of side effects than fixed stimulation, that is open-loop neuromodulation as shown in figure 1. CLN requires neural decoders that interpret neural activity, such that BCI can provide real-time feedback stimulation or control external devices based on the subjectâ€™s neural activity.</p>
</blockquote>
<p>**è„‘æœºæ¥å£ï¼ˆBCIï¼‰<strong>é€šè¿‡ä½¿æ®‹ç–¾äººèƒ½å¤Ÿä¸å¤–éƒ¨è®¾å¤‡äº¤äº’å¹¶æ¢å¤ä¸§å¤±çš„æ„Ÿè§‰ã€è¿åŠ¨æˆ–è®¤çŸ¥åŠŸèƒ½ï¼Œå½»åº•æ”¹å˜äº†ç¥ç»ç§‘å­¦å’ŒåŒ»å­¦é¢†åŸŸã€‚çš®å±‚å†…è„‘æœºæ¥å£ï¼ˆiBCIï¼‰æ˜¯ä¸€ç§ä¾µå…¥æ€§ BCIï¼Œæ¶‰åŠå°†ç”µæç›´æ¥æ”¾ç½®åœ¨å¤§è„‘çš®å±‚ä¸­ï¼Œå…·æœ‰</strong>é—­ç¯ç¥ç»è°ƒèŠ‚ï¼ˆCLNï¼‰**çš„å·¨å¤§æ½œåŠ›ã€‚CLN ä½¿ç”¨åŸºäºå—è¯•è€…ç¥ç»æ´»åŠ¨çš„ä¸ªæ€§åŒ–å’Œå“åº”æ€§æ²»ç–—æ€§ç”µç¥ç»è°ƒèŠ‚æ¥æ”¹å˜ç¥ç»æ´»åŠ¨ã€‚ä¸å›ºå®šåˆºæ¿€ï¼ˆå³å¼€ç¯ç¥ç»è°ƒèŠ‚ï¼‰ç›¸æ¯”ï¼ŒCLN å…·æœ‰æ›´é«˜çš„ç–—æ•ˆå’Œæ›´ä½çš„å‰¯ä½œç”¨é£é™©ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚CLN éœ€è¦è§£é‡Šç¥ç»æ´»åŠ¨çš„ç¥ç»è§£ç å™¨ï¼Œä»¥ä¾¿ BCI èƒ½å¤Ÿæ ¹æ®å—è¯•è€…çš„ç¥ç»æ´»åŠ¨æä¾›å®æ—¶åé¦ˆåˆºæ¿€æˆ–æ§åˆ¶å¤–éƒ¨è®¾å¤‡ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/CB8uHvUSb4Zh6Jd.png" alt=""  /></p>
<p>Paradigm of a closed-loop and open-loop neuromodulations. (a) During open-loop neuromodulation, the subject receives predefined stimulation. (b) During closed-loop neuromodulation (CLN), the subject receives adaptive stimulation based on the recorded and decoded neural activities. CLN enables individualized, responsive therapeutic treatment improving the effectiveness of the treatment and reducing side effects.</p>
</blockquote>
<p>é—­ç¯å’Œå¼€ç¯ç¥ç»è°ƒèŠ‚çš„èŒƒä¾‹ã€‚(a) åœ¨å¼€ç¯ç¥ç»è°ƒèŠ‚æœŸé—´ï¼Œå—è¯•è€…æ¥å—é¢„å®šä¹‰çš„åˆºæ¿€ã€‚(b) åœ¨é—­ç¯ç¥ç»è°ƒèŠ‚ (CLN) æœŸé—´ï¼Œå—è¯•è€…æ ¹æ®è®°å½•å’Œè§£ç çš„ç¥ç»æ´»åŠ¨æ¥æ”¶è‡ªé€‚åº”åˆºæ¿€ã€‚CLN å®ç°äº†ä¸ªæ€§åŒ–ã€å“åº”æ€§çš„æ²»ç–—ï¼Œæé«˜äº†æ²»ç–—æ•ˆæœå¹¶å‡å°‘äº†å‰¯ä½œç”¨ã€‚</p>
</blockquote>
<blockquote>
<p>Designing iBCIs for CLN is challenging because of the highly resource-constrained environment of the implants. Even a slight temperature increase of one degree can cause damage to neural cells. Moreover, a decoding time of a few milliseconds is required for CLN aimed at inter-areal interactions. This requires the development of energy-efficient and low-latency neural decoders that can overcome the constraints of low latency and energy consumption.</p>
</blockquote>
<p>ä¸º CLN è®¾è®¡ iBCI å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ¤å…¥ç‰©çš„èµ„æºå—é™ç¯å¢ƒéå¸¸ä¸¥é‡ã€‚å³ä½¿æ¸©åº¦ç•¥å¾®å‡é«˜ä¸€åº¦ä¹Ÿä¼šå¯¹ç¥ç»ç»†èƒé€ æˆæŸå®³ã€‚æ­¤å¤–ï¼ŒCLN æ—¨åœ¨å®ç°åŒºåŸŸé—´äº¤äº’ï¼Œéœ€è¦å‡ æ¯«ç§’çš„è§£ç æ—¶é—´ã€‚è¿™éœ€è¦å¼€å‘èƒ½å¤Ÿå…‹æœä½å»¶è¿Ÿå’Œèƒ½è€—é™åˆ¶çš„é«˜èƒ½æ•ˆã€ä½å»¶è¿Ÿç¥ç»è§£ç å™¨ã€‚</p>
<blockquote>
<p>Benchmarking neural decoders for online in vivo iBCIs is crucial to ensure their optimal performance within the resource-constrained environment of implantable systems. By evaluating various decoders based on their fidelity, latency, and power consumption, researchers can identify the most suitable options that satisfy clinical safety requirements and ensure effective real-time operation, ultimately improving the efficacy of CLN.</p>
</blockquote>
<p>åœ¨ä½“å†… iBCI åœ¨çº¿åŸºå‡†æµ‹è¯•ç¥ç»è§£ç å™¨å¯¹äºç¡®ä¿å…¶åœ¨å¯æ¤å…¥ç³»ç»Ÿçš„èµ„æºå—é™ç¯å¢ƒä¸­çš„æœ€ä½³æ€§èƒ½è‡³å…³é‡è¦ã€‚é€šè¿‡æ ¹æ®ä¿çœŸåº¦ã€å»¶è¿Ÿå’ŒåŠŸè€—è¯„ä¼°å„ç§è§£ç å™¨ï¼Œç ”ç©¶äººå‘˜å¯ä»¥ç¡®å®šæ»¡è¶³ä¸´åºŠå®‰å…¨è¦æ±‚å¹¶ç¡®ä¿æœ‰æ•ˆå®æ—¶æ“ä½œçš„æœ€åˆé€‚é€‰é¡¹ï¼Œä»è€Œæœ€ç»ˆæé«˜ CLN çš„ç–—æ•ˆã€‚</p>
<blockquote>
<p>Traditional benchmarks predominantly emphasize the accuracy and fidelity aspects of decoding methods. A recent addition, NeuroBench, expanded this focus to assess algorithm-hardware co-optimization, incorporating fidelity, efficiency, and performance metrics. While NeuroBench is well-suited for evaluating the operational cost of neural decoders, its algorithmic benchmark provides limited insights into power and latency, primarily relying on the effective operational cost as a proxy for hardware metrics. This paper, presents methods to extrapolate algorithmic-to-hardware metrics, addressing the gap encompassing all the essential constraints required to evaluate and compare the suitability of neural decoders for iBCIs in the context of CLN. Any benchmark designed to compare neural decoders for iBCI within the context of CLN must consider the co-optimization between hardware and software. Only then can we benchmark effectively and accurately evaluate power consumption, latency, and the fidelity of neural decoders, providing a holistic assessment of decoder suitability for real-time, low-energy applications.</p>
</blockquote>
<p>ä¼ ç»ŸåŸºå‡†æµ‹è¯•ä¸»è¦å¼ºè°ƒè§£ç æ–¹æ³•çš„å‡†ç¡®æ€§å’Œä¿çœŸåº¦æ–¹é¢ã€‚æœ€è¿‘æ–°å¢çš„ NeuroBench æ‰©å±•äº†è¿™ä¸€é‡ç‚¹ï¼Œä»¥è¯„ä¼°ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œç»“åˆäº†ä¿çœŸåº¦ã€æ•ˆç‡å’Œæ€§èƒ½æŒ‡æ ‡ã€‚è™½ç„¶ NeuroBench éå¸¸é€‚åˆè¯„ä¼°ç¥ç»è§£ç å™¨çš„æ“ä½œæˆæœ¬ï¼Œä½†å…¶ç®—æ³•åŸºå‡†å¯¹åŠŸç‡å’Œå»¶è¿Ÿæä¾›çš„è§è§£æœ‰é™ï¼Œä¸»è¦ä¾èµ–äºæœ‰æ•ˆæ“ä½œæˆæœ¬ä½œä¸ºç¡¬ä»¶æŒ‡æ ‡çš„ä»£ç†ã€‚æœ¬æ–‡æå‡ºäº†å°†ç®—æ³•æŒ‡æ ‡å¤–æ¨åˆ°ç¡¬ä»¶æŒ‡æ ‡çš„æ–¹æ³•ï¼Œè§£å†³äº†è¯„ä¼°å’Œæ¯”è¾ƒç¥ç»è§£ç å™¨åœ¨ CLN èƒŒæ™¯ä¸‹ç”¨äº iBCI é€‚ç”¨æ€§æ‰€éœ€çš„æ‰€æœ‰åŸºæœ¬çº¦æŸä¹‹é—´çš„å·®è·ã€‚ä»»ä½•æ—¨åœ¨æ¯”è¾ƒ CLN èƒŒæ™¯ä¸‹ iBCI ç¥ç»è§£ç å™¨çš„åŸºå‡†éƒ½å¿…é¡»è€ƒè™‘ç¡¬ä»¶å’Œè½¯ä»¶ä¹‹é—´çš„ååŒä¼˜åŒ–ã€‚åªæœ‰è¿™æ ·ï¼Œæˆ‘ä»¬æ‰èƒ½æœ‰æ•ˆåœ°åŸºå‡†æµ‹è¯•å¹¶å‡†ç¡®è¯„ä¼°ç¥ç»è§£ç å™¨çš„åŠŸè€—ã€å»¶è¿Ÿå’Œä¿çœŸåº¦ï¼Œä¸ºå®æ—¶ã€ä½èƒ½è€—åº”ç”¨æä¾›å…¨é¢çš„è§£ç å™¨é€‚ç”¨æ€§è¯„ä¼°ã€‚</p>
<blockquote>
<p>This paper will introduce metrics that researchers can use to avoid the complex co-optimization process by evaluating neural decoders algorithmically while incorporating hardware considerations. Section 3 presents metrics designed to suit the energy and hardware-constrained environment of iBCIs suitable for CLN. Section 4 introduces six neural decoders benchmarks their ability to predict a primateâ€™s finger movements. Finally, future directions and implications of this research will be discussed.</p>
</blockquote>
<p>æœ¬æ–‡å°†ä»‹ç»ç ”ç©¶äººå‘˜å¯ä»¥ä½¿ç”¨çš„æŒ‡æ ‡ï¼Œé€šè¿‡åœ¨è€ƒè™‘ç¡¬ä»¶çš„åŒæ—¶å¯¹ç¥ç»è§£ç å™¨è¿›è¡Œç®—æ³•è¯„ä¼°ï¼Œä»è€Œé¿å…å¤æ‚çš„ååŒä¼˜åŒ–è¿‡ç¨‹ã€‚ç¬¬ 3 èŠ‚ä»‹ç»äº†æ—¨åœ¨é€‚åº”é€‚ç”¨äº CLN çš„ iBCI çš„èƒ½æºå’Œç¡¬ä»¶å—é™ç¯å¢ƒçš„æŒ‡æ ‡ã€‚ç¬¬ 4 èŠ‚ä»‹ç»äº†å…­ç§ç¥ç»è§£ç å™¨åŸºå‡†åŠå…¶é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©æ‰‹æŒ‡è¿åŠ¨çš„èƒ½åŠ›ã€‚æœ€åï¼Œå°†è®¨è®ºè¯¥ç ”ç©¶çš„æœªæ¥æ–¹å‘å’Œå½±å“ã€‚</p>
<h1 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h1>
<blockquote>
<p>Intra-cortical neuronal recordings from the motor cortex have been pioneered by Delgado et al in 1952 and Evarts conducted further groundbreaking work capturing extracellular neural activity from single recording units in conscious primates engaged in diverse motor tasks. Today, almost 60 years later, neural recording has undergone a revolutionary evolution owing to innovative technologies such as high-density probes, high-density microelectrode array, and carbon nanotube yarn biosensors. These technologies have made it possible to record the activities of more neurons with a higher spatial resolution and coverage and have paved the way for more clinically viable and high-performance iBCIs. BCIs help subjects with disabilities to interact with external devices, such as neuroprosthetics, or restore lost sensory, motor, or cognitive functions by translating neural activity from the brain into control commands through neural decoding. In addition to therapeutic applications, iBCIs advance our understanding of the complex neural processes that underlie behavior, cognition, and perception.</p>
</blockquote>
<p>çš®å±‚å†…ç¥ç»å…ƒè®°å½•ç”± Delgado ç­‰äººåœ¨ 1952 å¹´å¼€åˆ›ï¼ŒEvarts åœ¨æ•æ‰å‚ä¸å„ç§è¿åŠ¨ä»»åŠ¡çš„æ¸…é†’çµé•¿ç±»åŠ¨ç‰©çš„å•ä¸ªè®°å½•å•å…ƒçš„ç»†èƒå¤–ç¥ç»æ´»åŠ¨æ–¹é¢è¿›è¡Œäº†è¿›ä¸€æ­¥çš„å¼€åˆ›æ€§å·¥ä½œã€‚ä»Šå¤©ï¼Œè¿‘ 60 å¹´åï¼Œç¥ç»è®°å½•ç»å†äº†ä¸€åœºé©å‘½æ€§çš„æ¼”å˜ï¼Œè¿™è¦å½’åŠŸäºé«˜å¯†åº¦æ¢é’ˆã€é«˜å¯†åº¦å¾®ç”µæé˜µåˆ—å’Œç¢³çº³ç±³ç®¡çº±çº¿ç”Ÿç‰©ä¼ æ„Ÿå™¨ç­‰åˆ›æ–°æŠ€æœ¯ã€‚è¿™äº›æŠ€æœ¯ä½¿å¾—ä»¥æ›´é«˜çš„ç©ºé—´åˆ†è¾¨ç‡å’Œè¦†ç›–èŒƒå›´è®°å½•æ›´å¤šç¥ç»å…ƒçš„æ´»åŠ¨æˆä¸ºå¯èƒ½ï¼Œå¹¶ä¸ºæ›´å…·ä¸´åºŠå¯è¡Œæ€§å’Œé«˜æ€§èƒ½çš„ iBCI é“ºå¹³äº†é“è·¯ã€‚BCI é€šè¿‡ç¥ç»è§£ç å°†å¤§è„‘ä¸­çš„ç¥ç»æ´»åŠ¨è½¬æ¢ä¸ºæ§åˆ¶å‘½ä»¤ï¼Œå¸®åŠ©æ®‹ç–¾äººç¾¤ä¸å¤–éƒ¨è®¾å¤‡ï¼ˆå¦‚ç¥ç»å‡ä½“ï¼‰äº¤äº’æˆ–æ¢å¤ä¸§å¤±çš„æ„Ÿè§‰ã€è¿åŠ¨æˆ–è®¤çŸ¥åŠŸèƒ½ã€‚é™¤äº†æ²»ç–—åº”ç”¨å¤–ï¼ŒiBCI è¿˜å¢è¿›äº†æˆ‘ä»¬å¯¹è¡Œä¸ºã€è®¤çŸ¥å’Œæ„ŸçŸ¥èƒŒåçš„å¤æ‚ç¥ç»è¿‡ç¨‹çš„ç†è§£ã€‚</p>
<blockquote>
<p>Two types of BCIs can be distinguished: non-invasive and invasive. Invasive BCIs involve implanting electrodes into or on the cortex. iBCIs are a specific subtype of invasive BCIs, in which electrodes are inserted into the cortex, which is the outermost layer of the brain. They provide the finest spatial and temporal resolutions and excellent signal quality. Although iBCIs carry a higher risk owing to surgical implantation, their superior spatiotemporal resolution is crucial for high-precision neural decoding.</p>
</blockquote>
<p>å¯ä»¥åŒºåˆ†ä¸¤ç§ç±»å‹çš„ BCIï¼šéä¾µå…¥æ€§å’Œä¾µå…¥æ€§ã€‚ä¾µå…¥æ€§ BCI æ¶‰åŠå°†ç”µææ¤å…¥æˆ–æ”¾ç½®åœ¨çš®å±‚ä¸Šã€‚iBCI æ˜¯ä¾µå…¥æ€§ BCI çš„ä¸€ä¸ªç‰¹å®šäºšå‹ï¼Œå…¶ä¸­ç”µææ’å…¥å¤§è„‘çš„æœ€å¤–å±‚çš®å±‚ã€‚å®ƒä»¬æä¾›äº†æœ€ç²¾ç»†çš„ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ä»¥åŠå‡ºè‰²çš„ä¿¡å·è´¨é‡ã€‚å°½ç®¡ iBCI ç”±äºå¤–ç§‘æ‰‹æœ¯æ¤å…¥è€Œå¸¦æ¥æ›´é«˜çš„é£é™©ï¼Œä½†å…¶å“è¶Šçš„æ—¶ç©ºåˆ†è¾¨ç‡å¯¹äºé«˜ç²¾åº¦ç¥ç»è§£ç è‡³å…³é‡è¦ã€‚</p>
<h2 id="cln">CLN<a hidden class="anchor" aria-hidden="true" href="#cln">#</a></h2>
<blockquote>
<p>One promising field for iBCI is neuromodulation. Traditionally, neuromodulation described the physiological processes by which neurons use neurotransmitters to regulate neural activity. More recently, neuromodulation has been adapted to refer to the process of altering neural activity via electrical stimulation to restore normal neurological functions or study intra-cortical interaction. Neuromodulation can be classified into open and closed-loop systems, as shown in figure 1. Open-loop neuromodulation involves delivering neural stimulation without real-time feedback from the targeted neural system with predefined and fixed stimulation parameters, such as strength or timing. In contrast, CLN with iBCI uses bi-directional communication between the brain and the computing devices, providing adaptive feedback to adapt and adjust the parameters of interventions, enabling personalized and responsive therapeutic neural modulation based on the subjectâ€™s neural activity. The adaptive and interactive nature of CLN enhances efficacy, i.e. maximizing the therapeutic impact and leading to more successful treatments, and reduces the side effects of neural stimulations (e.g. discomfort, headache, or worst case seizure). For the remainder of this paper, CLN refers exclusively to neuromodulation via iBCI.</p>
</blockquote>
<p>iBCI çš„ä¸€ä¸ªæœ‰å‰é€”çš„é¢†åŸŸæ˜¯ç¥ç»è°ƒèŠ‚ã€‚ä¼ ç»Ÿä¸Šï¼Œç¥ç»è°ƒèŠ‚æè¿°äº†ç¥ç»å…ƒä½¿ç”¨ç¥ç»é€’è´¨è°ƒèŠ‚ç¥ç»æ´»åŠ¨çš„ç”Ÿç†è¿‡ç¨‹ã€‚æœ€è¿‘ï¼Œç¥ç»è°ƒèŠ‚å·²è¢«æ”¹ç¼–ä¸ºæŒ‡é€šè¿‡ç”µåˆºæ¿€æ”¹å˜ç¥ç»æ´»åŠ¨ä»¥æ¢å¤æ­£å¸¸ç¥ç»åŠŸèƒ½æˆ–ç ”ç©¶çš®å±‚å†…ç›¸äº’ä½œç”¨çš„è¿‡ç¨‹ã€‚ç¥ç»è°ƒèŠ‚å¯ä»¥åˆ†ä¸ºå¼€ç¯å’Œé—­ç¯ç³»ç»Ÿï¼Œå¦‚å›¾ 1 æ‰€ç¤ºã€‚å¼€ç¯ç¥ç»è°ƒèŠ‚æ¶‰åŠåœ¨æ²¡æœ‰æ¥è‡ªç›®æ ‡ç¥ç»ç³»ç»Ÿçš„å®æ—¶åé¦ˆçš„æƒ…å†µä¸‹æä¾›ç¥ç»åˆºæ¿€ï¼Œå…·æœ‰é¢„å®šä¹‰å’Œå›ºå®šçš„åˆºæ¿€å‚æ•°ï¼Œä¾‹å¦‚å¼ºåº¦æˆ–æ—¶é—´ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒiBCI çš„ CLN ä½¿ç”¨å¤§è„‘ä¸è®¡ç®—è®¾å¤‡ä¹‹é—´çš„åŒå‘é€šä¿¡ï¼Œæä¾›è‡ªé€‚åº”åé¦ˆä»¥è°ƒæ•´å¹²é¢„å‚æ•°ï¼Œå®ç°åŸºäºå—è¯•è€…ç¥ç»æ´»åŠ¨çš„ä¸ªæ€§åŒ–å’Œå“åº”æ€§æ²»ç–—æ€§ç¥ç»è°ƒèŠ‚ã€‚CLN çš„è‡ªé€‚åº”å’Œäº¤äº’æ€§è´¨æé«˜äº†ç–—æ•ˆï¼Œå³æœ€å¤§åŒ–æ²»ç–—æ•ˆæœå¹¶å¯¼è‡´æ›´æˆåŠŸçš„æ²»ç–—ï¼Œå¹¶å‡å°‘äº†ç¥ç»åˆºæ¿€çš„å‰¯ä½œç”¨ï¼ˆä¾‹å¦‚ä¸é€‚ã€å¤´ç—›æˆ–æœ€åæƒ…å†µç™«ç—«å‘ä½œï¼‰ã€‚åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ä¸­ï¼ŒCLN ä¸“é—¨æŒ‡é€šè¿‡ iBCI è¿›è¡Œçš„ç¥ç»è°ƒèŠ‚ã€‚</p>
<h2 id="constraints-of-closed-loop-neuromodulation">Constraints of closed-loop neuromodulation<a hidden class="anchor" aria-hidden="true" href="#constraints-of-closed-loop-neuromodulation">#</a></h2>
<blockquote>
<p>CLN typically requires a powerful external computer to decode complex neural activities. More sophisticated neural tasks (e.g. sensory and motor cortex interaction) require high channel counts of neural recording with fine spatial and temporal resolutions, generating vast amounts of recording data, which impose significant limitations on the real-time applicability of neural decoders, see figure 2. Transferring data from the intra-cortical neural sensors to an external system requires energy-intensive wireless transmission, and limited wireless transmission bandwidth can increase the systemâ€™s latency. Moreover, the transfer of neural data for processing to an external computer raises privacy concerns. Many neural decoders for iBCI and CLN have been implemented in application-specific integrated circuit (ASICs), achieving low power consumption and miniature form factor, which demonstrates the feasibility of in vivo neural decoding.</p>
</blockquote>
<p>é—­ç¯ç¥ç»è°ƒèŠ‚é€šå¸¸éœ€è¦å¼ºå¤§çš„å¤–éƒ¨è®¡ç®—æœºæ¥è§£ç å¤æ‚çš„ç¥ç»æ´»åŠ¨ã€‚æ›´å¤æ‚çš„ç¥ç»ä»»åŠ¡ï¼ˆä¾‹å¦‚æ„Ÿè§‰å’Œè¿åŠ¨çš®å±‚äº¤äº’ï¼‰éœ€è¦é«˜é€šé“æ•°çš„ç¥ç»è®°å½•ï¼Œå…·æœ‰ç²¾ç»†çš„ç©ºé—´å’Œæ—¶é—´åˆ†è¾¨ç‡ï¼Œç”Ÿæˆå¤§é‡çš„è®°å½•æ•°æ®ï¼Œè¿™å¯¹ç¥ç»è§£ç å™¨çš„å®æ—¶é€‚ç”¨æ€§æ–½åŠ äº†é‡å¤§é™åˆ¶ï¼Œè§å›¾ 2ã€‚ä»çš®å±‚å†…ç¥ç»ä¼ æ„Ÿå™¨å‘å¤–éƒ¨ç³»ç»Ÿä¼ è¾“æ•°æ®éœ€è¦è€—èƒ½çš„æ— çº¿ä¼ è¾“ï¼Œæœ‰é™çš„æ— çº¿ä¼ è¾“å¸¦å®½ä¼šå¢åŠ ç³»ç»Ÿçš„å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œå°†ç¥ç»æ•°æ®ä¼ è¾“åˆ°å¤–éƒ¨è®¡ç®—æœºè¿›è¡Œå¤„ç†ä¼šå¼•å‘éšç§é—®é¢˜ã€‚è®¸å¤šç”¨äº iBCI å’Œ CLN çš„ç¥ç»è§£ç å™¨å·²åœ¨ä¸“ç”¨é›†æˆç”µè·¯ (ASIC) ä¸­å®ç°ï¼Œå®ç°äº†ä½åŠŸè€—å’Œå¾®å‹åŒ–å½¢å¼å› ç´ ï¼Œå±•ç¤ºäº†ä½“å†…ç¥ç»è§£ç çš„å¯è¡Œæ€§ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/u9NgjTDwmLH6Wb7.png" alt=""  /></p>
<p>Advantages and disadvantages of external and local processing. (a) External processing requires transferring neural data or extracted features to an external computing device. Wireless data transfer suffers from long latency, high transmission energy, and privacy concerns. (b) Local neural processing has the potential to be significantly faster, with low transmission energy, at the cost of little flexibility.</p>
</blockquote>
<p>å¤–éƒ¨å’Œæœ¬åœ°å¤„ç†çš„ä¼˜ç¼ºç‚¹ã€‚(a) å¤–éƒ¨å¤„ç†éœ€è¦å°†ç¥ç»æ•°æ®æˆ–æå–çš„ç‰¹å¾ä¼ è¾“åˆ°å¤–éƒ¨è®¡ç®—è®¾å¤‡ã€‚æ— çº¿æ•°æ®ä¼ è¾“å­˜åœ¨é•¿å»¶è¿Ÿã€é«˜ä¼ è¾“èƒ½è€—å’Œéšç§é—®é¢˜ã€‚(b) æœ¬åœ°ç¥ç»å¤„ç†æœ‰å¯èƒ½æ˜¾è‘—æ›´å¿«ï¼Œä¼ è¾“èƒ½è€—ä½ï¼Œä½†çµæ´»æ€§è¾ƒå·®ã€‚</p>
</blockquote>
<blockquote>
<p>To address these concerns, data transmission can be avoided by eliminating the need for external computing and decoding neural signals locally on the implant. This eliminates the necessity for intensive data communication collectively except for programming the implant or diagnostics. Valencia and Alimohammad highlighted the need for local processing in a fully implantable iBCI for in vivo closed-loop neural decoding, eliminating data transmission during inference and significantly reducing energy consumption, latency, and privacy concerns.</p>
</blockquote>
<p>ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡æ¶ˆé™¤å¯¹å¤–éƒ¨è®¡ç®—çš„éœ€æ±‚å¹¶åœ¨æ¤å…¥ç‰©ä¸Šæœ¬åœ°è§£ç ç¥ç»ä¿¡å·æ¥é¿å…æ•°æ®ä¼ è¾“ã€‚è¿™æ¶ˆé™¤äº†é™¤äº†å¯¹æ¤å…¥ç‰©è¿›è¡Œç¼–ç¨‹æˆ–è¯Šæ–­ä¹‹å¤–çš„å¯†é›†æ•°æ®é€šä¿¡çš„å¿…è¦æ€§ã€‚Valencia å’Œ Alimohammad å¼ºè°ƒäº†åœ¨ä½“å†…é—­ç¯ç¥ç»è§£ç çš„å…¨æ¤å…¥å¼ iBCI ä¸­è¿›è¡Œæœ¬åœ°å¤„ç†çš„å¿…è¦æ€§ï¼Œæ¶ˆé™¤äº†æ¨ç†è¿‡ç¨‹ä¸­çš„æ•°æ®ä¼ è¾“ï¼Œå¹¶æ˜¾è‘—é™ä½äº†èƒ½è€—ã€å»¶è¿Ÿå’Œéšç§é—®é¢˜ã€‚</p>
<blockquote>
<p>Designing iBCIs for CLN is challenging because of the highly resource-constrained environment of implants. The implant volume should be minimized to reduce the invasiveness and risks of the surgery, and low power consumption is required to prevent tissue damage due to even a one degree temperature increase. However, iBCIs are required to process an exponentially growing amount of neural data, which adds to the complexity of the decoding task. Minimal heat diffusion is required to ensure safe local processing, without causing tissue damage.
While Wolf initially cautiously recommended limiting the temperature of implant electronics to below 40 available at: heat flux and 2 â—¦C, a much lower bound of 1 â—¦C is vital to maintain long-term neural cell health. This means that a 10 mm2 of implant electronics cannot exceed a power dissipation of 400 Î¼W, which is âˆ¼10Ã— lower than that of smartphone processors (e.g. the microprocessor in iPhone concerns 100â€™s mW of power with an ASIC area of approximately 100 mm2). Given the conservative nature of these recommendations, minimizing power consumption beyond the stated limits is paramount. However, traditional processors cannot satisfy this power requirement, and low-power implants performing neural decoding algorithms is a major challenge to the successful clinical adoption of real-time closed-loop iBCIs.</p>
</blockquote>
<p>ä¸º CLN è®¾è®¡ iBCI å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ¤å…¥ç‰©çš„èµ„æºæå…¶å—é™çš„ç¯å¢ƒã€‚ä¸ºäº†å‡å°‘æ‰‹æœ¯çš„ä¾µå…¥æ€§å’Œé£é™©ï¼Œåº”å°½é‡å‡å°‘æ¤å…¥ç‰©çš„ä½“ç§¯ï¼Œå¹¶ä¸”éœ€è¦ä½åŠŸè€—ä»¥é˜²æ­¢ç”±äºå³ä½¿æ¸©åº¦åªå‡é«˜ä¸€åº¦è€Œå¯¼è‡´çš„ç»„ç»‡æŸä¼¤ã€‚ç„¶è€Œï¼ŒiBCI éœ€è¦å¤„ç†æŒ‡æ•°å¢é•¿çš„ç¥ç»æ•°æ®é‡ï¼Œè¿™å¢åŠ äº†è§£ç ä»»åŠ¡çš„å¤æ‚æ€§ã€‚éœ€è¦æœ€å°çš„çƒ­æ‰©æ•£ä»¥ç¡®ä¿å®‰å…¨çš„æœ¬åœ°å¤„ç†ï¼Œè€Œä¸ä¼šé€ æˆç»„ç»‡æŸä¼¤ã€‚
è™½ç„¶ Wolf æœ€åˆè°¨æ…åœ°å»ºè®®å°†æ¤å…¥ç”µå­è®¾å¤‡çš„æ¸©åº¦é™åˆ¶åœ¨ 40 å¯ç”¨ï¼šçƒ­é€šé‡å’Œ 2 â—¦C ä»¥ä¸‹ï¼Œä½†ä¸ºäº†ç»´æŒé•¿æœŸç¥ç»ç»†èƒå¥åº·ï¼Œ1 â—¦C çš„æ›´ä½ç•Œé™è‡³å…³é‡è¦ã€‚è¿™æ„å‘³ç€ $10\text{ mm}^{2}$ çš„æ¤å…¥ç”µå­è®¾å¤‡çš„åŠŸè€—ä¸èƒ½è¶…è¿‡ $400 \mu\text{W}$ï¼Œè¿™å¤§çº¦æ˜¯æ™ºèƒ½æ‰‹æœºå¤„ç†å™¨ï¼ˆä¾‹å¦‚ iPhone ä¸­çš„å¾®å¤„ç†å™¨ï¼ŒåŠŸç‡ä¸ºæ•°ç™¾æ¯«ç“¦ï¼ŒASIC é¢ç§¯çº¦ä¸º 100 mm2ï¼‰çš„ 10 å€ã€‚é‰´äºè¿™äº›å»ºè®®çš„ä¿å®ˆæ€§è´¨ï¼Œè¶…å‡ºè§„å®šé™åˆ¶çš„æœ€å°åŒ–åŠŸè€—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿå¤„ç†å™¨æ— æ³•æ»¡è¶³æ­¤åŠŸç‡è¦æ±‚ï¼Œæ‰§è¡Œç¥ç»è§£ç ç®—æ³•çš„ä½åŠŸè€—æ¤å…¥ç‰©æ˜¯å®æ—¶é—­ç¯ iBCI æˆåŠŸä¸´åºŠé‡‡ç”¨çš„ä¸€å¤§æŒ‘æˆ˜ã€‚</p>
<blockquote>
<p>Real-time processing is another crucial requirement for closed-loop iBCIs, in which continuous neural recording, decoding, and feedback occur in real time. This necessitates fast and efficient neural decoding algorithms to ensure timely and seamless interaction between the nervous system and the iBCI. Controlling a robotic prosthesis requires a latency of less than 150 ms between neural activity and arm movement for smooth and natural control, which is close to the biological delay for signal propagation between the brain and the arm. However, immediate feedback is crucial for the neural decoder to adjust the control system in real-time, allowing subjects to adapt and refine their actions in real-time. In this closed-loop iBCI, much lower latency of less than 10 ms is necessary for decoding inter-areal interactions (e.g. sensory and motor) in the brain.</p>
</blockquote>
<p>å®æ—¶å¤„ç†æ˜¯é—­ç¯ iBCI çš„å¦ä¸€ä¸ªå…³é”®è¦æ±‚ï¼Œå…¶ä¸­è¿ç»­çš„ç¥ç»è®°å½•ã€è§£ç å’Œåé¦ˆå®æ—¶å‘ç”Ÿã€‚è¿™éœ€è¦å¿«é€Ÿé«˜æ•ˆçš„ç¥ç»è§£ç ç®—æ³•ï¼Œä»¥ç¡®ä¿ç¥ç»ç³»ç»Ÿä¸ iBCI ä¹‹é—´çš„åŠæ—¶æ— ç¼äº¤äº’ã€‚æ§åˆ¶æœºå™¨äººå‡è‚¢éœ€è¦åœ¨ç¥ç»æ´»åŠ¨å’Œæ‰‹è‡‚è¿åŠ¨ä¹‹é—´çš„å»¶è¿Ÿå°äº 150 æ¯«ç§’ï¼Œä»¥å®ç°å¹³ç¨³è‡ªç„¶çš„æ§åˆ¶ï¼Œè¿™æ¥è¿‘å¤§è„‘ä¸æ‰‹è‡‚ä¹‹é—´ä¿¡å·ä¼ æ’­çš„ç”Ÿç‰©å­¦å»¶è¿Ÿã€‚ç„¶è€Œï¼Œç«‹å³åé¦ˆå¯¹äºç¥ç»è§£ç å™¨å®æ—¶è°ƒæ•´æ§åˆ¶ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œä½¿å—è¯•è€…èƒ½å¤Ÿå®æ—¶é€‚åº”å’Œå®Œå–„å…¶åŠ¨ä½œã€‚åœ¨è¿™ç§é—­ç¯ iBCI ä¸­ï¼Œå¯¹äºè§£ç å¤§è„‘ä¸­çš„åŒºåŸŸé—´äº¤äº’ï¼ˆä¾‹å¦‚æ„Ÿè§‰å’Œè¿åŠ¨ï¼‰ï¼Œéœ€è¦æ›´ä½çš„å»¶è¿Ÿï¼Œä½äº 10 æ¯«ç§’ã€‚</p>
<h1 id="metrics">Metrics<a hidden class="anchor" aria-hidden="true" href="#metrics">#</a></h1>
<blockquote>
<p>Traditionally, neural decoders have been the primary evaluated on decoding performance. However, in hardware-constrained iBCIs, other factors, such as latency and power consumption, are crucial to ensure the tractability of neural decoders for applications such as CLN. Evaluating decoders solely on task performance often fails to capture their true potential but also limitations. This chapter introduces the need for comprehensive metrics for algorithmic evaluation that encompass fidelity (i.e. accuracy), latency, power consumption, and memory size for neural decoders. Table 1 presents an overview of the proposed evaluation metrics.</p>
</blockquote>
<p>ä¼ ç»Ÿä¸Šï¼Œç¥ç»è§£ç å™¨ä¸»è¦è¯„ä¼°è§£ç æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨ç¡¬ä»¶å—é™çš„ iBCI ä¸­ï¼Œå»¶è¿Ÿå’ŒåŠŸè€—ç­‰å…¶ä»–å› ç´ å¯¹äºç¡®ä¿ç¥ç»è§£ç å™¨åœ¨ CLN ç­‰åº”ç”¨ä¸­çš„å¯å¤„ç†æ€§è‡³å…³é‡è¦ã€‚ä»…æ ¹æ®ä»»åŠ¡æ€§èƒ½è¯„ä¼°è§£ç å™¨é€šå¸¸æ— æ³•æ•æ‰å…¶çœŸæ­£çš„æ½œåŠ›ï¼Œä¹Ÿæ— æ³•æ•æ‰å…¶å±€é™æ€§ã€‚æœ¬ç« ä»‹ç»äº†å…¨é¢æŒ‡æ ‡çš„å¿…è¦æ€§ï¼Œç”¨äºæ¶µç›–ç¥ç»è§£ç å™¨çš„ä¿çœŸåº¦ï¼ˆå³å‡†ç¡®æ€§ï¼‰ã€å»¶è¿Ÿã€åŠŸè€—å’Œå†…å­˜å¤§å°çš„ç®—æ³•è¯„ä¼°ã€‚è¡¨ 1 æå‡ºäº†æ‰€å»ºè®®çš„è¯„ä¼°æŒ‡æ ‡çš„æ¦‚è¿°ã€‚</p>
<blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left"></th>
          <th style="text-align: left">Metric</th>
          <th style="text-align: left">Explaination</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Fidelity</td>
          <td style="text-align: left">$R^{2}\\r$</td>
          <td style="text-align: left">Proportion of explainable data variance $\\$ Temporal alignment of label and prediction</td>
      </tr>
      <tr>
          <td style="text-align: left">Latency</td>
          <td style="text-align: left">Binning latency $\\$ Processing latency</td>
          <td style="text-align: left">Timespan of input data needed per inference $\\$ Operational delay optimized by the algorithm designer</td>
      </tr>
      <tr>
          <td style="text-align: left">Power consumption</td>
          <td style="text-align: left">Total eff. operations $\\$ Memory access</td>
          <td style="text-align: left">Number of effective operations needed per inference $\\$ Number of effective memory access needed per inference</td>
      </tr>
      <tr>
          <td style="text-align: left">Size</td>
          <td style="text-align: left">Memory footprint</td>
          <td style="text-align: left">Number of bits required to store the decoder</td>
      </tr>
  </tbody>
</table>
</blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left"></th>
          <th style="text-align: left">æŒ‡æ ‡</th>
          <th style="text-align: left">è§£é‡Š</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">ä¿çœŸåº¦</td>
          <td style="text-align: left">$R^{2}\\r$</td>
          <td style="text-align: left">å¯è§£é‡Šæ•°æ®æ–¹å·®çš„æ¯”ä¾‹ $\\$ æ ‡ç­¾å’Œé¢„æµ‹çš„æ—¶é—´å¯¹é½</td>
      </tr>
      <tr>
          <td style="text-align: left">å»¶è¿Ÿ</td>
          <td style="text-align: left">åˆ†ç®±å»¶è¿Ÿ $\\$ å¤„ç†å»¶è¿Ÿ</td>
          <td style="text-align: left">æ¯æ¬¡æ¨ç†æ‰€éœ€çš„è¾“å…¥æ•°æ®æ—¶é—´è·¨åº¦ $\\$ ç”±ç®—æ³•è®¾è®¡å¸ˆä¼˜åŒ–çš„æ“ä½œå»¶è¿Ÿ</td>
      </tr>
      <tr>
          <td style="text-align: left">åŠŸè€—</td>
          <td style="text-align: left">æ€»æœ‰æ•ˆæ“ä½œ $\\$ å†…å­˜è®¿é—®</td>
          <td style="text-align: left">æ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆæ“ä½œæ•° $\\$ æ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆå†…å­˜è®¿é—®æ•°</td>
      </tr>
      <tr>
          <td style="text-align: left">å¤§å°</td>
          <td style="text-align: left">å†…å­˜å ç”¨</td>
          <td style="text-align: left">å­˜å‚¨è§£ç å™¨æ‰€éœ€çš„ä½æ•°</td>
      </tr>
  </tbody>
</table>
<h2 id="model-fidelity">Model fidelity<a hidden class="anchor" aria-hidden="true" href="#model-fidelity">#</a></h2>
<blockquote>
<p>The fidelity of a neural decoder in an iBCI is its ability to correctly classify or predict. In closed-loop iBCI, making accurate predictions is crucial for effective and reliable control of external devices or neural stimulations, which should closely reflect the subjectâ€™s intention or state.</p>
</blockquote>
<p>iBCI ä¸­ç¥ç»è§£ç å™¨çš„ä¿çœŸåº¦æ˜¯å…¶æ­£ç¡®åˆ†ç±»æˆ–é¢„æµ‹çš„èƒ½åŠ›ã€‚åœ¨é—­ç¯ iBCI ä¸­ï¼Œåšå‡ºå‡†ç¡®çš„é¢„æµ‹å¯¹äºæœ‰æ•ˆå¯é åœ°æ§åˆ¶å¤–éƒ¨è®¾å¤‡æˆ–ç¥ç»åˆºæ¿€è‡³å…³é‡è¦ï¼Œè¿™åº”ä¸å—è¯•è€…çš„æ„å›¾æˆ–çŠ¶æ€å¯†åˆ‡ç›¸å…³ã€‚</p>
<blockquote>
<p>Classification accuracy has traditionally been used to assess neural decoding performance by determining the percentage of correct classifications of stimuli, such as odors, faces, or speech. However, these metrics do not consider the temporal continuity of neural data, which is critical for many neural decoding applications. Neural decoding tasks require metrics that incorporate the correction of the temporal regression to evaluate decoding accuracy. In such cases, the coefficient of determination ($R^2$) and the coefficient of correlation (Pearson&rsquo;s $r$) are widely used to assess the performance of neural decoding algorithms.</p>
</blockquote>
<p>ä¼ ç»Ÿä¸Šï¼Œåˆ†ç±»å‡†ç¡®æ€§å·²è¢«ç”¨æ¥è¯„ä¼°ç¥ç»è§£ç æ€§èƒ½ï¼Œé€šè¿‡ç¡®å®šå¯¹åˆºæ¿€ï¼ˆå¦‚æ°”å‘³ã€é¢å­”æˆ–è¯­è¨€ï¼‰çš„æ­£ç¡®åˆ†ç±»çš„ç™¾åˆ†æ¯”ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡æ²¡æœ‰è€ƒè™‘ç¥ç»æ•°æ®çš„æ—¶é—´è¿ç»­æ€§ï¼Œè€Œè¿™å¯¹äºè®¸å¤šç¥ç»è§£ç åº”ç”¨è‡³å…³é‡è¦ã€‚ç¥ç»è§£ç ä»»åŠ¡éœ€è¦ç»“åˆæ—¶é—´å›å½’æ ¡æ­£çš„æŒ‡æ ‡æ¥è¯„ä¼°è§£ç ç²¾åº¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå†³å®šç³»æ•° ($R^2$) å’Œç›¸å…³ç³»æ•°ï¼ˆPearson çš„ $r$ï¼‰è¢«å¹¿æ³›ç”¨äºè¯„ä¼°ç¥ç»è§£ç ç®—æ³•çš„æ€§èƒ½ã€‚</p>
<blockquote>
<p>The $R^2$ measures the proportion of variance in the dependent variable explained by the modelâ€™s prediction, while Pearsonâ€™s $r$ evaluates the temporal alignment of the predictions and labels via a linear relationship. Both metrics should be reported to assess the temporal regression performance of the neural decoder comprehensively.</p>
</blockquote>
<p>$R^2$ è¡¡é‡æ¨¡å‹é¢„æµ‹è§£é‡Šçš„å› å˜é‡æ–¹å·®çš„æ¯”ä¾‹ï¼Œè€Œ Pearson çš„ $r$ é€šè¿‡çº¿æ€§å…³ç³»è¯„ä¼°é¢„æµ‹å’Œæ ‡ç­¾çš„æ—¶é—´å¯¹é½ã€‚åº”æŠ¥å‘Šè¿™ä¸¤ä¸ªæŒ‡æ ‡ï¼Œä»¥å…¨é¢è¯„ä¼°ç¥ç»è§£ç å™¨çš„æ—¶é—´å›å½’æ€§èƒ½ã€‚</p>
<h2 id="latency">Latency<a hidden class="anchor" aria-hidden="true" href="#latency">#</a></h2>
<blockquote>
<p>The latency of the neural decoder, defined as the time delay between the first input stimulus and the output response, comprises two architecture-specific subcomponents: the <em>binning latency</em> and the <em>processing latency</em> (see figure 3(c)). This allows for a platform- and architecture-agnostic evaluation of neural decoders.</p>
</blockquote>
<p>ç¥ç»è§£ç å™¨çš„å»¶è¿Ÿå®šä¹‰ä¸ºä»ç¬¬ä¸€ä¸ªè¾“å…¥åˆºæ¿€åˆ°è¾“å‡ºå“åº”ä¹‹é—´çš„æ—¶é—´å»¶è¿Ÿï¼ŒåŒ…æ‹¬ä¸¤ä¸ªç‰¹å®šäºæ¶æ„çš„å­ç»„ä»¶ï¼š<em>åˆ†ç®±å»¶è¿Ÿ</em> å’Œ <em>å¤„ç†å»¶è¿Ÿ</em>ï¼ˆè§å›¾ 3(c)ï¼‰ã€‚è¿™å…è®¸å¯¹ç¥ç»è§£ç å™¨è¿›è¡Œå¹³å°å’Œæ¶æ„æ— å…³çš„è¯„ä¼°ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/KBoVzx1DMlLnAOs.png" alt=""  /></p>
<p>Experimental pipeline for evaluating closed-loop capability of neural decoders. (a) A primate consecutively reaches for black boxes on a grid. Neural activity is recorded using one or two UTAH arrays placed at the primary motor and sensorimotor cortices, while finger position is tracked through an electromagnetic position sensor. Finger velocity is computed and used as a decoding target. (b) Neural activity is processed as a spike train, binned, and processed by the neural decoding system to predict finger velocity. (c) The visualization illustrates the latency of the entire decoding system, composed of binning latency and processing latency.</p>
</blockquote>
<p>è¯„ä¼°ç¥ç»è§£ç å™¨é—­ç¯èƒ½åŠ›çš„å®éªŒæµç¨‹ã€‚(a) çµé•¿ç±»åŠ¨ç‰©è¿ç»­åœ°ä¼¸æ‰‹å»æŠ“ç½‘æ ¼ä¸Šçš„é»‘è‰²ç›’å­ã€‚ä½¿ç”¨æ”¾ç½®åœ¨åˆçº§è¿åŠ¨çš®å±‚å’Œæ„Ÿè§‰è¿åŠ¨çš®å±‚çš„ä¸€ä¸ªæˆ–ä¸¤ä¸ª UTAH é˜µåˆ—è®°å½•ç¥ç»æ´»åŠ¨ï¼ŒåŒæ—¶é€šè¿‡ç”µç£ä½ç½®ä¼ æ„Ÿå™¨è·Ÿè¸ªæ‰‹æŒ‡ä½ç½®ã€‚è®¡ç®—æ‰‹æŒ‡é€Ÿåº¦å¹¶ç”¨ä½œè§£ç ç›®æ ‡ã€‚(b) ç¥ç»æ´»åŠ¨è¢«å¤„ç†ä¸ºè„‰å†²åºåˆ—ï¼Œè¿›è¡Œåˆ†ç®±ï¼Œå¹¶ç”±ç¥ç»è§£ç ç³»ç»Ÿå¤„ç†ä»¥é¢„æµ‹æ‰‹æŒ‡é€Ÿåº¦ã€‚(c) å¯è§†åŒ–è¯´æ˜äº†æ•´ä¸ªè§£ç ç³»ç»Ÿçš„å»¶è¿Ÿï¼Œç”±åˆ†ç®±å»¶è¿Ÿå’Œå¤„ç†å»¶è¿Ÿç»„æˆã€‚</p>
</blockquote>
<blockquote>
<p>The <em>binning latency</em> corresponds to the time span of the input data required for each prediction. This equates to the binning time window or the history of binning windows in the case of multiple windows. Minimizing binning window size is crucial for limiting total latency.</p>
</blockquote>
<p><em>åˆ†ç®±å»¶è¿Ÿ</em> å¯¹åº”äºæ¯æ¬¡é¢„æµ‹æ‰€éœ€çš„è¾“å…¥æ•°æ®çš„æ—¶é—´è·¨åº¦ã€‚è¿™ç›¸å½“äºåˆ†ç®±æ—¶é—´çª—å£ï¼Œæˆ–è€…åœ¨å¤šä¸ªçª—å£çš„æƒ…å†µä¸‹ä¸ºåˆ†ç®±çª—å£çš„å†å²ã€‚æœ€å°åŒ–åˆ†ç®±çª—å£å¤§å°å¯¹äºé™åˆ¶æ€»å»¶è¿Ÿè‡³å…³é‡è¦ã€‚</p>
<blockquote>
<p>The <em>processing latency</em> is caused by the processing time for a neural decoder to produce a prediction. This combines the operational delay of preprocessing, network inference, and postprocessing. The processing time is bound by a function of the systemâ€™s required effective operations per inference, which can be assessed by computing the effective <strong>multiply-and-accumulate (MAC)</strong> operations of neural decoder algorithms.
This definition ignores a potential speed-up of parallel processing, which would require binding the algorithm to hardware. Latency can be reported in wall time, such as absolute SI units, or relative system time, as the total number of clock cycles per inference. This paper reports latency in milliseconds, providing a more intuitive and user-centric perspective and allowing the reader to assess the systemâ€™s ability to deliver timely and accurate responses. Converting the processing latency into seconds requires platform-specific assumptions regarding the required clock cycles per operation, the clock frequency, and a systemâ€™s capability for parallel processing.
For the remainder of this paper, a clock frequency of 1 MHz and 3 MAC operations per clock cycle were assumed, to provide a more intuitive comparison of the latency of the evaluated decoders. For simplicity, one addition corresponding to the sparse synaptic operation of neurons in the SNN is assumed to be equivalent to one MAC in terms of required clock cycles.</p>
</blockquote>
<p><em>å¤„ç†å»¶è¿Ÿ</em> æ˜¯ç¥ç»è§£ç å™¨ç”Ÿæˆé¢„æµ‹æ‰€éœ€çš„å¤„ç†æ—¶é—´å¼•èµ·çš„ã€‚è¿™ç»“åˆäº†é¢„å¤„ç†ã€ç½‘ç»œæ¨ç†å’Œåå¤„ç†çš„æ“ä½œå»¶è¿Ÿã€‚å¤„ç†æ—¶é—´å—ç³»ç»Ÿæ¯æ¬¡æ¨ç†æ‰€éœ€çš„æœ‰æ•ˆæ“ä½œæ•°å‡½æ•°çš„çº¦æŸï¼Œå¯ä»¥é€šè¿‡è®¡ç®—ç¥ç»è§£ç å™¨ç®—æ³•çš„<strong>æœ‰æ•ˆä¹˜åŠ  (MAC)</strong> æ“ä½œæ¥è¯„ä¼°ã€‚
è¿™ä¸€å®šä¹‰å¿½ç•¥äº†å¹¶è¡Œå¤„ç†çš„æ½œåœ¨åŠ é€Ÿï¼Œè¿™å°†éœ€è¦å°†ç®—æ³•ç»‘å®šåˆ°ç¡¬ä»¶ã€‚å»¶è¿Ÿå¯ä»¥ä»¥å¢™æ—¶ï¼ˆä¾‹å¦‚ç»å¯¹ SI å•ä½ï¼‰æˆ–ç›¸å¯¹ç³»ç»Ÿæ—¶é—´ï¼ˆæ¯æ¬¡æ¨ç†çš„æ€»æ—¶é’Ÿå‘¨æœŸæ•°ï¼‰æŠ¥å‘Šã€‚æœ¬æ–‡ä»¥æ¯«ç§’ä¸ºå•ä½æŠ¥å‘Šå»¶è¿Ÿï¼Œæä¾›äº†æ›´ç›´è§‚å’Œä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è§†è§’ï¼Œå¹¶å…è®¸è¯»è€…è¯„ä¼°ç³»ç»Ÿæä¾›åŠæ—¶å‡†ç¡®å“åº”çš„èƒ½åŠ›ã€‚å°†å¤„ç†å»¶è¿Ÿè½¬æ¢ä¸ºç§’éœ€è¦å…³äºæ¯æ¬¡æ“ä½œæ‰€éœ€æ—¶é’Ÿå‘¨æœŸã€æ—¶é’Ÿé¢‘ç‡å’Œç³»ç»Ÿå¹¶è¡Œå¤„ç†èƒ½åŠ›çš„å¹³å°ç‰¹å®šå‡è®¾ã€‚
åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼Œå‡è®¾æ—¶é’Ÿé¢‘ç‡ä¸º 1 MHzï¼Œæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸ 3 æ¬¡ MAC æ“ä½œï¼Œä»¥æä¾›å¯¹è¯„ä¼°è§£ç å™¨å»¶è¿Ÿçš„æ›´ç›´è§‚æ¯”è¾ƒã€‚ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œå‡è®¾ä¸ SNN ä¸­ç¥ç»å…ƒç¨€ç–çªè§¦æ“ä½œå¯¹åº”çš„ä¸€æ¬¡åŠ æ³•åœ¨æ‰€éœ€æ—¶é’Ÿå‘¨æœŸæ–¹é¢ç­‰åŒäºä¸€æ¬¡ MACã€‚</p>
<h2 id="power-consumption">Power consumption<a hidden class="anchor" aria-hidden="true" href="#power-consumption">#</a></h2>
<blockquote>
<p>Power consumption is vital to evaluating neural decoders, particularly in resource-constrained iBCIs suitable for CLN. Local neural processing, which is implemented directly on an embedded device, is usually preferable to external processing due to latency, communication bandwidth, and privacy issues. However, local neural processing requires low energy consumption to minimize tissue heating.</p>
</blockquote>
<p>åŠŸè€—å¯¹äºè¯„ä¼°ç¥ç»è§£ç å™¨è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨é€‚ç”¨äº CLN çš„èµ„æºå—é™ iBCI ä¸­ã€‚ç›´æ¥åœ¨åµŒå…¥å¼è®¾å¤‡ä¸Šå®ç°çš„æœ¬åœ°ç¥ç»å¤„ç†é€šå¸¸ä¼˜äºå¤–éƒ¨å¤„ç†ï¼Œå› ä¸ºå­˜åœ¨å»¶è¿Ÿã€é€šä¿¡å¸¦å®½å’Œéšç§é—®é¢˜ã€‚ç„¶è€Œï¼Œæœ¬åœ°ç¥ç»å¤„ç†éœ€è¦ä½èƒ½è€—ä»¥æœ€å°åŒ–ç»„ç»‡åŠ çƒ­ã€‚</p>
<blockquote>
<p>To compare the energy efficiency of different neural decoders in a hardware- and architecture-independent manner, one can benchmark with two hardware-agnostic metrics: total effective operations and memory accesses. This considers only algorithmic optimizations, such as reducing effective operational costs. Although algorithm-hardware co-optimizations can further improve latency, performance, and energy efficacy, they require binding the neural decoder to specific hardware and, thus, are not considered in this study.</p>
</blockquote>
<p>ä¸ºäº†ä»¥ç¡¬ä»¶å’Œæ¶æ„æ— å…³çš„æ–¹å¼æ¯”è¾ƒä¸åŒç¥ç»è§£ç å™¨çš„èƒ½æ•ˆï¼Œå¯ä»¥ä½¿ç”¨ä¸¤ä¸ªç¡¬ä»¶æ— å…³çš„æŒ‡æ ‡è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼šæ€»æœ‰æ•ˆæ“ä½œå’Œå†…å­˜è®¿é—®ã€‚è¿™ä»…è€ƒè™‘ç®—æ³•ä¼˜åŒ–ï¼Œä¾‹å¦‚å‡å°‘æœ‰æ•ˆæ“ä½œæˆæœ¬ã€‚å°½ç®¡ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–å¯ä»¥è¿›ä¸€æ­¥æé«˜å»¶è¿Ÿã€æ€§èƒ½å’Œèƒ½é‡æ•ˆç‡ï¼Œä½†å®ƒä»¬éœ€è¦å°†ç¥ç»è§£ç å™¨ç»‘å®šåˆ°ç‰¹å®šç¡¬ä»¶ï¼Œå› æ­¤åœ¨æœ¬ç ”ç©¶ä¸­ä¸äºˆè€ƒè™‘ã€‚</p>
<blockquote>
<p>The total effective operations are reported as the number of non-zero operations required per inference. This combines two relevant operations that dominate neural network operations: multiplication and addition. To estimate the energy consumption of a neural decoder, however, total operations should be reported instead of MAC and ACC since these operations are assumed to be optimized by vector accelerators, which is the bottleneck for latency but does not reflect well on the energy cost of a neural decoder. To reduce energy consumption, neural decoders can exploit the sparsity of the spiking data by distinguishing between effective and ineffective operations. This accounts for only non-zeros contributing to the products and, consequently, the accumulation, which can be leveraged by specialized hardware. Reporting the effective computational cost as the number of non-zero operations allows for hardware-agnostic comparison of different networks, considering computational primitives in neuromorphic neural networks. In the remainder of this paper, MAC denotes effective MAC operations.</p>
</blockquote>
<p>æ€»æœ‰æ•ˆæ“ä½œæŠ¥å‘Šä¸ºæ¯æ¬¡æ¨ç†æ‰€éœ€çš„éé›¶æ“ä½œæ•°ã€‚è¿™ç»“åˆäº†ä¸»å¯¼ç¥ç»ç½‘ç»œæ“ä½œçš„ä¸¤ä¸ªç›¸å…³æ“ä½œï¼šä¹˜æ³•å’ŒåŠ æ³•ã€‚ç„¶è€Œï¼Œä¸ºäº†ä¼°è®¡ç¥ç»è§£ç å™¨çš„èƒ½è€—ï¼Œåº”æŠ¥å‘Šæ€»æ“ä½œæ•°è€Œä¸æ˜¯ MAC å’Œ ACCï¼Œå› ä¸ºè¿™äº›æ“ä½œå‡å®šç”±å‘é‡åŠ é€Ÿå™¨ä¼˜åŒ–ï¼Œè¿™æ˜¯å»¶è¿Ÿçš„ç“¶é¢ˆï¼Œä½†ä¸èƒ½å¾ˆå¥½åœ°åæ˜ ç¥ç»è§£ç å™¨çš„èƒ½é‡æˆæœ¬ã€‚ä¸ºäº†é™ä½èƒ½è€—ï¼Œç¥ç»è§£ç å™¨å¯ä»¥é€šè¿‡åŒºåˆ†æœ‰æ•ˆå’Œæ— æ•ˆæ“ä½œæ¥åˆ©ç”¨è„‰å†²æ•°æ®çš„ç¨€ç–æ€§ã€‚è¿™ä»…è€ƒè™‘å¯¹ä¹˜ç§¯å’Œå› æ­¤ç´¯ç§¯æœ‰è´¡çŒ®çš„éé›¶é¡¹ï¼Œè¿™å¯ä»¥è¢«ä¸“ç”¨ç¡¬ä»¶åˆ©ç”¨ã€‚å°†æœ‰æ•ˆè®¡ç®—æˆæœ¬æŠ¥å‘Šä¸ºéé›¶æ“ä½œæ•°å…è®¸å¯¹ä¸åŒç½‘ç»œè¿›è¡Œç¡¬ä»¶æ— å…³çš„æ¯”è¾ƒï¼Œè€ƒè™‘ç¥ç»å½¢æ€ç¥ç»ç½‘ç»œä¸­çš„è®¡ç®—åŸè¯­ã€‚åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼ŒMAC è¡¨ç¤ºæœ‰æ•ˆ MAC æ“ä½œã€‚</p>
<blockquote>
<p>Reporting memory access is crucial for comprehensively estimating the energy consumption of neural decoders. Because a read-and-write operation to the memory requires one to two orders of magnitude more energy than operations of arithmetic linear units, it is insufficient to report only effective operations without including the memory access. Furthermore, Liao et al report âˆ¼10Ã— more reads than effective operations during inference, highlighting that most of the energy consumption of an architecture comes from the memory read-and-write operations. Following their approach, the number of memory accesses in a network is conservatively estimated by assuming that a MAC operation consists of three loads and one store. By contrast, an ACC consists of two loads and one store, which both, similarly to before, need to be combined with the sparseness of activity of the network.</p>
</blockquote>
<p>æŠ¥å‘Šå†…å­˜è®¿é—®å¯¹äºå…¨é¢ä¼°è®¡ç¥ç»è§£ç å™¨çš„èƒ½è€—è‡³å…³é‡è¦ã€‚å› ä¸ºå¯¹å†…å­˜çš„è¯»å†™æ“ä½œæ‰€éœ€çš„èƒ½é‡æ¯”ç®—æœ¯çº¿æ€§å•å…ƒçš„æ“ä½œé«˜å‡ºä¸€ä¸ªåˆ°ä¸¤ä¸ªæ•°é‡çº§ï¼Œä»…æŠ¥å‘Šæœ‰æ•ˆæ“ä½œè€Œä¸åŒ…æ‹¬å†…å­˜è®¿é—®æ˜¯ä¸å¤Ÿçš„ã€‚æ­¤å¤–ï¼ŒLiao ç­‰äººåœ¨æ¨ç†è¿‡ç¨‹ä¸­æŠ¥å‘Šäº†å¤§çº¦ 10 å€äºæœ‰æ•ˆæ“ä½œçš„è¯»å–æ¬¡æ•°ï¼Œå¼ºè°ƒäº†æ¶æ„çš„å¤§éƒ¨åˆ†èƒ½è€—æ¥è‡ªå†…å­˜è¯»å†™æ“ä½œã€‚éµå¾ªä»–ä»¬çš„æ–¹æ³•ï¼Œé€šè¿‡å‡è®¾ MAC æ“ä½œç”±ä¸‰æ¬¡åŠ è½½å’Œä¸€æ¬¡å­˜å‚¨ç»„æˆï¼Œä¿å®ˆåœ°ä¼°è®¡ç½‘ç»œä¸­çš„å†…å­˜è®¿é—®æ¬¡æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒACC ç”±ä¸¤æ¬¡åŠ è½½å’Œä¸€æ¬¡å­˜å‚¨ç»„æˆï¼Œä¸ä¹‹å‰ç±»ä¼¼ï¼Œéƒ½éœ€è¦ä¸ç½‘ç»œæ´»åŠ¨çš„ç¨€ç–æ€§ç›¸ç»“åˆã€‚</p>
<h2 id="memory-footprint">Memory footprint<a hidden class="anchor" aria-hidden="true" href="#memory-footprint">#</a></h2>
<blockquote>
<p>Due to space volume constraints of iBCIs, the memory size, which in comparison to other function blocks consumes far more ASIC area, should be reported. If the memory requirements of the neural decoder are too large, external memory is required, which can consume more than 100Ã— more energy than on-chip memory. Estimating the memory footprint of a neural decoder involves calculating the sum of the networkâ€™s parameters and variables, as well as the memory requirements of input data from binning windows. The memory size should be reported in bits to provide credit to architectures that limit the precision of weights.</p>
</blockquote>
<p>ç”±äº iBCI çš„ç©ºé—´ä½“ç§¯é™åˆ¶ï¼Œå†…å­˜å¤§å°åº”äºˆä»¥æŠ¥å‘Šï¼Œå› ä¸ºä¸å…¶ä»–åŠŸèƒ½å—ç›¸æ¯”ï¼Œå®ƒæ¶ˆè€—äº†æ›´å¤šçš„ ASIC é¢ç§¯ã€‚å¦‚æœç¥ç»è§£ç å™¨çš„å†…å­˜éœ€æ±‚è¿‡å¤§ï¼Œåˆ™éœ€è¦å¤–éƒ¨å†…å­˜ï¼Œå…¶èƒ½è€—å¯èƒ½è¶…è¿‡ç‰‡ä¸Šå†…å­˜çš„ 100 å€ã€‚ä¼°è®¡ç¥ç»è§£ç å™¨çš„å†…å­˜å ç”¨æ¶‰åŠè®¡ç®—ç½‘ç»œå‚æ•°å’Œå˜é‡çš„æ€»å’Œï¼Œä»¥åŠæ¥è‡ªåˆ†ç®±çª—å£çš„è¾“å…¥æ•°æ®çš„å†…å­˜éœ€æ±‚ã€‚å†…å­˜å¤§å°åº”ä»¥ä½ä¸ºå•ä½æŠ¥å‘Šï¼Œä»¥è¡¨å½°é™åˆ¶æƒé‡ç²¾åº¦çš„æ¶æ„ã€‚</p>
<h1 id="methods">Methods<a hidden class="anchor" aria-hidden="true" href="#methods">#</a></h1>
<blockquote>
<p>The methodology is structured into five subsections, addressing how this study evaluates and benchmarks various neural decoders within the context of iBCI for CLN. The first subsection provides an overview of the neural data utilized in this benchmark, which comprises neural activity recorded from non-human primates, representing a relevant scenario for closed-loop iBCI applications. Decoders are categorized into three main groups: traditional neural decoders, artificial neural networks (ANN)-based neural decoders, and neuromorphic spiking neural network (SNN)-based decoders. The selection of traditional and ANN decoders was based on existing literature, while the long short-term memory (LSTM) and SNN-based decoders were optimized for this study. The presented decoders are non-exhaustive (the interested reader is referred to recently proposed models), yet the decoders aim to represent commonly used neural decoding methods. The final subsection outlines the experimental setup and details the conditions and parameters under which the benchmark was conducted. These methodological components provide a detailed pipeline for evaluating neural decoding methods for closed-loop iBCI applications.</p>
</blockquote>
<p>è¯¥æ–¹æ³•åˆ†ä¸ºäº”ä¸ªå­éƒ¨åˆ†ï¼Œè§£å†³äº†æœ¬ç ”ç©¶å¦‚ä½•åœ¨ CLN çš„ iBCI èƒŒæ™¯ä¸‹è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•å„ç§ç¥ç»è§£ç å™¨ã€‚ç¬¬ä¸€ä¸ªå­éƒ¨åˆ†æ¦‚è¿°äº†æœ¬åŸºå‡†æµ‹è¯•ä¸­ä½¿ç”¨çš„ç¥ç»æ•°æ®ï¼Œè¿™äº›æ•°æ®åŒ…æ‹¬ä»éäººç±»çµé•¿ç±»åŠ¨ç‰©è®°å½•çš„ç¥ç»æ´»åŠ¨ï¼Œä»£è¡¨äº†é—­ç¯ iBCI åº”ç”¨çš„ç›¸å…³åœºæ™¯ã€‚è§£ç å™¨åˆ†ä¸ºä¸‰å¤§ç±»ï¼šä¼ ç»Ÿç¥ç»è§£ç å™¨ã€åŸºäºäººå·¥ç¥ç»ç½‘ç»œ (ANN) çš„ç¥ç»è§£ç å™¨å’ŒåŸºäºç¥ç»å½¢æ€è„‰å†²ç¥ç»ç½‘ç»œ (SNN) çš„è§£ç å™¨ã€‚ä¼ ç»Ÿå’Œ ANN è§£ç å™¨çš„é€‰æ‹©åŸºäºç°æœ‰æ–‡çŒ®ï¼Œè€Œé•¿çŸ­æœŸè®°å¿† (LSTM) å’Œ SNN åŸºè§£ç å™¨åˆ™é’ˆå¯¹æœ¬ç ”ç©¶è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ‰€å‘ˆç°çš„è§£ç å™¨å¹¶éè¯¦å°½æ— é—ï¼ˆæœ‰å…´è¶£çš„è¯»è€…å¯å‚è€ƒæœ€è¿‘æå‡ºçš„æ¨¡å‹ï¼‰ï¼Œä½†è¿™äº›è§£ç å™¨æ—¨åœ¨ä»£è¡¨å¸¸ç”¨çš„ç¥ç»è§£ç æ–¹æ³•ã€‚æœ€åä¸€ä¸ªå­éƒ¨åˆ†æ¦‚è¿°äº†å®éªŒè®¾ç½®ï¼Œå¹¶è¯¦ç»†è¯´æ˜äº†è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„æ¡ä»¶å’Œå‚æ•°ã€‚è¿™äº›æ–¹æ³•è®ºç»„ä»¶ä¸ºè¯„ä¼°é—­ç¯ iBCI åº”ç”¨çš„ç¥ç»è§£ç æ–¹æ³•æä¾›äº†è¯¦ç»†çš„æµç¨‹ã€‚</p>
<h2 id="neural-recording-dataset">Neural recording dataset<a hidden class="anchor" aria-hidden="true" href="#neural-recording-dataset">#</a></h2>
<blockquote>
<p>The ANN and SNN neural decoders were trained and benchmarked on the â€˜primate reaching taskâ€™ of the neuromorphic benchmark NeuroBench, as visualized in figures 3(a) and (b). This benchmark employs the same data as Makin et al, which previously were used to evaluate their traditional decoders. The $R^{2}$ value published by Makin et al is reported here, and the metrics for power consumption and latency are calculated conservatively based on the most time-consuming and energy-intensive matrix operations, as defined in Chapters 4.2 and Chapter 4.3.</p>
</blockquote>
<p>ANN å’Œ SNN ç¥ç»è§£ç å™¨åœ¨ç¥ç»å½¢æ€åŸºå‡† NeuroBench çš„â€œçµé•¿ç±»åŠ¨ç‰©ä¼¸æ‰‹ä»»åŠ¡â€ä¸Šè¿›è¡Œäº†è®­ç»ƒå’ŒåŸºå‡†æµ‹è¯•ï¼Œå¦‚å›¾ 3(a) å’Œ (b) æ‰€ç¤ºã€‚è¯¥åŸºå‡†æµ‹è¯•ä½¿ç”¨ä¸ Makin ç­‰äººç›¸åŒçš„æ•°æ®ï¼Œä¹‹å‰ç”¨äºè¯„ä¼°ä»–ä»¬çš„ä¼ ç»Ÿè§£ç å™¨ã€‚è¿™é‡ŒæŠ¥å‘Šäº† Makin ç­‰äººå‘å¸ƒçš„ $R^{2}$ å€¼ï¼Œå¹¶æ ¹æ®ç¬¬ 4.2 ç« å’Œç¬¬ 4.3 ç« ä¸­å®šä¹‰çš„æœ€è€—æ—¶å’Œæœ€è€—èƒ½çš„çŸ©é˜µæ“ä½œï¼Œä¿å®ˆåœ°è®¡ç®—äº†åŠŸè€—å’Œå»¶è¿Ÿçš„æŒ‡æ ‡ã€‚</p>
<blockquote>
<p>The dataset is a subset of 6 out of 33 recording sessions of 2 Rhesus primates during subsequent reaching tasks as shown in figure 3(a), which was released by Dyer et al. These sessions encompassed two non-human primates (NHPs) and the entire recording period. Three NHP â€˜Iâ€™ sessions were recorded using a 96-channel Utah array from Blackrock Neurotech implanted in the primary motor cortex. The three NHP â€˜Lâ€™ sessions had an additional Utah array in the sensorimotor cortex, enabling the simultaneous recording of 192 channels. Each recording session comprises 354â€“819 individual reaches, and those longer than 8 s were discarded as they indicate the primateâ€™s inattention.</p>
</blockquote>
<p>è¯¥æ•°æ®é›†æ˜¯ Dyer ç­‰äººå‘å¸ƒçš„ 2 åªæ’æ²³çŒ´åœ¨éšåçš„ä¼¸æ‰‹ä»»åŠ¡æœŸé—´çš„ 33 ä¸ªè®°å½•ä¼šè¯ä¸­çš„ 6 ä¸ªå­é›†ï¼Œå¦‚å›¾ 3(a) æ‰€ç¤ºã€‚è¿™äº›ä¼šè¯æ¶µç›–äº†ä¸¤åªéäººç±»çµé•¿ç±»åŠ¨ç‰© (NHPs) å’Œæ•´ä¸ªè®°å½•æœŸã€‚ä¸‰æ¬¡ NHPâ€œIâ€ä¼šè¯ä½¿ç”¨ Blackrock Neurotech æ¤å…¥åˆçº§è¿åŠ¨çš®å±‚çš„ 96 é€šé“ Utah é˜µåˆ—è¿›è¡Œè®°å½•ã€‚ä¸‰æ¬¡ NHPâ€œLâ€ä¼šè¯åœ¨æ„Ÿè§‰è¿åŠ¨çš®å±‚ä¸­å¢åŠ äº†ä¸€ä¸ª Utah é˜µåˆ—ï¼Œå®ç°äº† 192 é€šé“çš„åŒæ—¶è®°å½•ã€‚æ¯ä¸ªè®°å½•ä¼šè¯åŒ…æ‹¬ 354-819 æ¬¡å•ç‹¬çš„ä¼¸æ‰‹åŠ¨ä½œï¼Œè¶…è¿‡ 8 ç§’çš„åŠ¨ä½œè¢«ä¸¢å¼ƒï¼Œå› ä¸ºå®ƒä»¬è¡¨æ˜çµé•¿ç±»åŠ¨ç‰©ä¸ä¸“å¿ƒã€‚</p>
<blockquote>
<p>Spikes were detected from the raw neural data using a threshold of 3.5â€“4 times the root-mean-square (RMS) noise. The finger position was recorded using an electromagnetic position sensor at 250 Hz, and the velocity was computed as the discrete gradient of the position. Predicting the translation invariant finger velocity better aligns with the natural dynamics of limb movements and corresponds to how neural activity encodes kinematics. Makin et al, and Dyer et al report the detailed experimental setup and the data acquisition.</p>
</blockquote>
<p>ä»åŸå§‹ç¥ç»æ•°æ®ä¸­ä½¿ç”¨ 3.5-4 å€å‡æ–¹æ ¹ (RMS) å™ªå£°çš„é˜ˆå€¼æ£€æµ‹è„‰å†²ã€‚æ‰‹æŒ‡ä½ç½®ä½¿ç”¨ç”µç£ä½ç½®ä¼ æ„Ÿå™¨ä»¥ 250 Hz çš„é¢‘ç‡è®°å½•ï¼Œå¹¶è®¡ç®—ä¸ºä½ç½®çš„ç¦»æ•£æ¢¯åº¦ã€‚é¢„æµ‹å¹³ç§»ä¸å˜çš„æ‰‹æŒ‡é€Ÿåº¦æ›´å¥½åœ°ç¬¦åˆè‚¢ä½“è¿åŠ¨çš„è‡ªç„¶åŠ¨æ€ï¼Œå¹¶ä¸”ä¸ç¥ç»æ´»åŠ¨å¦‚ä½•ç¼–ç è¿åŠ¨å­¦ç›¸å¯¹åº”ã€‚Makin ç­‰äººå’Œ Dyer ç­‰äººæŠ¥å‘Šäº†è¯¦ç»†çš„å®éªŒè®¾ç½®å’Œæ•°æ®é‡‡é›†ã€‚</p>
<h2 id="traditional-neural-decoders">Traditional neural decoders<a hidden class="anchor" aria-hidden="true" href="#traditional-neural-decoders">#</a></h2>
<blockquote>
<p>Classic neural decoding methods have been extensively used in brain-computer interfacing. Of the six decoders Makin et al presented, the three best-performing models were selected to represent traditional neural decoders. Those decoders are the â€˜unscentedâ€™ Kalman Filter (UKF), the static, and the dynamic â€˜recurrent exponential-family harmoniumâ€™ (rEFH), and they are evaluated due to their established performance and versatility in handling various neural data modalities. Makin et al also considered linear regression, conventional KF, and Wiener filter. However, since these decoders had worse $R^{2}$ performance and scaled poorly with decreasing binning windows, they were not considered suitable for this neural decoding benchmark for closed-loop iBCIs suitable for CLN.</p>
</blockquote>
<p>ç»å…¸ç¥ç»è§£ç æ–¹æ³•å·²è¢«å¹¿æ³›ç”¨äºè„‘æœºæ¥å£ã€‚åœ¨ Makin ç­‰äººæå‡ºçš„å…­ç§è§£ç å™¨ä¸­ï¼Œé€‰æ‹©äº†è¡¨ç°æœ€å¥½çš„ä¸‰ç§æ¨¡å‹æ¥ä»£è¡¨ä¼ ç»Ÿç¥ç»è§£ç å™¨ã€‚è¿™äº›è§£ç å™¨æ˜¯â€œæ— è¿¹â€å¡å°”æ›¼æ»¤æ³¢å™¨ (UKF)ã€é™æ€å’ŒåŠ¨æ€â€œé€’å½’æŒ‡æ•°æ—è°æŒ¯å™¨â€ (rEFH)ï¼Œç”±äºå…¶åœ¨å¤„ç†å„ç§ç¥ç»æ•°æ®æ¨¡æ€æ–¹é¢çš„æ—¢å®šæ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§è€Œè¿›è¡Œè¯„ä¼°ã€‚Makin ç­‰äººè¿˜è€ƒè™‘äº†çº¿æ€§å›å½’ã€ä¼ ç»Ÿ KF å’Œ Wiener æ»¤æ³¢å™¨ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›è§£ç å™¨çš„ $R^{2}$ æ€§èƒ½è¾ƒå·®ï¼Œå¹¶ä¸”éšç€åˆ†ç®±çª—å£çš„å‡å°è€Œæ‰©å±•æ€§å·®ï¼Œå› æ­¤å®ƒä»¬ä¸é€‚åˆç”¨äºé€‚ç”¨äº CLN çš„é—­ç¯ iBCI çš„ç¥ç»è§£ç åŸºå‡†æµ‹è¯•ã€‚</p>
<blockquote>
<p>The UKF approximates the state distribution by applying a full nonlinearity to a minimal set of carefully selected representative points. It was designed as an extension of the KF to address the problem of its exploding residuals on the true posterior mean and covariance. The UKF solves this by replacing the normal sampled state distribution with a deterministic sampling of this distribution. The UKF, as described by Makin et al and Wan et al, has a state space of deterministically sampled 40 variables, which  requires $O (n^3/6)$ operations due to Cholesky decomposition. As a conservative estimate of the processing latency and the operational cost, only matrix multiplications required during inference and the computationally intensive matrix inversion were considered. This large-scale matrix inversion was assumed to require at least 200 ms.</p>
</blockquote>
<p>UKF é€šè¿‡å¯¹ç²¾å¿ƒé€‰æ‹©çš„ä»£è¡¨ç‚¹é›†åº”ç”¨å®Œæ•´çš„éçº¿æ€§æ¥è¿‘ä¼¼çŠ¶æ€åˆ†å¸ƒã€‚å®ƒè¢«è®¾è®¡ä¸º KF çš„æ‰©å±•ï¼Œä»¥è§£å†³å…¶åœ¨çœŸå®åéªŒå‡å€¼å’Œåæ–¹å·®ä¸Šçš„æ®‹å·®çˆ†ç‚¸é—®é¢˜ã€‚UKF é€šè¿‡ç”¨è¯¥åˆ†å¸ƒçš„ç¡®å®šæ€§é‡‡æ ·æ›¿æ¢æ­£å¸¸é‡‡æ ·çš„çŠ¶æ€åˆ†å¸ƒæ¥è§£å†³æ­¤é—®é¢˜ã€‚æ­£å¦‚ Makin ç­‰äººå’Œ Wan ç­‰äººæ‰€æè¿°çš„é‚£æ ·ï¼ŒUKF å…·æœ‰ç¡®å®šæ€§é‡‡æ ·çš„ 40 ä¸ªå˜é‡çš„çŠ¶æ€ç©ºé—´ï¼Œç”±äº Cholesky åˆ†è§£éœ€è¦ $O (n^3/6)$ æ“ä½œã€‚ä½œä¸ºå¤„ç†å»¶è¿Ÿå’Œæ“ä½œæˆæœ¬çš„ä¿å®ˆä¼°è®¡ï¼Œä»…è€ƒè™‘äº†æ¨ç†è¿‡ç¨‹ä¸­æ‰€éœ€çš„çŸ©é˜µä¹˜æ³•å’Œè®¡ç®—å¯†é›†å‹çŸ©é˜µæ±‚é€†ã€‚å‡è®¾è¿™ç§å¤§è§„æ¨¡çŸ©é˜µæ±‚é€†è‡³å°‘éœ€è¦ 200 æ¯«ç§’ã€‚</p>
<blockquote>
<p>The rEFH, instead of assuming Gaussian state variables, models the state variables as a variant of a restricted Boltzmann Machine (RBM) and explicitly samples the spike count from a Poisson distribution. The static variant converts the latent space of the RBM into kinematics via static mapping, that is, a matrix multiplication, whereas the dynamic version uses a KF. For the static and the dynamic rEFH models, only the forward pass of the RBM uses higher-dimensional matrix multiplications, and thus is considered. There are four times as many hidden neurons in the RBM than there are input channels and 1800 output neurons mapped to the kinematic output via either a matrix multiplication or a KF. All traditional decoders were evaluated using binning windows of 16 ms, 32 ms, 64 ms, and 128 ms.</p>
</blockquote>
<p>rEFH ä¸å‡è®¾é«˜æ–¯çŠ¶æ€å˜é‡ï¼Œè€Œæ˜¯å°†çŠ¶æ€å˜é‡å»ºæ¨¡ä¸ºå—é™ç»å°”å…¹æ›¼æœº (RBM) çš„å˜ä½“ï¼Œå¹¶æ˜ç¡®åœ°ä»æ³Šæ¾åˆ†å¸ƒä¸­é‡‡æ ·è„‰å†²è®¡æ•°ã€‚é™æ€å˜ä½“é€šè¿‡é™æ€æ˜ å°„ï¼ˆå³çŸ©é˜µä¹˜æ³•ï¼‰å°† RBM çš„æ½œåœ¨ç©ºé—´è½¬æ¢ä¸ºè¿åŠ¨å­¦ï¼Œè€ŒåŠ¨æ€ç‰ˆæœ¬åˆ™ä½¿ç”¨ KFã€‚å¯¹äºé™æ€å’ŒåŠ¨æ€ rEFH æ¨¡å‹ï¼Œä»… RBM çš„å‰å‘ä¼ é€’ä½¿ç”¨æ›´é«˜ç»´çš„çŸ©é˜µä¹˜æ³•ï¼Œå› æ­¤äºˆä»¥è€ƒè™‘ã€‚RBM ä¸­çš„éšè—ç¥ç»å…ƒæ•°é‡æ˜¯è¾“å…¥é€šé“æ•°é‡çš„å››å€ï¼Œ1800 ä¸ªè¾“å‡ºç¥ç»å…ƒé€šè¿‡çŸ©é˜µä¹˜æ³•æˆ– KF æ˜ å°„åˆ°è¿åŠ¨å­¦è¾“å‡ºã€‚æ‰€æœ‰ä¼ ç»Ÿè§£ç å™¨å‡ä½¿ç”¨ 16 æ¯«ç§’ã€32 æ¯«ç§’ã€64 æ¯«ç§’å’Œ 128 æ¯«ç§’çš„åˆ†ç®±çª—å£è¿›è¡Œè¯„ä¼°ã€‚</p>
<h2 id="anns">ANNs<a hidden class="anchor" aria-hidden="true" href="#anns">#</a></h2>
<blockquote>
<p>This study used two ANN-based decoders as baselines owing to their established history of high-accuracy predictions. Previous studies have demonstrated that ANN-based decoders perform on par or better than traditional decoders. One fully connected ANN, published as a baseline for the NeuroBench benchmark, and one LSTM network were evaluated.</p>
</blockquote>
<p>æœ¬ç ”ç©¶ä½¿ç”¨äº†ä¸¤ä¸ªåŸºäº ANN çš„è§£ç å™¨ä½œä¸ºåŸºçº¿ï¼Œå› å…¶åœ¨é«˜ç²¾åº¦é¢„æµ‹æ–¹é¢çš„æ—¢å®šå†å²ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäº ANN çš„è§£ç å™¨çš„æ€§èƒ½ä¸ä¼ ç»Ÿè§£ç å™¨ç›¸å½“æˆ–æ›´å¥½ã€‚è¯„ä¼°äº†ä¸€ä¸ªä½œä¸º NeuroBench åŸºå‡†åŸºçº¿å‘å¸ƒçš„å…¨è¿æ¥ ANN å’Œä¸€ä¸ª LSTM ç½‘ç»œã€‚</p>
<blockquote>
<p>The ANN is a conventional 3-layer feedforward network with 32 and 48 hidden and two output neurons, respectively. This implementation uses a history of multiple non-overlapping binning windows that are flattened and processed as input data. The default implementation, including the history of 7 binning windows, is shown in figure 4(a). To explore the latency versus fidelity trade-off, a history of 4, 7, and 14 binning windows of 28 ms was considered, and the number of neurons in the hidden layers halved and doubled.</p>
</blockquote>
<p>ANN æ˜¯ä¸€ä¸ªä¼ ç»Ÿçš„ä¸‰å±‚å‰é¦ˆç½‘ç»œï¼Œåˆ†åˆ«å…·æœ‰ 32 ä¸ªå’Œ 48 ä¸ªéšè—ç¥ç»å…ƒä»¥åŠä¸¤ä¸ªè¾“å‡ºç¥ç»å…ƒã€‚è¯¥å®ç°ä½¿ç”¨å¤šä¸ªä¸é‡å åˆ†ç®±çª—å£çš„å†å²è®°å½•ï¼Œè¿™äº›çª—å£è¢«å±•å¹³å¹¶ä½œä¸ºè¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ã€‚é»˜è®¤å®ç°åŒ…æ‹¬ 7 ä¸ªåˆ†ç®±çª—å£çš„å†å²ï¼Œå¦‚å›¾ 4(a) æ‰€ç¤ºã€‚ä¸ºäº†æ¢ç´¢å»¶è¿Ÿä¸ä¿çœŸåº¦çš„æƒè¡¡ï¼Œè€ƒè™‘äº† 28 æ¯«ç§’çš„ 4ã€7 å’Œ 14 ä¸ªåˆ†ç®±çª—å£çš„å†å²è®°å½•ï¼Œå¹¶å°†éšè—å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡å‡åŠå’ŒåŠ å€ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/3JgGOtPwVYcEkfH.png" alt=""  /></p>
<p>Architecture of three neural network-based decoders. The data extraction and binning are visualized in red, and the network architecture in blue. Each layerâ€™s dimensions and type are stated above and below, respectively.
(a) The ANN uses seven binning windows spanning 28 ms as input. These extracted windows are flattened and processed by two hidden layers with 32 and 48 Neurons, respectively.
(b) The LSTM extracts spikes with a temporal resolution of 4 milliseconds, effectively representing the neural data as a spike train. Then, the data undergoes dimensionality reduction via a fully connected (FC) layer with 16 neurons, after which a long short-term memory (LSTM) cell is employed.
(c) Similarly, the SNN decoder extracts the spike train and processes it through a network featuring 50 hidden Leaky Integrate-and-Fire (LIF) neurons. The final output of this network comprises the membrane potential of two LIF neurons.</p>
</blockquote>
<p>ä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨çš„æ¶æ„ã€‚æ•°æ®æå–å’Œåˆ†ç®±ä»¥çº¢è‰²å¯è§†åŒ–ï¼Œç½‘ç»œæ¶æ„ä»¥è“è‰²å¯è§†åŒ–ã€‚æ¯ä¸€å±‚çš„ç»´åº¦å’Œç±»å‹åˆ†åˆ«åœ¨ä¸Šæ–¹å’Œä¸‹æ–¹è¯´æ˜ã€‚
(a) ANN ä½¿ç”¨è·¨è¶Š 28 æ¯«ç§’çš„ä¸ƒä¸ªåˆ†ç®±çª—å£ä½œä¸ºè¾“å…¥ã€‚è¿™äº›æå–çš„çª—å£è¢«å±•å¹³ï¼Œå¹¶åˆ†åˆ«ç”±ä¸¤ä¸ªå…·æœ‰ 32 å’Œ 48 ä¸ªç¥ç»å…ƒçš„éšè—å±‚å¤„ç†ã€‚
(b) LSTM ä»¥ 4 æ¯«ç§’çš„æ—¶é—´åˆ†è¾¨ç‡æå–è„‰å†²ï¼Œæœ‰æ•ˆåœ°å°†ç¥ç»æ•°æ®è¡¨ç¤ºä¸ºè„‰å†²åºåˆ—ã€‚ç„¶åï¼Œæ•°æ®é€šè¿‡å…·æœ‰ 16 ä¸ªç¥ç»å…ƒçš„å…¨è¿æ¥ (FC) å±‚è¿›è¡Œé™ç»´ï¼Œä¹‹åä½¿ç”¨é•¿çŸ­æœŸè®°å¿† (LSTM) å•å…ƒã€‚
(c) ç±»ä¼¼åœ°ï¼ŒSNN è§£ç å™¨æå–è„‰å†²åºåˆ—ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå…·æœ‰ 50 ä¸ªéšè—æ³„æ¼ç§¯åˆ†ä¸å‘æ”¾ (LIF) ç¥ç»å…ƒçš„ç½‘ç»œè¿›è¡Œå¤„ç†ã€‚è¯¥ç½‘ç»œçš„æœ€ç»ˆè¾“å‡ºåŒ…æ‹¬ä¸¤ä¸ª LIF ç¥ç»å…ƒçš„è†œç”µä½ã€‚</p>
</blockquote>
<blockquote>
<p>The LSTM, as shown in figure 4(b), uses a fully connected layer to reduce the input dimensionality to 16, followed by a single LSTM cell with 16 hidden neurons. A feedforward layer returns the predicted kinematics. Similar to the ANN, binning windows of 4 ms, 8 ms, and 16 ms and wider networks, with 64 and 128 hidden neurons, were examined. The networks use batch normalization (BatchNorm) and layer normalization (LayerNorm), respectively, and use Dropout.</p>
</blockquote>
<p>LSTM å¦‚å›¾ 4(b) æ‰€ç¤ºï¼Œä½¿ç”¨å…¨è¿æ¥å±‚å°†è¾“å…¥ç»´åº¦é™ä½åˆ° 16ï¼Œéšåæ˜¯ä¸€ä¸ªå…·æœ‰ 16 ä¸ªéšè—ç¥ç»å…ƒçš„å•ä¸ª LSTM å•å…ƒã€‚ä¸€ä¸ªå‰é¦ˆå±‚è¿”å›é¢„æµ‹çš„è¿åŠ¨å­¦ã€‚ä¸ ANN ç±»ä¼¼ï¼Œæ£€æŸ¥äº† 4 æ¯«ç§’ã€8 æ¯«ç§’å’Œ 16 æ¯«ç§’çš„åˆ†ç®±çª—å£ä»¥åŠå…·æœ‰ 64 å’Œ 128 ä¸ªéšè—ç¥ç»å…ƒçš„æ›´å®½ç½‘ç»œã€‚ç½‘ç»œåˆ†åˆ«ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ– (BatchNorm) å’Œå±‚å½’ä¸€åŒ– (LayerNorm)ï¼Œå¹¶ä½¿ç”¨ Dropoutã€‚</p>
<h2 id="snn">SNN<a hidden class="anchor" aria-hidden="true" href="#snn">#</a></h2>
<blockquote>
<p>SNNs are a variant of neural networks that attempt to mimic the properties, processes, and functions of biological neurons. This makes them inherently recurrent and allows them to exploit sparsity to achieve lower latency and power consumption. SNNs, at their core consist of stateful spiking neurons, a more bio-plausible variant of the Perceptron, with the leaky integrate-and-fire (LIF) being the most widely used neuron model. As the Perceptron, the LIF weighs and accumulates the input, but instead of returning this weighted accumulation, it is added to the neuronâ€™s membrane potential. If the membrane potential exceeds a threshold, the neuron produces a binary output, that is, a spike, and the membrane potential is reset; otherwise, it decays per time step, as conceptually illustrated in figure 5. This enables the neuron to combine information over multiple time steps, making it inherently recurrent. In addition to their binary output, LIF neurons exploit binary input data, enabling sparsity in networks built around these neurons. The binary input separates the operations into effective and ineffective because multiplications by zero do not contribute to the accumulation. Therefore, the multiplication of weights times input can be forgone by adding only non-zero weights.</p>
</blockquote>
<p>SNN æ˜¯ç¥ç»ç½‘ç»œçš„ä¸€ç§å˜ä½“ï¼Œè¯•å›¾æ¨¡ä»¿ç”Ÿç‰©ç¥ç»å…ƒçš„å±æ€§ã€è¿‡ç¨‹å’ŒåŠŸèƒ½ã€‚è¿™ä½¿å®ƒä»¬æœ¬è´¨ä¸Šæ˜¯é€’å½’çš„ï¼Œå¹¶å…è®¸å®ƒä»¬åˆ©ç”¨ç¨€ç–æ€§æ¥å®ç°æ›´ä½çš„å»¶è¿Ÿå’ŒåŠŸè€—ã€‚SNN çš„æ ¸å¿ƒç”±æœ‰çŠ¶æ€çš„è„‰å†²ç¥ç»å…ƒç»„æˆï¼Œè¿™æ˜¯ä¸€ç§æ›´ç¬¦åˆç”Ÿç‰©å­¦çš„æ„ŸçŸ¥å™¨å˜ä½“ï¼Œå…¶ä¸­æ³„æ¼ç§¯åˆ†ä¸å‘æ”¾ (LIF) æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„ç¥ç»å…ƒæ¨¡å‹ã€‚ä¸æ„ŸçŸ¥å™¨ä¸€æ ·ï¼ŒLIF å¯¹è¾“å…¥è¿›è¡ŒåŠ æƒå’Œç´¯ç§¯ï¼Œä½†ä¸æ˜¯è¿”å›è¿™ç§åŠ æƒç´¯ç§¯ï¼Œè€Œæ˜¯å°†å…¶æ·»åŠ åˆ°ç¥ç»å…ƒçš„è†œç”µä½ä¸­ã€‚å¦‚æœè†œç”µä½è¶…è¿‡é˜ˆå€¼ï¼Œç¥ç»å…ƒä¼šäº§ç”ŸäºŒè¿›åˆ¶è¾“å‡ºï¼Œå³è„‰å†²ï¼Œå¹¶ä¸”è†œç”µä½ä¼šè¢«é‡ç½®ï¼›å¦åˆ™ï¼Œå®ƒä¼šéšç€æ—¶é—´æ­¥é•¿è€Œè¡°å‡ï¼Œå¦‚å›¾ 5 æ‰€ç¤ºçš„æ¦‚å¿µæ€§è¯´æ˜ã€‚è¿™ä½¿å¾—ç¥ç»å…ƒèƒ½å¤Ÿåœ¨å¤šä¸ªæ—¶é—´æ­¥é•¿ä¸Šç»“åˆä¿¡æ¯ï¼Œä½¿å…¶æœ¬è´¨ä¸Šæ˜¯é€’å½’çš„ã€‚é™¤äº†å®ƒä»¬çš„äºŒè¿›åˆ¶è¾“å‡ºå¤–ï¼ŒLIF ç¥ç»å…ƒè¿˜åˆ©ç”¨äºŒè¿›åˆ¶è¾“å…¥æ•°æ®ï¼Œä½¿å›´ç»•è¿™äº›ç¥ç»å…ƒæ„å»ºçš„ç½‘ç»œå…·æœ‰ç¨€ç–æ€§ã€‚äºŒè¿›åˆ¶è¾“å…¥å°†æ“ä½œåˆ†ä¸ºæœ‰æ•ˆå’Œæ— æ•ˆï¼Œå› ä¸ºä¹˜ä»¥é›¶ä¸ä¼šå¯¹ç´¯ç§¯äº§ç”Ÿè´¡çŒ®ã€‚å› æ­¤ï¼Œå¯ä»¥é€šè¿‡ä»…æ·»åŠ éé›¶æƒé‡æ¥çœç•¥æƒé‡ä¹˜ä»¥è¾“å…¥çš„ä¹˜æ³•ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/c3YEUKxOylTe856.png" alt=""  /></p>
<p>A scheme of the LIF neuron. In this neuron model, incoming neural signals are integrated into the membrane potential, and if the accumulated value surpasses a specified threshold, the neuron generates a binary output signal. The â€˜leakyâ€™ property allows for the gradual decay of the accumulated charge, further contributing to the modelâ€™s simplicity. The intrinsic recurrent nature of the LIF neuron originates in the updated membrane potential.</p>
</blockquote>
<p>LIF ç¥ç»å…ƒçš„ç¤ºæ„å›¾ã€‚åœ¨è¿™ç§ç¥ç»å…ƒæ¨¡å‹ä¸­ï¼Œä¼ å…¥çš„ç¥ç»ä¿¡å·è¢«æ•´åˆåˆ°è†œç”µä½ä¸­ï¼Œå¦‚æœç´¯ç§¯å€¼è¶…è¿‡æŒ‡å®šçš„é˜ˆå€¼ï¼Œç¥ç»å…ƒä¼šäº§ç”ŸäºŒè¿›åˆ¶è¾“å‡ºä¿¡å·ã€‚â€œæ³„æ¼â€å±æ€§å…è®¸ç´¯ç§¯ç”µè·é€æ¸è¡°å‡ï¼Œè¿›ä¸€æ­¥æœ‰åŠ©äºæ¨¡å‹çš„ç®€åŒ–ã€‚LIF ç¥ç»å…ƒçš„å†…åœ¨é€’å½’æ€§è´¨æºäºæ›´æ–°çš„è†œç”µä½ã€‚</p>
</blockquote>
<blockquote>
<p>The implemented neuromorphic SNN decoder is a simplified version of the model proposed by Liao et al with fewer learnable parameters. In a preliminary exploration, reducing the complexity of the network only marginally impacted the accuracy while significantly improving the operational cost. Each hidden layer is decreased to 50 LIF-neurons without a bias term and a fixed decay ($\tau = 0.96$). The BatchNorm layer is removed because combining BatchNorm and Dropout leads to models with different feature variances inside the network during training and testing. The threshold of the LIF neurons is set to one. To further push for lower latency and power consumption and explore the various tradeoffs against accuracy, the number of hidden layers is decreased from three to two and one (SNN3, SNN2, and SNN1, respectively). SNN1 is a baseline model for the â€˜primate reaching taskâ€™ of NeuroBench and is depicted in figure 4(c).</p>
</blockquote>
<p>æ‰€å®ç°çš„ç¥ç»å½¢æ€ SNN è§£ç å™¨æ˜¯ Liao ç­‰äººæå‡ºçš„æ¨¡å‹çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå…·æœ‰æ›´å°‘çš„å¯å­¦ä¹ å‚æ•°ã€‚åœ¨åˆæ­¥æ¢ç´¢ä¸­ï¼Œå‡å°‘ç½‘ç»œçš„å¤æ‚æ€§ä»…å¯¹å‡†ç¡®æ€§äº§ç”Ÿäº†è¾¹é™…å½±å“ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†æ“ä½œæˆæœ¬ã€‚æ¯ä¸ªéšè—å±‚å‡å°‘åˆ° 50 ä¸ªæ²¡æœ‰åç½®é¡¹ä¸”å…·æœ‰å›ºå®šè¡°å‡ ($\tau = 0.96$) çš„ LIF ç¥ç»å…ƒã€‚åˆ é™¤äº† BatchNorm å±‚ï¼Œå› ä¸ºå°† BatchNorm å’Œ Dropout ç»“åˆä¼šå¯¼è‡´è®­ç»ƒå’Œæµ‹è¯•æœŸé—´ç½‘ç»œå†…éƒ¨å…·æœ‰ä¸åŒç‰¹å¾æ–¹å·®çš„æ¨¡å‹ã€‚LIF ç¥ç»å…ƒçš„é˜ˆå€¼è®¾ç½®ä¸º 1ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ¨åŠ¨æ›´ä½çš„å»¶è¿Ÿå’ŒåŠŸè€—ï¼Œå¹¶æ¢ç´¢ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å„ç§æƒè¡¡ï¼Œå°†éšè—å±‚çš„æ•°é‡ä»ä¸‰ä¸ªå‡å°‘åˆ°ä¸¤ä¸ªå’Œä¸€ä¸ªï¼ˆåˆ†åˆ«ä¸º SNN3ã€SNN2 å’Œ SNN1ï¼‰ã€‚SNN1 æ˜¯ NeuroBench â€œçµé•¿ç±»åŠ¨ç‰©ä¼¸æ‰‹ä»»åŠ¡â€ çš„åŸºçº¿æ¨¡å‹ï¼Œå¦‚å›¾ 4(c) æ‰€ç¤ºã€‚</p>
<h2 id="experimental-setup">Experimental setup<a hidden class="anchor" aria-hidden="true" href="#experimental-setup">#</a></h2>
<blockquote>
<p>The spike train was binned according to the window requirements of the respective network, and a sliding window with a stride of 4 ms extracted the spiking data. The RNNs and the SNNs used a sliding window of 50 bins to extract temporal information from the data and the non-recurrent ANNs extracted the bins individually. The neural decoders were trained to predict the finger velocity as visualized in figure 3.</p>
</blockquote>
<p>è„‰å†²åºåˆ—æ ¹æ®å„è‡ªç½‘ç»œçš„çª—å£è¦æ±‚è¿›è¡Œåˆ†ç®±ï¼Œå¹¶ä½¿ç”¨æ­¥å¹…ä¸º 4 æ¯«ç§’çš„æ»‘åŠ¨çª—å£æå–è„‰å†²æ•°æ®ã€‚RNN å’Œ SNN ä½¿ç”¨ 50 ä¸ªåˆ†ç®±çš„æ»‘åŠ¨çª—å£ä»æ•°æ®ä¸­æå–æ—¶é—´ä¿¡æ¯ï¼Œè€Œéé€’å½’ ANN åˆ™å•ç‹¬æå–åˆ†ç®±ã€‚ç¥ç»è§£ç å™¨ç»è¿‡è®­ç»ƒä»¥é¢„æµ‹å›¾ 3 ä¸­æ‰€ç¤ºçš„æ‰‹æŒ‡é€Ÿåº¦ã€‚</p>
<blockquote>
<p>RNNs and SNNs notoriously suffer from difficulties when learning long-term dependencies from data. To improve the gradient flow, the SNN was trained to predict the time window of the primateâ€™s finger kinematics and, for consistency, was tested to predict individual finger velocities as the ANNs. The Loss for this setup was a linearly weighted mean squared error (MSE) from zero to one to account for warm-up steps. The ANN and LSTM were trained using the conventional MSE Loss.</p>
</blockquote>
<p>RNN å’Œ SNN åœ¨ä»æ•°æ®ä¸­å­¦ä¹ é•¿æœŸä¾èµ–å…³ç³»æ—¶è‡­åæ˜­è‘—åœ°å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†æ”¹å–„æ¢¯åº¦æµï¼ŒSNN è¢«è®­ç»ƒä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©æ‰‹æŒ‡è¿åŠ¨å­¦çš„æ—¶é—´çª—å£ï¼Œå¹¶ä¸”ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œåƒ ANN ä¸€æ ·æµ‹è¯•ä»¥é¢„æµ‹å•ä¸ªæ‰‹æŒ‡é€Ÿåº¦ã€‚è¯¥è®¾ç½®çš„æŸå¤±æ˜¯ä»é›¶åˆ°ä¸€çš„çº¿æ€§åŠ æƒå‡æ–¹è¯¯å·® (MSE)ï¼Œä»¥è€ƒè™‘é¢„çƒ­æ­¥éª¤ã€‚ANN å’Œ LSTM ä½¿ç”¨ä¼ ç»Ÿçš„ MSE æŸå¤±è¿›è¡Œè®­ç»ƒã€‚</p>
<blockquote>
<p>Each session was divided into the first 75% of the reaches shuffled and, in contrast to the Neurobench-proposed evaluation pipeline, was used for model selection using 10-fold group cross-validation with early stopping and the last 25% for testing. This allows for finding the optimal hyperparameters and the number of training epochs while reporting more robust performance.</p>
</blockquote>
<p>æ¯ä¸ªä¼šè¯è¢«åˆ’åˆ†ä¸ºå‰ 75% çš„ä¼¸æ‰‹åŠ¨ä½œè¿›è¡Œæ´—ç‰Œï¼Œå¹¶ä¸ Neurobench æå‡ºçš„è¯„ä¼°æµç¨‹å½¢æˆå¯¹æ¯”ï¼Œç”¨äºä½¿ç”¨ 10 æŠ˜ç»„äº¤å‰éªŒè¯å’Œæå‰åœæ­¢è¿›è¡Œæ¨¡å‹é€‰æ‹©ï¼Œæœ€å 25% ç”¨äºæµ‹è¯•ã€‚è¿™å…è®¸æ‰¾åˆ°æœ€ä½³çš„è¶…å‚æ•°å’Œè®­ç»ƒå‘¨æœŸæ•°ï¼ŒåŒæ—¶æŠ¥å‘Šæ›´ç¨³å¥çš„æ€§èƒ½ã€‚</p>
<h1 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h1>
<blockquote>
<p>We considered six decoders trained on reconstructing a primateâ€™s finger velocity given binned neural activity with metrics that allow assessing a decoderâ€™s latency and power consumption. The results in table 2 offer a complete overview of the performance of all decoders. The performance of the decoders is in line with previous literature given the reduced dataset, different training paradigms and different metrics.</p>
</blockquote>
<p>æˆ‘ä»¬è€ƒè™‘äº†å…­ç§è§£ç å™¨ï¼Œè¿™äº›è§£ç å™¨ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥æ ¹æ®åˆ†ç®±çš„ç¥ç»æ´»åŠ¨é‡å»ºçµé•¿ç±»åŠ¨ç‰©çš„æ‰‹æŒ‡é€Ÿåº¦ï¼Œå¹¶å…·æœ‰å…è®¸è¯„ä¼°è§£ç å™¨å»¶è¿Ÿå’ŒåŠŸè€—çš„æŒ‡æ ‡ã€‚è¡¨ 2 ä¸­çš„ç»“æœæä¾›äº†æ‰€æœ‰è§£ç å™¨æ€§èƒ½çš„å®Œæ•´æ¦‚è¿°ã€‚é‰´äºæ•°æ®é›†çš„å‡å°‘ã€ä¸åŒçš„è®­ç»ƒèŒƒå¼å’Œä¸åŒçš„æŒ‡æ ‡ï¼Œè§£ç å™¨çš„æ€§èƒ½ä¸å…ˆå‰çš„æ–‡çŒ®ä¸€è‡´ã€‚</p>
<h2 id="latency-vs-fidelity">Latency vs. fidelity<a hidden class="anchor" aria-hidden="true" href="#latency-vs-fidelity">#</a></h2>
<blockquote>
<p>A higher $R^2$ performance can typically be achieved using deeper and more complex architectures or by better estimating the neural firing rate with a longer binning window. Both approaches negatively impact the latency and, thus, the capability of the neural decoder to facilitate real-time closed-loop feedback. The performance tradeoff of the six decoders is visualized in figure 6.</p>
</blockquote>
<p>é€šå¸¸å¯ä»¥ä½¿ç”¨æ›´æ·±å’Œæ›´å¤æ‚çš„æ¶æ„æˆ–é€šè¿‡æ›´é•¿çš„åˆ†ç®±çª—å£æ›´å¥½åœ°ä¼°è®¡ç¥ç»å‘æ”¾ç‡æ¥å®ç°æ›´é«˜çš„ $R^2$ æ€§èƒ½ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½ä¼šå¯¹å»¶è¿Ÿäº§ç”Ÿè´Ÿé¢å½±å“ï¼Œä»è€Œå½±å“ç¥ç»è§£ç å™¨ä¿ƒè¿›å®æ—¶é—­ç¯åé¦ˆçš„èƒ½åŠ›ã€‚å…­ç§è§£ç å™¨çš„æ€§èƒ½æƒè¡¡å¦‚å›¾ 6 æ‰€ç¤ºã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/i9LTA3EQSNDJnX7.png" alt=""  /></p>
<p>The accuracy versus latency trade-off of the six evaluated decoders. The R2 fidelity is plotted on the horizontal axis, and the vertical axis is the millisecond latency. In the plot, traditional decoders are represented as squares, artificial neural network-based decoders as triangles, and spiking neural networks (SNNs) as circles. The decoders with the best trade-off are in the bottom right corner. Recurrent decoders such as LSTM and SNN achieve substantially lower latency while maintaining competitive accuracy.</p>
</blockquote>
<p>å…­ç§è¯„ä¼°è§£ç å™¨çš„å‡†ç¡®æ€§ä¸å»¶è¿Ÿæƒè¡¡ã€‚æ°´å¹³è½´ä¸Šç»˜åˆ¶äº† $R^2$ ä¿çœŸåº¦ï¼Œå‚ç›´è½´ä¸ºæ¯«ç§’å»¶è¿Ÿã€‚åœ¨å›¾ä¸­ï¼Œä¼ ç»Ÿè§£ç å™¨è¡¨ç¤ºä¸ºæ–¹å—ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œçš„è§£ç å™¨è¡¨ç¤ºä¸ºä¸‰è§’å½¢ï¼Œè„‰å†²ç¥ç»ç½‘ç»œ (SNN) è¡¨ç¤ºä¸ºåœ†åœˆã€‚å…·æœ‰æœ€ä½³æƒè¡¡çš„è§£ç å™¨ä½äºå³ä¸‹è§’ã€‚è¯¸å¦‚ LSTM å’Œ SNN ä¹‹ç±»çš„é€’å½’è§£ç å™¨åœ¨ä¿æŒç«äº‰åŠ›çš„å‡†ç¡®æ€§çš„åŒæ—¶å®ç°äº†æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿã€‚</p>
</blockquote>
<blockquote>
<p>The UKF requires computationally intense matrix operations and a matrix inverse, making it significantly slower than the other decoders and achieving lower fidelity. Contrary to the rEFH filters, the $R^2$ score improved with decreasing binning windows. The best-performing rEFH filter had an $R^2$ of 63.19% (std = 0.17) with a latency of 129 ms, significantly outperforming the UKF with an $R^2$ of 45.10% (std = 0.12) and a latency of 270 ms both in terms of fidelity and latency.</p>
</blockquote>
<p>UKF éœ€è¦è®¡ç®—å¯†é›†å‹çš„çŸ©é˜µæ“ä½œå’ŒçŸ©é˜µæ±‚é€†ï¼Œä½¿å…¶æ¯”å…¶ä»–è§£ç å™¨æ˜¾è‘—æ›´æ…¢ä¸”å®ç°è¾ƒä½çš„ä¿çœŸåº¦ã€‚ä¸ rEFH æ»¤æ³¢å™¨ç›¸åï¼Œéšç€åˆ†ç®±çª—å£çš„å‡å°ï¼Œ$R^2$ åˆ†æ•°æœ‰æ‰€æé«˜ã€‚è¡¨ç°æœ€å¥½çš„ rEFH æ»¤æ³¢å™¨çš„ $R^2$ ä¸º 63.19%ï¼ˆæ ‡å‡†å·® = 0.17ï¼‰ï¼Œå»¶è¿Ÿä¸º 129 æ¯«ç§’ï¼Œåœ¨ä¿çœŸåº¦å’Œå»¶è¿Ÿæ–¹é¢å‡æ˜¾è‘—ä¼˜äº UKFï¼Œå…¶ $R^2$ ä¸º 45.10%ï¼ˆæ ‡å‡†å·® = 0.12ï¼‰ï¼Œå»¶è¿Ÿä¸º 270 æ¯«ç§’ã€‚</p>
<blockquote>
<p>The rEFH filters can achieve comparable $R^2$ scores to NN-based decoders. However, they require long binning windows to approximate the state distribution and experience a stark drop in the $R^2$ scores with smaller binning windows. Nevertheless, the trendlines of the rEFH and ANN models indicate that the rEFH can achieve a better latency versus fidelity tradeoff than the ANN. This stems from the ANN requiring a considerable history of binning windows to extract temporal information, which result in high latency. For the ANN, reducing the number of binning windows led to a significant decrease in fidelity. The shallow LSTM attains a much lower latency versus fidelity tradeoff than the traditional decoders and ANNs, indicated by the trendlines, achieving peak $R^2$ scores above 60% while having a latency between 4.05 ms and 16.05 ms. Notably, the fidelity drops significantly when using a longer binning window of 16 ms, indicating that the LSTM relies on the temporal dimension of the neural data to extract information about neural dynamics. The SNN achieved the best tradeoff with competitive $R^2$ scores and lower latency for all three models examined. The latency scales only marginally with an increasing number of layers.</p>
</blockquote>
<p>rEFH æ»¤æ³¢å™¨å¯ä»¥å®ç°ä¸åŸºäº NN çš„è§£ç å™¨ç›¸å½“çš„ $R^2$ åˆ†æ•°ã€‚ç„¶è€Œï¼Œå®ƒä»¬éœ€è¦è¾ƒé•¿çš„åˆ†ç®±çª—å£æ¥è¿‘ä¼¼çŠ¶æ€åˆ†å¸ƒï¼Œå¹¶ä¸”åœ¨è¾ƒå°çš„åˆ†ç®±çª—å£ä¸‹ç»å†äº† $R^2$ åˆ†æ•°çš„æ˜¾è‘—ä¸‹é™ã€‚å°½ç®¡å¦‚æ­¤ï¼ŒrEFH å’Œ ANN æ¨¡å‹çš„è¶‹åŠ¿çº¿è¡¨æ˜ï¼ŒrEFH å¯ä»¥å®ç°æ¯” ANN æ›´å¥½çš„å»¶è¿Ÿä¸ä¿çœŸåº¦æƒè¡¡ã€‚è¿™æºäº ANN éœ€è¦å¤§é‡çš„åˆ†ç®±çª—å£å†å²æ¥æå–æ—¶é—´ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´é«˜å»¶è¿Ÿã€‚å¯¹äº ANNï¼Œå‡å°‘åˆ†ç®±çª—å£çš„æ•°é‡ä¼šå¯¼è‡´ä¿çœŸåº¦æ˜¾è‘—ä¸‹é™ã€‚æµ…å±‚ LSTM å®ç°äº†æ¯”ä¼ ç»Ÿè§£ç å™¨å’Œ ANN æ›´ä½çš„å»¶è¿Ÿä¸ä¿çœŸåº¦æƒè¡¡ï¼Œå¦‚è¶‹åŠ¿çº¿æ‰€ç¤ºï¼Œå®ç°äº†è¶…è¿‡ 60% çš„å³°å€¼ $R^2$ åˆ†æ•°ï¼ŒåŒæ—¶å»¶è¿Ÿä»‹äº 4.05 æ¯«ç§’å’Œ 16.05 æ¯«ç§’ä¹‹é—´ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨ 16 æ¯«ç§’çš„è¾ƒé•¿åˆ†ç®±çª—å£æ—¶ï¼Œä¿çœŸåº¦æ˜¾è‘—ä¸‹é™ï¼Œè¿™è¡¨æ˜ LSTM ä¾èµ–äºç¥ç»æ•°æ®çš„æ—¶é—´ç»´åº¦æ¥æå–æœ‰å…³ç¥ç»åŠ¨æ€çš„ä¿¡æ¯ã€‚SNN åœ¨æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹ä¸­éƒ½å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„ $R^2$ åˆ†æ•°å’Œæ›´ä½å»¶è¿Ÿçš„æœ€ä½³æƒè¡¡ã€‚éšç€å±‚æ•°çš„å¢åŠ ï¼Œå»¶è¿Ÿä»…ç•¥æœ‰å¢åŠ ã€‚</p>
<blockquote>
<p>The overall trend of the six decoders shows that recurrent neural networks (RNNs), such as the SNN and the LSTM, can achieve competitive fidelity to non-recurrent ones while extracting neural dynamics from intra-cortical spike data and having significantly lower latency, with SNNs maintaining lower latency for higher fidelity than LSTMs.</p>
</blockquote>
<p>æ•´ä½“è¶‹åŠ¿æ˜¾ç¤ºï¼Œé€’å½’ç¥ç»ç½‘ç»œ (RNN)ï¼Œå¦‚ SNN å’Œ LSTMï¼Œå¯ä»¥å®ç°ä¸éé€’å½’ç½‘ç»œç›¸å½“çš„ä¿çœŸåº¦ï¼ŒåŒæ—¶ä»çš®å±‚å†…è„‰å†²æ•°æ®ä¸­æå–ç¥ç»åŠ¨æ€ï¼Œå¹¶å…·æœ‰æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿï¼ŒSNN åœ¨è¾ƒé«˜ä¿çœŸåº¦ä¸‹ä¿æŒæ¯” LSTM æ›´ä½çš„å»¶è¿Ÿã€‚</p>
<h2 id="power-consumption-vs-fidelity">Power consumption vs. fidelity<a hidden class="anchor" aria-hidden="true" href="#power-consumption-vs-fidelity">#</a></h2>
<blockquote>
<p>MACs, reported as the number of inner products of matrix-vector multiplications, are indifferent to the length of the vectors in the inner product. This makes them inadequate for assessing power consumption. Instead, the total number of required operations during inference provides a better estimate of the actual energy cost. Figure 7 shows the operational cost versus fidelity tradeoff of the neural decoders.</p>
</blockquote>
<p>MAC ä½œä¸ºçŸ©é˜µ-å‘é‡ä¹˜æ³•çš„å†…ç§¯æ¬¡æ•°è¿›è¡ŒæŠ¥å‘Šï¼Œå¯¹å†…ç§¯ä¸­å‘é‡çš„é•¿åº¦æ— åŠ¨äºè¡·ã€‚è¿™ä½¿å¾—å®ƒä»¬ä¸é€‚åˆè¯„ä¼°åŠŸè€—ã€‚ç›¸åï¼Œæ¨ç†è¿‡ç¨‹ä¸­æ‰€éœ€çš„æ€»æ“ä½œæ•°æä¾›äº†å¯¹å®é™…èƒ½é‡æˆæœ¬çš„æ›´å¥½ä¼°è®¡ã€‚å›¾ 7 æ˜¾ç¤ºäº†ç¥ç»è§£ç å™¨çš„æ“ä½œæˆæœ¬ä¸ä¿çœŸåº¦æƒè¡¡ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/EgWxCGowedptMuf.png" alt=""  /></p>
<p>Visualized trade-off between $R^2$ score and total operations. The specific closed-loop setting requires neural decoders in the bottom right corner. ANN-based decoders, such as the ANN and the LSTM depicted as triangles, are an improvement compared to traditional decoders, represented as squares. Yet, the SNN, denoted by circles, achieves the lowest operational cost while maintaining competitive $R^2$ scores. Comparing memory access instead of total operations shows the same trend and is redundant.</p>
</blockquote>
<p>$R^2$ åˆ†æ•°ä¸æ€»æ“ä½œæ•°ä¹‹é—´çš„æƒè¡¡å¯è§†åŒ–ã€‚ç‰¹å®šçš„é—­ç¯è®¾ç½®éœ€è¦ä½äºå³ä¸‹è§’çš„ç¥ç»è§£ç å™¨ã€‚åŸºäº ANN çš„è§£ç å™¨ï¼ˆå¦‚å›¾ä¸­çš„ ANN å’Œ LSTMï¼Œè¡¨ç¤ºä¸ºä¸‰è§’å½¢ï¼‰ç›¸æ¯”ä¼ ç»Ÿè§£ç å™¨ï¼ˆè¡¨ç¤ºä¸ºæ–¹å—ï¼‰æœ‰æ‰€æ”¹è¿›ã€‚ç„¶è€Œï¼ŒSNNï¼ˆè¡¨ç¤ºä¸ºåœ†åœˆï¼‰åœ¨ä¿æŒç«äº‰åŠ›çš„ $R^2$ åˆ†æ•°çš„åŒæ—¶å®ç°äº†æœ€ä½çš„æ“ä½œæˆæœ¬ã€‚æ¯”è¾ƒå†…å­˜è®¿é—®è€Œä¸æ˜¯æ€»æ“ä½œæ•°æ˜¾ç¤ºäº†ç›¸åŒçš„è¶‹åŠ¿ï¼Œå› æ­¤æ˜¯å¤šä½™çš„ã€‚</p>
</blockquote>
<blockquote>
<p>All traditional decoders require matrix operations with large inner products, leading to, by far, the most operations to effectively decode neural signals. The average number of operations for traditional decoders across the experiments was between 700 000 and 2300 000. The three decoders have the same high number of total operations across the various binning windows because unlike the other models, the length of the binning window does not affect the operational cost. Traditional decoders had the most extensive range of $R^2$ scores, ranging from 23% to 66%. NN-based decoders represent a shift towards more computationally efficient decoding algorithms. Our experiments demonstrated significantly reduced power consumption compared to traditional decoders. The LSTM with 16 hidden neurons required 4700 operations, whereas the ANN with seven binned windows required approximately 34 000 operations. Compared to the traditional decoders, this significant improvement comes with consistently high fidelity, with $R^2$ values of ANN-based decoders ranging from 50% to 65%. The SNN decoders exhibited the highest energy efficacy among the decoder types considered in this study. On average, SNN decoders required 200 operations while achieving competitive fidelity levels, with $R^2$ values ranging from 60% to 63%.</p>
</blockquote>
<p>æ‰€æœ‰ä¼ ç»Ÿè§£ç å™¨éƒ½éœ€è¦å…·æœ‰å¤§å†…ç§¯çš„çŸ©é˜µæ“ä½œï¼Œä»è€Œå¯¼è‡´è¿„ä»Šä¸ºæ­¢è§£ç ç¥ç»ä¿¡å·æ‰€éœ€çš„æ“ä½œæœ€å¤šã€‚ä¼ ç»Ÿè§£ç å™¨åœ¨å®éªŒä¸­çš„å¹³å‡æ“ä½œæ¬¡æ•°åœ¨ 700,000 åˆ° 2,300,000 ä¹‹é—´ã€‚è¿™ä¸‰ç§è§£ç å™¨åœ¨å„ç§åˆ†ç®±çª—å£ä¸­å…·æœ‰ç›¸åŒçš„é«˜æ€»æ“ä½œæ•°ï¼Œå› ä¸ºä¸å…¶ä»–æ¨¡å‹ä¸åŒï¼Œåˆ†ç®±çª—å£çš„é•¿åº¦ä¸ä¼šå½±å“æ“ä½œæˆæœ¬ã€‚ä¼ ç»Ÿè§£ç å™¨å…·æœ‰æœ€å¹¿æ³›çš„ $R^2$ åˆ†æ•°èŒƒå›´ï¼ŒèŒƒå›´ä» 23% åˆ° 66%ã€‚åŸºäº NN çš„è§£ç å™¨ä»£è¡¨äº†å‘æ›´é«˜æ•ˆè®¡ç®—è§£ç ç®—æ³•çš„è½¬å˜ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”ï¼ŒåŠŸè€—æ˜¾è‘—é™ä½ã€‚å…·æœ‰ 16 ä¸ªéšè—ç¥ç»å…ƒçš„ LSTM éœ€è¦ 4700 æ¬¡æ“ä½œï¼Œè€Œå…·æœ‰ä¸ƒä¸ªåˆ†ç®±çª—å£çš„ ANN å¤§çº¦éœ€è¦ 34,000 æ¬¡æ“ä½œã€‚ä¸ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”ï¼Œè¿™ä¸€æ˜¾è‘—æ”¹è¿›ä¼´éšç€å§‹ç»ˆå¦‚ä¸€çš„é«˜ä¿çœŸåº¦ï¼ŒåŸºäº ANN çš„è§£ç å™¨çš„ $R^2$ å€¼èŒƒå›´ä» 50% åˆ° 65%ã€‚SNN è§£ç å™¨åœ¨æœ¬ç ”ç©¶è€ƒè™‘çš„è§£ç å™¨ç±»å‹ä¸­è¡¨ç°å‡ºæœ€é«˜çš„èƒ½é‡æ•ˆç‡ã€‚SNN è§£ç å™¨å¹³å‡éœ€è¦ 200 æ¬¡æ“ä½œï¼ŒåŒæ—¶å®ç°å…·æœ‰ç«äº‰åŠ›çš„ä¿çœŸåº¦æ°´å¹³ï¼Œ$R^2$ å€¼èŒƒå›´ä» 60% åˆ° 63%ã€‚</p>
<blockquote>
<p>Comparing memory access instead of total effective operations reveals the same tradeoff and is not reiterated. A comparison of the power consumption and fidelity metrics reveals an intriguing trade-off among the three decoder types. While traditional decoders require substantial operations, they offer a range of $R^2$ scores. In contrast, ANN-based and SNN-based decoders provide the advantage of reduced energy costs, with SNN decoders exhibiting the lowest computational load while maintaining competitive fidelity levels.</p>
</blockquote>
<p>æ¯”è¾ƒå†…å­˜è®¿é—®è€Œä¸æ˜¯æ€»æœ‰æ•ˆæ“ä½œæ­ç¤ºäº†ç›¸åŒçš„æƒè¡¡ï¼Œå¹¶æœªé‡ç”³ã€‚åŠŸè€—å’Œä¿çœŸåº¦æŒ‡æ ‡çš„æ¯”è¾ƒæ­ç¤ºäº†ä¸‰ç§è§£ç å™¨ç±»å‹ä¹‹é—´æœ‰è¶£çš„æƒè¡¡ã€‚è™½ç„¶ä¼ ç»Ÿè§£ç å™¨éœ€è¦å¤§é‡æ“ä½œï¼Œä½†å®ƒä»¬æä¾›äº†ä¸€ç³»åˆ— $R^2$ åˆ†æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäº ANN å’Œ SNN çš„è§£ç å™¨æä¾›äº†é™ä½èƒ½é‡æˆæœ¬çš„ä¼˜åŠ¿ï¼ŒSNN è§£ç å™¨åœ¨ä¿æŒç«äº‰åŠ›çš„ä¿çœŸåº¦æ°´å¹³çš„åŒæ—¶è¡¨ç°å‡ºæœ€ä½çš„è®¡ç®—è´Ÿè½½ã€‚</p>
<h2 id="bayesian-information-criterion-bic">Bayesian information criterion (BIC)<a hidden class="anchor" aria-hidden="true" href="#bayesian-information-criterion-bic">#</a></h2>
<blockquote>
<p>The BIC serves as a valuable instrument for the comparing various neural networks, effectively addressing the concern of increased model complexity and its potential impact on performance enhancement. The BIC introduces a penalization term for the number of model parameters, thereby discouraging the adoption of overly complex models with excessive weights and biases. This penalty term effectively balances fidelity and model complexity, enabling us to discern whether a modelâ€™s performance improvements stem from an increased number of learnable parameters or architectural design.</p>
</blockquote>
<p>BIC æ˜¯æ¯”è¾ƒå„ç§ç¥ç»ç½‘ç»œçš„æœ‰ä»·å€¼çš„å·¥å…·ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ¨¡å‹å¤æ‚æ€§å¢åŠ åŠå…¶å¯¹æ€§èƒ½æå‡çš„æ½œåœ¨å½±å“çš„é—®é¢˜ã€‚BIC ä¸ºæ¨¡å‹å‚æ•°çš„æ•°é‡å¼•å…¥äº†æƒ©ç½šé¡¹ï¼Œä»è€Œé˜»æ­¢é‡‡ç”¨å…·æœ‰è¿‡å¤šæƒé‡å’Œåç½®çš„è¿‡äºå¤æ‚çš„æ¨¡å‹ã€‚è¯¥æƒ©ç½šé¡¹æœ‰æ•ˆåœ°å¹³è¡¡äº†ä¿çœŸåº¦å’Œæ¨¡å‹å¤æ‚æ€§ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¾¨åˆ«æ¨¡å‹çš„æ€§èƒ½æ”¹è¿›æ˜¯æºäºå¯å­¦ä¹ å‚æ•°æ•°é‡çš„å¢åŠ è¿˜æ˜¯æ¶æ„è®¾è®¡ã€‚</p>
<blockquote>
<p>Figure 8 presents the BIC values for various configurations of the three neural network-based decoders. Notably, the single-layer SNN, characterized by its minimal complexity, attains the lowest BIC score. In contrast, SNN2 and SNN3 had significantly higher BIC scores despite exhibiting performance improvements. This discrepancy suggests that the performance improvements are disproportional to the increased number of learnable parameters in these models. All SNNs achieved much lower BIC scores than the traditional and ANN-based neural decoder.</p>
</blockquote>
<p>å›¾ 8 å±•ç¤ºäº†ä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨çš„å„ç§é…ç½®çš„ BIC å€¼ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå•å±‚ SNN ä»¥å…¶æœ€å°çš„å¤æ‚æ€§è·å¾—äº†æœ€ä½çš„ BIC åˆ†æ•°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå°½ç®¡ SNN2 å’Œ SNN3 è¡¨ç°å‡ºæ€§èƒ½æå‡ï¼Œä½†å®ƒä»¬çš„ BIC åˆ†æ•°æ˜¾è‘—æ›´é«˜ã€‚è¿™ç§å·®å¼‚è¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹ä¸­çš„æ€§èƒ½æ”¹è¿›ä¸å¯å­¦ä¹ å‚æ•°æ•°é‡çš„å¢åŠ ä¸æˆæ¯”ä¾‹ã€‚æ‰€æœ‰ SNN çš„ BIC åˆ†æ•°éƒ½è¿œä½äºä¼ ç»Ÿå’ŒåŸºäº ANN çš„ç¥ç»è§£ç å™¨ã€‚</p>
<blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/12/gTcQfZrSLl5OPvY.png" alt=""  /></p>
<p>The evaluated NN-based decodersâ€™ Bayesian information criterion (BIC) shows that the SNN achieve far lower BIC scores than other decoders, suggesting that SNNs are more suitable for the constrained closed-loop setting. A low BIC indicates that a decoder can learn better, given its complexity. The lowest BIC score is achieved by SNN1. The various models appear in the same order as presented in table 2.</p>
</blockquote>
<p>è¯„ä¼°çš„åŸºäº NN çš„è§£ç å™¨çš„è´å¶æ–¯ä¿¡æ¯å‡†åˆ™ (BIC) æ˜¾ç¤ºï¼ŒSNN å®ç°äº†è¿œä½äºå…¶ä»–è§£ç å™¨çš„ BIC åˆ†æ•°ï¼Œè¿™è¡¨æ˜ SNN æ›´é€‚åˆå—é™çš„é—­ç¯è®¾ç½®ã€‚è¾ƒä½çš„ BIC è¡¨æ˜ï¼Œç»™å®šå…¶å¤æ‚æ€§ï¼Œè§£ç å™¨å¯ä»¥å­¦ä¹ å¾—æ›´å¥½ã€‚æœ€ä½çš„ BIC åˆ†æ•°ç”± SNN1 å®ç°ã€‚å„ç§æ¨¡å‹çš„å‡ºç°é¡ºåºä¸è¡¨ 2 ä¸­å‘ˆç°çš„é¡ºåºç›¸åŒã€‚</p>
</blockquote>
<h1 id="discussions">Discussions<a hidden class="anchor" aria-hidden="true" href="#discussions">#</a></h1>
<blockquote>
<p>In conclusion, optimizing neural decoders for closed-loop iBCI systems capable of CLN presents a delicate balance, requiring careful consideration of the trade-offs between fidelity, latency, power consumption, and memory size. Our findings emphasize that although more complex and deeper neural architectures with more trainable parameters, hold the potential for improved decoding accuracy, optimizing only for fidelity by increasing the complexity of a network can result in reduced usability for closed-loop iBCIs. The decoding accuracy reaffirms the findings of Glaser et al that conventional neural network-based decoders can achieve the highest R2 scores. However, we observe that this comes at the cost of increased latency and power consumption. Even when only considering fidelity, evaluating the BIC across the three NN-based decoders showed that SNNs consistently outperformed the ANN and the LSTM, achieving significantly lower BIC scores. This indicates that the performance improvement of the ANN is due to disproportionally more learnable parameters. Remarkably, the single-layer SNN emerged as the top performer out of the models we benchmarked in this paper, signifying its suitability for effectively learning data variance, particularly when considering the number of learnable parameters. This highlights that the shallow SNN is preferable for robust and energy-efficient neural decoding, given its complexity among the three neural network-based decoder types we evaluated.</p>
</blockquote>
<p>æ€»ä¹‹ï¼Œä¸ºèƒ½å¤Ÿå®ç° CLN çš„é—­ç¯ iBCI ç³»ç»Ÿä¼˜åŒ–ç¥ç»è§£ç å™¨éœ€è¦åœ¨ä¿çœŸåº¦ã€å»¶è¿Ÿã€åŠŸè€—å’Œå†…å­˜å¤§å°ä¹‹é—´è¿›è¡Œå¾®å¦™çš„å¹³è¡¡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œå°½ç®¡å…·æœ‰æ›´å¤šå¯è®­ç»ƒå‚æ•°çš„æ›´å¤æ‚å’Œæ›´æ·±çš„ç¥ç»æ¶æ„å…·æœ‰æé«˜è§£ç å‡†ç¡®æ€§çš„æ½œåŠ›ï¼Œä½†ä»…é€šè¿‡å¢åŠ ç½‘ç»œçš„å¤æ‚æ€§æ¥ä¼˜åŒ–ä¿çœŸåº¦å¯èƒ½ä¼šé™ä½é—­ç¯ iBCI çš„å¯ç”¨æ€§ã€‚è§£ç å‡†ç¡®æ€§é‡ç”³äº† Glaser ç­‰äººçš„å‘ç°ï¼Œå³ä¼ ç»Ÿçš„åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨å¯ä»¥å®ç°æœ€é«˜çš„ $R^2$ åˆ†æ•°ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œè¿™ä»¥å¢åŠ å»¶è¿Ÿå’ŒåŠŸè€—ä¸ºä»£ä»·ã€‚å³ä½¿ä»…è€ƒè™‘ä¿çœŸåº¦ï¼Œè¯„ä¼°ä¸‰ç§åŸºäº NN çš„è§£ç å™¨çš„ BIC ä¹Ÿæ˜¾ç¤º SNN å§‹ç»ˆä¼˜äº ANN å’Œ LSTMï¼Œå®ç°äº†æ˜¾è‘—è¾ƒä½çš„ BIC åˆ†æ•°ã€‚è¿™è¡¨æ˜ ANN çš„æ€§èƒ½æå‡æ˜¯ç”±äºä¸æˆæ¯”ä¾‹åœ°æ›´å¤šçš„å¯å­¦ä¹ å‚æ•°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå•å±‚ SNN æˆä¸ºæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­åŸºå‡†æµ‹è¯•çš„æ¨¡å‹ä¸­çš„æœ€ä½³è¡¨ç°è€…ï¼Œè¡¨æ˜å…¶é€‚åˆæœ‰æ•ˆå­¦ä¹ æ•°æ®æ–¹å·®ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°å¯å­¦ä¹ å‚æ•°çš„æ•°é‡ã€‚è¿™çªæ˜¾å‡ºï¼Œåœ¨æˆ‘ä»¬è¯„ä¼°çš„ä¸‰ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨ç±»å‹ä¸­ï¼Œè€ƒè™‘åˆ°å…¶å¤æ‚æ€§ï¼Œæµ…å±‚ SNN æ›´é€‚åˆè¿›è¡Œç¨³å¥ä¸”èŠ‚èƒ½çš„ç¥ç»è§£ç ã€‚</p>
<blockquote>
<p>The ability of a neural decoder to effectively harness sparsity represents a crucial design consideration in closed-loop iBCI systems. Conventional neural data are characterized by their inherent sparsity and temporal encoding, with rate-based encoding accounting for a mere fraction of the neural activity in regions such as the visual cortex. The inherent sparsity of neural spikes provides SNNs with a distinct advantage, enabling them to capitalize on the spatiotemporal structure of the input data, which is less pronounced in non-neuromorphic ANNs.</p>
</blockquote>
<p>ç¥ç»è§£ç å™¨æœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ€§çš„èƒ½åŠ›æ˜¯é—­ç¯ iBCI ç³»ç»Ÿä¸­çš„ä¸€ä¸ªå…³é”®è®¾è®¡è€ƒè™‘å› ç´ ã€‚ä¼ ç»Ÿçš„ç¥ç»æ•°æ®ä»¥å…¶å›ºæœ‰çš„ç¨€ç–æ€§å’Œæ—¶é—´ç¼–ç ä¸ºç‰¹å¾ï¼ŒåŸºäºé€Ÿç‡çš„ç¼–ç ä»…å è§†è§‰çš®å±‚ç­‰åŒºåŸŸç¥ç»æ´»åŠ¨çš„ä¸€å°éƒ¨åˆ†ã€‚ç¥ç»è„‰å†²çš„å›ºæœ‰ç¨€ç–æ€§ä¸º SNN æä¾›äº†ç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨è¾“å…¥æ•°æ®çš„æ—¶ç©ºç»“æ„ï¼Œè€Œè¿™ç§ç»“æ„åœ¨éç¥ç»å½¢æ€çš„ ANN ä¸­ä¸é‚£ä¹ˆæ˜æ˜¾ã€‚</p>
<blockquote>
<p>SNNs have previously demonstrated their potential for reduced power consumption and lower latency in various applications. In our study, we reaffirm and extend these prior findings, indicating that SNNs can extract neural dynamics from extracellular spiking data, while maintaining competitive fidelity and showing superior performance in terms of power consumption and latency.</p>
</blockquote>
<p>SNN å…ˆå‰å·²å±•ç¤ºäº†å…¶åœ¨å„ç§åº”ç”¨ä¸­é™ä½åŠŸè€—å’Œå»¶è¿Ÿçš„æ½œåŠ›ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é‡ç”³å¹¶æ‰©å±•äº†è¿™äº›å…ˆå‰çš„å‘ç°ï¼Œè¡¨æ˜ SNN å¯ä»¥ä»ç»†èƒå¤–è„‰å†²æ•°æ®ä¸­æå–ç¥ç»åŠ¨æ€ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›çš„ä¿çœŸåº¦ï¼Œå¹¶åœ¨åŠŸè€—å’Œå»¶è¿Ÿæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<blockquote>
<p>The latency metric introduced in our analysis operates under the assumption that the computation of an inner product is equivalent to a single addition in terms of clock cycles. Although this abstraction aligns with standard practices for MAC operations, it is essential to acknowledge that this assumption may only partially represent the potential hardware optimizations for vector accumulations. While the process of counting additions might initially appear as a potential disadvantage when comparing SNNs to ANNs in the context of latency, we observe that despite this methodological abstraction, SNNs consistently achieved substantially lower latency when compared to traditional decoders and the ANN. The longer latency of traditional decoders and ANNs is primarily attributed to their reliance on long binning windows for extracting temporal information and their high operational cost. Notably, the sole exception to this trend is the LSTM, which demonstrates a latency level comparable to that of SNNs. This observation reaffirms the findings of Zenke et al, who demonstrated the efficiency of RNNs, such as LSTMs and SNNs, in exploiting the temporal structure of neural data, emphasizing their capacity to achieve competitive fidelity with low latency in a closed-loop neural decoding system. These insights underscore that even without accounting for the potential hardware optimizations, SNNs can exhibit a marked advantage in terms of latency over traditional decoder models and non-recurrent ANNs, which require more extensive computational resources owing to their temporal information extraction procedures.</p>
</blockquote>
<p>æˆ‘ä»¬åˆ†æä¸­å¼•å…¥çš„å»¶è¿ŸæŒ‡æ ‡å‡è®¾å†…ç§¯çš„è®¡ç®—åœ¨æ—¶é’Ÿå‘¨æœŸæ–¹é¢ç­‰åŒäºå•æ¬¡åŠ æ³•ã€‚å°½ç®¡è¿™ç§æŠ½è±¡ä¸ MAC æ“ä½œçš„æ ‡å‡†åšæ³•ä¸€è‡´ï¼Œä½†å¿…é¡»æ‰¿è®¤ï¼Œè¿™ä¸€å‡è®¾å¯èƒ½ä»…éƒ¨åˆ†ä»£è¡¨äº†å‘é‡ç´¯ç§¯çš„æ½œåœ¨ç¡¬ä»¶ä¼˜åŒ–ã€‚è™½ç„¶åœ¨å»¶è¿Ÿæ–¹é¢æ¯”è¾ƒ SNN å’Œ ANN æ—¶ï¼Œè®¡ç®—åŠ æ³•çš„è¿‡ç¨‹æœ€åˆä¼¼ä¹æ˜¯ä¸€ä¸ªæ½œåœ¨çš„åŠ£åŠ¿ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå°½ç®¡å­˜åœ¨è¿™ç§æ–¹æ³•è®ºæŠ½è±¡ï¼ŒSNN ä¸ä¼ ç»Ÿè§£ç å™¨å’Œ ANN ç›¸æ¯”ä»å§‹ç»ˆå®ç°äº†æ˜¾è‘—è¾ƒä½çš„å»¶è¿Ÿã€‚ä¼ ç»Ÿè§£ç å™¨å’Œ ANN è¾ƒé•¿çš„å»¶è¿Ÿä¸»è¦å½’å› äºå®ƒä»¬ä¾èµ–äºé•¿åˆ†ç®±çª—å£æ¥æå–æ—¶é—´ä¿¡æ¯åŠå…¶é«˜æ“ä½œæˆæœ¬ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸€è¶‹åŠ¿çš„å”¯ä¸€ä¾‹å¤–æ˜¯ LSTMï¼Œå…¶æ˜¾ç¤ºå‡ºä¸ SNN ç›¸å½“çš„å»¶è¿Ÿæ°´å¹³ã€‚è¿™ä¸€è§‚å¯Ÿç»“æœé‡ç”³äº† Zenke ç­‰äººçš„å‘ç°ï¼Œä»–ä»¬å±•ç¤ºäº† RNNï¼ˆå¦‚ LSTM å’Œ SNNï¼‰åœ¨åˆ©ç”¨ç¥ç»æ•°æ®çš„æ—¶é—´ç»“æ„æ–¹é¢çš„æ•ˆç‡ï¼Œå¼ºè°ƒäº†å®ƒä»¬åœ¨é—­ç¯ç¥ç»è§£ç ç³»ç»Ÿä¸­ä»¥ä½å»¶è¿Ÿå®ç°ç«äº‰åŠ›ä¿çœŸåº¦çš„èƒ½åŠ›ã€‚è¿™äº›è§è§£å¼ºè°ƒï¼Œå³ä½¿ä¸è€ƒè™‘æ½œåœ¨çš„ç¡¬ä»¶ä¼˜åŒ–ï¼ŒSNN åœ¨å»¶è¿Ÿæ–¹é¢ä¹Ÿèƒ½è¡¨ç°å‡ºæ˜æ˜¾ä¼˜äºä¼ ç»Ÿè§£ç å™¨æ¨¡å‹å’Œéé€’å½’ ANN çš„ä¼˜åŠ¿ï¼Œåè€…ç”±äºå…¶æ—¶é—´ä¿¡æ¯æå–ç¨‹åºè€Œéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚</p>
<blockquote>
<p>The advantages of employing neuromorphic SNNs for closed-loop iBCIs become more apparent when the energy cost is evaluated using the total number of operations. In this context, SNNs significantly outperform traditional and ANN-based decoders. Our results show that traditional and ANN-based decoders require several orders of magnitude more operations to attain performance levels comparable to SNNs. The remarkable reduction in the number of operations required by SNNs can be attributed to their constrained design, which minimizes the number of learnable parameters while still delivering competitive performance. However, the primary driving forces behind the substantially lower energy cost associated with SNNs lies in their ability to exploit sparsity and their more energy-efficient operations. This capacity allows for approximately 5% of the operations to be executed, emphasizing the exceptional efficiency achieved by SNNs while maintaining high fidelity. Following previously reported estimates of required energy per operation, we observe an approximate energy cost of around $2 \mu\text{W}$ per inference for the SNNs, which is 50 times lower than for the LSTM, 100 times lower for the ANN, and 10 000 times lower than for the UKF.</p>
</blockquote>
<p>é‡‡ç”¨ç¥ç»å½¢æ€ SNN ç”¨äºé—­ç¯ iBCI çš„ä¼˜åŠ¿åœ¨ä½¿ç”¨æ€»æ“ä½œæ•°è¯„ä¼°èƒ½é‡æˆæœ¬æ—¶å˜å¾—æ›´åŠ æ˜æ˜¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒSNN æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå’ŒåŸºäº ANN çš„è§£ç å™¨ã€‚æˆ‘ä»¬çš„ç»“æœæ˜¾ç¤ºï¼Œä¼ ç»Ÿå’ŒåŸºäº ANN çš„è§£ç å™¨éœ€è¦å¤šä¸ªæ•°é‡çº§çš„æ›´å¤šæ“ä½œæ‰èƒ½è¾¾åˆ°ä¸ SNN ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚SNN æ‰€éœ€æ“ä½œæ•°çš„æ˜¾è‘—å‡å°‘å¯å½’å› äºå…¶å—é™çš„è®¾è®¡ï¼Œè¯¥è®¾è®¡åœ¨æœ€å°åŒ–å¯å­¦ä¹ å‚æ•°æ•°é‡çš„åŒæ—¶ä»æä¾›ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¸ SNN ç›¸å…³çš„æ˜¾è‘—è¾ƒä½èƒ½é‡æˆæœ¬çš„ä¸»è¦é©±åŠ¨åŠ›åœ¨äºå®ƒä»¬åˆ©ç”¨ç¨€ç–æ€§å’Œæ›´èŠ‚èƒ½æ“ä½œçš„èƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›ä½¿å¾—å¤§çº¦ 5% çš„æ“ä½œå¾—ä»¥æ‰§è¡Œï¼Œå¼ºè°ƒäº† SNN åœ¨ä¿æŒé«˜ä¿çœŸåº¦çš„åŒæ—¶å®ç°çš„å“è¶Šæ•ˆç‡ã€‚æ ¹æ®å…ˆå‰æŠ¥å‘Šçš„æ¯æ¬¡æ“ä½œæ‰€éœ€èƒ½é‡çš„ä¼°è®¡ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ° SNN æ¯æ¬¡æ¨ç†çš„å¤§çº¦èƒ½é‡æˆæœ¬çº¦ä¸º $2 \mu\text{W}$ï¼Œè¿™æ¯” LSTM ä½ 50 å€ï¼Œæ¯” ANN ä½ 100 å€ï¼Œæ¯” UKF ä½ 10,000 å€ã€‚</p>
<blockquote>
<p>The field of neurotechnology and BCIs are rapidly expanding. New advancements and technologies enable the development of more effective, user-friendly, and versatile BCIs. This paper discusses two main challenges in designing processors for implantable closed-loop neural decoders: low energy consumption to minimize heat diffusion, and low latency to enable real-time CLN. We defined metrics for neural decoders and benchmarked common decoding methods to predict a primateâ€™s finger kinematics. This study explores the suitability of low latency and low computing neural decoders and highlights the potential advantages of neuromorphic SNNs for CLN. Our results show that SNNs can balance decoding accuracy and operational efficiency, offering immense potential for reshaping the landscape of neural decoders and opening new frontiers in closed-loop intracortical human-brain interaction.</p>
</blockquote>
<p>ç¥ç»æŠ€æœ¯å’Œ BCI é¢†åŸŸæ­£åœ¨è¿…é€Ÿæ‰©å±•ã€‚æ–°çš„è¿›å±•å’ŒæŠ€æœ¯ä½¿å¾—å¼€å‘æ›´æœ‰æ•ˆã€ç”¨æˆ·å‹å¥½ä¸”å¤šåŠŸèƒ½çš„ BCI æˆä¸ºå¯èƒ½ã€‚æœ¬æ–‡è®¨è®ºäº†ä¸ºå¯æ¤å…¥é—­ç¯ç¥ç»è§£ç å™¨è®¾è®¡å¤„ç†å™¨çš„ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šä½èƒ½è€—ä»¥æœ€å°åŒ–çƒ­æ‰©æ•£ï¼Œä»¥åŠä½å»¶è¿Ÿä»¥å®ç°å®æ—¶ CLNã€‚æˆ‘ä»¬ä¸ºç¥ç»è§£ç å™¨å®šä¹‰äº†æŒ‡æ ‡ï¼Œå¹¶åŸºå‡†æµ‹è¯•äº†å¸¸è§çš„è§£ç æ–¹æ³•ä»¥é¢„æµ‹çµé•¿ç±»åŠ¨ç‰©çš„æ‰‹æŒ‡è¿åŠ¨å­¦ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä½å»¶è¿Ÿå’Œä½è®¡ç®—ç¥ç»è§£ç å™¨çš„é€‚ç”¨æ€§ï¼Œå¹¶å¼ºè°ƒäº†ç¥ç»å½¢æ€ SNN åœ¨ CLN ä¸­çš„æ½œåœ¨ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSNN å¯ä»¥å¹³è¡¡è§£ç å‡†ç¡®æ€§å’Œæ“ä½œæ•ˆç‡ï¼Œä¸ºé‡å¡‘ç¥ç»è§£ç å™¨çš„æ ¼å±€æä¾›äº†å·¨å¤§çš„æ½œåŠ›ï¼Œå¹¶ä¸ºé—­ç¯çš®å±‚å†…äººè„‘äº¤äº’å¼€è¾Ÿäº†æ–°çš„å‰æ²¿ã€‚</p>
<blockquote>
<p>Using neuromorphic SNNs for CLN is an area of research with great promise, as indicated by successfully predicting an NHP finger kinematic in this study. However, the list of evaluated decoders is non-exhaustive, and only a single neural decoder, the SNN, was optimized for latency and power consumption. This allows for comparing commonly used decoders, yet it favors inherently efficient and fast neuromorphic decoders. Additionally, only one exemplary dataset was evaluated as representative of closed-loop iBCI tasks requiring low latency and power consumption. Therefore, this study highlights the potential of SNN for iBCI for CLN, however, further studies are required to explore the suitability of these networks for other types of neural decoding tasks and to optimize their performance to meet the requirements of CLN systems. Developing fully implantable iBCIs with local processing capabilities is crucial for reducing energy consumption and latency and improving the real-time applicability of CLN systems.</p>
</blockquote>
<p>åœ¨æœ¬ç ”ç©¶ä¸­æˆåŠŸé¢„æµ‹ NHP æ‰‹æŒ‡è¿åŠ¨å­¦è¡¨æ˜ï¼Œä½¿ç”¨ç¥ç»å½¢æ€ SNN è¿›è¡Œ CLN æ˜¯ä¸€ä¸ªå……æ»¡å¸Œæœ›çš„ç ”ç©¶é¢†åŸŸã€‚ç„¶è€Œï¼Œè¯„ä¼°çš„è§£ç å™¨åˆ—è¡¨å¹¶ä¸è¯¦å°½ï¼Œåªæœ‰å•ä¸ªç¥ç»è§£ç å™¨ SNN é’ˆå¯¹å»¶è¿Ÿå’ŒåŠŸè€—è¿›è¡Œäº†ä¼˜åŒ–ã€‚è¿™å…è®¸æ¯”è¾ƒå¸¸ç”¨çš„è§£ç å™¨ï¼Œä½†æœ‰åˆ©äºæœ¬è´¨ä¸Šé«˜æ•ˆä¸”å¿«é€Ÿçš„ç¥ç»å½¢æ€è§£ç å™¨ã€‚æ­¤å¤–ï¼Œä»…è¯„ä¼°äº†ä¸€ä¸ªå…¸å‹æ•°æ®é›†ï¼Œä½œä¸ºéœ€è¦ä½å»¶è¿Ÿå’ŒåŠŸè€—çš„é—­ç¯ iBCI ä»»åŠ¡çš„ä»£è¡¨ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶çªæ˜¾äº† SNN åœ¨ CLN iBCI ä¸­çš„æ½œåŠ›ï¼Œä½†éœ€è¦è¿›ä¸€æ­¥çš„ç ”ç©¶æ¥æ¢ç´¢è¿™äº›ç½‘ç»œåœ¨å…¶ä»–ç±»å‹ç¥ç»è§£ç ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¼˜åŒ–å…¶æ€§èƒ½ä»¥æ»¡è¶³ CLN ç³»ç»Ÿçš„è¦æ±‚ã€‚å¼€å‘å…·æœ‰æœ¬åœ°å¤„ç†èƒ½åŠ›çš„å®Œå…¨å¯æ¤å…¥ iBCI å¯¹äºé™ä½èƒ½è€—å’Œå»¶è¿Ÿä»¥åŠæé«˜ CLN ç³»ç»Ÿçš„å®æ—¶é€‚ç”¨æ€§è‡³å…³é‡è¦ã€‚</p>
<blockquote>
<p>Overall, the outlook for neural engineering and BCIs is bright. New developments will improve neural recording and decoding technologies, ultimately enhancing our understanding of the brain and its complex neural processes.</p>
</blockquote>
<p>æ€»ä½“è€Œè¨€ï¼Œç¥ç»å·¥ç¨‹å’Œ BCI çš„å‰æ™¯å…‰æ˜ã€‚æ–°çš„å‘å±•å°†æ”¹å–„ç¥ç»è®°å½•å’Œè§£ç æŠ€æœ¯ï¼Œæœ€ç»ˆå¢å¼ºæˆ‘ä»¬å¯¹å¤§è„‘åŠå…¶å¤æ‚ç¥ç»è¿‡ç¨‹çš„ç†è§£ã€‚</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<blockquote>
<p>Our study introduces methods to extrapolate algorithmic-to-hardware metrics that allow evaluating the low latency and high energy efficacy requirements of iBCI suitable for CLN. We present six commonly used neural decoders and compare them in predicting an NHP fine motor kinematics from binned neural activity. Our results highlight the potential advantages of neuromorphic SNNs in the context of iBCIs capable of CLN. In our benchmark, we observe that SNNs outperform other commonly used decoders, with evident performance differences when compared against benchmarked traditional decoders. Notably, the exceptionally low latency of SNNs and LSTMs, surpassing that of traditional decoders and non-RNNs, arises from their innate ability to extract temporal information from spiking neural data. The power efficiency can be attributed to the adeptness of SNNs in exploiting sparsity and their deliberately constrained architectural design. Our results show that SNNs can achieve competitive decoding performance in less than 5 ms, using less than 1% of computational resources, and more than 50 times less energy than other neural decoding methods in this benchmark. This makes them highly suitable candidates for closed-loop iBCI challenges and positions them as a game-changing technology for reshaping the landscape of neural decoders. Significant advancements in CLN can be achieved by adopting SNNs as the preferred neural decoder. Their capacity for efficient and accurate neural signal processing holds the potential to revolutionize BCI applications, enhancing our ability to interact with and understand the intricacies of the human brain.</p>
</blockquote>
<p>æˆ‘ä»¬çš„ç ”ç©¶å¼•å…¥äº†å°†ç®—æ³•æŒ‡æ ‡å¤–æ¨åˆ°ç¡¬ä»¶æŒ‡æ ‡çš„æ–¹æ³•ï¼Œä½¿å¾—è¯„ä¼°é€‚ç”¨äº CLN çš„ iBCI çš„ä½å»¶è¿Ÿå’Œé«˜èƒ½æ•ˆè¦æ±‚æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†å…­ç§å¸¸ç”¨çš„ç¥ç»è§£ç å™¨ï¼Œå¹¶æ¯”è¾ƒäº†å®ƒä»¬åœ¨æ ¹æ®åˆ†ç®±ç¥ç»æ´»åŠ¨é¢„æµ‹ NHP ç²¾ç»†è¿åŠ¨å­¦æ–¹é¢çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†ç¥ç»å½¢æ€ SNN åœ¨èƒ½å¤Ÿå®ç° CLN çš„ iBCI èƒŒæ™¯ä¸‹çš„æ½œåœ¨ä¼˜åŠ¿ã€‚åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ° SNN ä¼˜äºå…¶ä»–å¸¸ç”¨è§£ç å™¨ï¼Œä¸åŸºå‡†ä¼ ç»Ÿè§£ç å™¨ç›¸æ¯”è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒSNN å’Œ LSTM çš„å¼‚å¸¸ä½å»¶è¿Ÿè¶…è¿‡äº†ä¼ ç»Ÿè§£ç å™¨å’Œé RNNï¼Œè¿™æºäºå®ƒä»¬ä»è„‰å†²ç¥ç»æ•°æ®ä¸­æå–æ—¶é—´ä¿¡æ¯çš„å¤©ç”Ÿèƒ½åŠ›ã€‚åŠŸç‡æ•ˆç‡å¯å½’å› äº SNN åœ¨åˆ©ç”¨ç¨€ç–æ€§æ–¹é¢çš„ç†Ÿç»ƒç¨‹åº¦åŠå…¶æœ‰æ„å—é™çš„æ¶æ„è®¾è®¡ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSNN å¯ä»¥åœ¨ä¸åˆ° 5 æ¯«ç§’å†…å®ç°å…·æœ‰ç«äº‰åŠ›çš„è§£ç æ€§èƒ½ï¼Œä½¿ç”¨ä¸åˆ° 1% çš„è®¡ç®—èµ„æºï¼Œå¹¶ä¸”æ¯”æœ¬åŸºå‡†ä¸­çš„å…¶ä»–ç¥ç»è§£ç æ–¹æ³•èŠ‚çœè¶…è¿‡ 50 å€çš„èƒ½é‡ã€‚è¿™ä½¿å¾—å®ƒä»¬æˆä¸ºé—­ç¯ iBCI æŒ‘æˆ˜çš„é«˜åº¦åˆé€‚å€™é€‰è€…ï¼Œå¹¶å°†å…¶å®šä½ä¸ºé‡å¡‘ç¥ç»è§£ç å™¨æ ¼å±€çš„å˜é©æ€§æŠ€æœ¯ã€‚é€šè¿‡é‡‡ç”¨ SNN ä½œä¸ºé¦–é€‰ç¥ç»è§£ç å™¨ï¼Œå¯ä»¥åœ¨ CLN æ–¹é¢å–å¾—é‡å¤§è¿›å±•ã€‚å®ƒä»¬é«˜æ•ˆä¸”å‡†ç¡®å¤„ç†ç¥ç»ä¿¡å·çš„èƒ½åŠ›æœ‰æœ›å½»åº•æ”¹å˜ BCI åº”ç”¨ï¼Œå¢å¼ºæˆ‘ä»¬ä¸äººç±»å¤§è„‘å¤æ‚æ€§äº’åŠ¨å’Œç†è§£çš„èƒ½åŠ›ã€‚</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Muatyz.github.io/posts/read/reference/brain-neural-networks-and-computation/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>Brain, neural networks, and computation</span>
  </a>
  <a class="next" href="https://Muatyz.github.io/posts/read/reference/odor-landscapes-in-turbulent-env/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>Odor Landscapes in Turbulent Environments</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>





<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-api-one-xi.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            region: 'ap-shanghai',  
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>Muartz</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script><script>

    let detail = document.getElementsByClassName('details')
   
    details = [].slice.call(detail);
   
    for (let index = 0; index < details.length; index++) {
   
    let element = details[index]
   
    const summary = element.getElementsByClassName('details-summary')[0];
   
    if (summary) {
   
    summary.addEventListener('click', () => {
   
    element.classList.toggle('open');
   
    }, false);
   
    }
   
    }
   
   </script>   

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>


<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        
        
        
        
        
        
        
        
        
        

        
        
        
        
        
        
        
        
        
        
        

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>


<script>
    
    document.addEventListener('keydown', function(event) {
      
      if (event.key === 'j') {
        
        var nextPageLink = document.querySelector('.pagination-item.pagination-next > a');
        if (nextPageLink) {
          nextPageLink.click();
        }
      } else if (event.key === 'k') {
        
        var prevPageLink = document.querySelector('.pagination-item.pagination-previous > a');
        if (prevPageLink) {
          prevPageLink.click();
        }
      }
    });
  </script>
  
</body>







<body>
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
</body>


</html>
