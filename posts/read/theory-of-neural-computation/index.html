<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Theory of Neural Computation | æ— å¤„æƒ¹å°˜åŸƒ</title>
<meta name="keywords" content="">
<meta name="description" content="æ¯å‘¨é˜…è¯»ç¬”è®°">
<meta name="author" content="Muartz">
<link rel="canonical" href="https://Muatyz.github.io/posts/read/theory-of-neural-computation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://Muatyz.github.io/img/Head16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Muatyz.github.io/img/Head32.png">
<link rel="apple-touch-icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="mask-icon" href="https://Muatyz.github.io/img/Head32.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Muatyz.github.io/posts/read/theory-of-neural-computation/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "www.muartz.com"; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script><meta property="og:title" content="Theory of Neural Computation" />
<meta property="og:description" content="æ¯å‘¨é˜…è¯»ç¬”è®°" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Muatyz.github.io/posts/read/theory-of-neural-computation/" />
<meta property="og:image" content="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-10-12T00:18:23+08:00" />
<meta property="article:modified_time" content="2025-10-12T00:18:23+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" />
<meta name="twitter:title" content="Theory of Neural Computation"/>
<meta name="twitter:description" content="æ¯å‘¨é˜…è¯»ç¬”è®°"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Muatyz.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "ğŸ“• é˜…è¯»",
          "item": "https://Muatyz.github.io/posts/read/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Theory of Neural Computation",
      "item": "https://Muatyz.github.io/posts/read/theory-of-neural-computation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Theory of Neural Computation",
  "name": "Theory of Neural Computation",
  "description": "æ¯å‘¨é˜…è¯»ç¬”è®°",
  "keywords": [
    ""
  ],
  "articleBody": "Introduction 1.1 Inspiration from Neuroscience Neurons McCulloch-Pitts Neuron Model\n$$ n_{i}(t+1) = \\Theta\\left[\\sum_{j}w_{ij}n_{j}(t)-\\mu_{i}\\right],\\quad \\Theta(x) = \\begin{cases} 1, \u0026 x \\geq 0 \\\\ 0, \u0026 \\text{otherwise} \\end{cases} $$\n$w_{ij}$: the strength of the synapse connecting neuron $j$ to neuron $i$.\ngraded response: respond to their input in a continuous way\nasynchronous updating(å¼‚æ­¥æ›´æ–°)\n$$ n_{i}:= g\\left( \\sum_{j}w_{ij}n_{j}-\\mu_{i} \\right) $$\n$n_{i}$: the state or activation of unit $i$.\n$g(x)$: (nonlinear) activation function, gain function, transfer function, or squashing function\nneuron $\\rightarrow$ unit(processing element, neurodes), synapse(çªè§¦) $\\rightarrow$ weight(æƒé‡).\nParallel Processing æ•°é‡çš„å·¨å¤§ä»¥å…è®¸é”™è¯¯ä¸å™ªå£°.\n1.2 History associative content-addressable memory(è”æƒ³å†…å®¹å¯»å€è®°å¿†), CAM\nThe Hopfield Model 2.1 The Associative Memory Problem Store a set of $p$ patterns $\\xi_{i}^{\\mu}$? in such a way that when presented with a new pattern $\\zeta_{i}$, the network responds by producing whichever one o f the stored patterns most closely resembles $\\zeta_{i}$.\nå­˜å‚¨ $p$ ä¸ªå›¾æ¡ˆ $\\xi_{i}^{\\mu}$ ä¸ºä¸€ç»„ï¼Œè¿™æ ·å½“å‡ºç°ä¸€ä¸ªæ–°å›¾æ¡ˆ $\\zeta_{i}$ æ—¶ï¼Œç½‘ç»œå°±ä¼šåšå‡ºååº”ï¼Œç”Ÿæˆå­˜å‚¨å›¾æ¡ˆä¸­ä¸ $\\zeta_{i}$ æœ€ç›¸ä¼¼çš„å›¾æ¡ˆã€‚å…¶ä¸­ $\\mu=1,2,\\cdots,p$ æ˜¯å›¾æ¡ˆçš„ç´¢å¼•ï¼Œ$i=1,2,\\cdots N$ æ˜¯ç¥ç»å…ƒçš„ç´¢å¼•.\nHamming distance:\n$$ \\sum_{i}[\\xi_{i}^{\\mu}(1-\\zeta_{i}) + (1-\\xi_{i}^{\\mu})\\zeta_{i}] $$\nå¦‚ä½•æ„å»º $w_{ij}$, ä½¿å¾—è¾“å…¥æµ‹è¯•å›¾æ¡ˆ $n_{i}=\\zeta_{i}$ æ—¶, è¾“å‡ºè®°å¿†å›¾æ¡ˆ $n_{i}=\\xi_{i}^{\\mu_{0}}$, å…¶ä¸­ $\\mu_{0}$ ä½¿å¾— Hamming distance($\\zeta_{i},\\xi_{i}^{\\mu}$) æœ€å°.\nè®°å¿†å›¾æ¡ˆæ˜¯ç›¸ç©ºé—´ä¸­ $\\mu$ ä¸ªå¸å¼•å­(attractor).\n2.2 The Model $n_{i}=0,1$ è®°å½•å•å…ƒçš„çŠ¶æ€, å¼•å…¥ $S_{i} = 2n_{i}-1 = \\pm 1$ è¡¨ç¤ºæ˜¯å¦æ¿€æ´».\nä»¤æ¿€æ´»å‡½æ•°ä¸ºç¬¦å·å‡½æ•°:\n$$ S_{i} := \\text{sgn}\\left(\\sum_{j}w_{ij}S_{j}-\\theta_{i}\\right),\\quad \\text{sgn}(x) = \\begin{cases} 1, \u0026 x \\geq 0 \\\\ -1, \u0026 x \u003c 0 \\end{cases} $$\n$\\theta_{i}$: threshold(é˜ˆå€¼), å…¶ä¸­ $\\theta_{i} = 2\\mu_{i}-\\sum_{j}w_{ij}$. ä¸ºç®€åŒ–å¯ä»¤ $\\theta_{i}=0$, é‚£ä¹ˆ\n$$ S_{i} := \\text{sgn}\\left(\\sum_{j}w_{ij}S_{j}\\right) $$\nå¼‚æ­¥æ›´æ–°(asynchronous)/åŒæ­¥æ›´æ–°(synchronous).\néšæœºé€‰å–ä¸€ä¸ªèŠ‚ç‚¹ $i$, ä»¤å…¶æ›´æ–° ä»¤å„èŠ‚ç‚¹ä»¥æŸæ¦‚ç‡åˆ¤å®šæ˜¯å¦æ›´æ–°. ä¸¤ç§æ–¹æ³•æ˜¯ç­‰ä»·çš„.\nå¼‚æ­¥æ›´æ–°çš„ç»ˆç‚¹æ˜¯æ²¡æœ‰ä»»ä½• $S_{i}$ å¯å˜åŒ–. è¿™è¦æ±‚ $w_{ij}$: 1. å›¾æ¡ˆå¯è¢«è®°å¿†ä¸ºç¨³å®šç‚¹; 2. æŠ—å¾®æ‰°.\nOne Pattern åªè®°å¿†ä¸€ä¸ªå›¾æ¡ˆ $\\{\\xi_{i}\\}$, åˆ™æ”¶æ•›æ¡ä»¶ä¸º\n$$ \\text{sgn}\\left(\\sum_{j}^{N}w_{ij}\\xi_{j}\\right) = \\xi_{i},\\quad \\forall i $$\nå–\n$$ w_{ij} = \\frac{1}{N}\\xi_{i}\\xi_{j} $$\nå› ä¸º $\\xi_{j}^{2} = 1$, å¯ä»¥è½»æ¾éªŒè¯è¯¥è®°å¿†æ–¹æ³•æˆç«‹.\nå› ä¸ºæ˜¯ç¬¦å·å‡½æ•°, å› æ­¤å³ä½¿åˆå§‹æ€ $h_{i}=\\sum_{j}w_{ij}S_{j}$ åå·®äº $\\xi_{i}$, åªè¦ç¬¦å·ä¸å˜, ä»ç„¶ä¼šæ”¶æ•›åˆ° $\\xi_{i}$. è¿™å°±æ˜¯ attractor(å¸å¼•å­).\nåœ¨è¿™ç§æ¿€æ´»å‡½æ•°ä¸‹, å¸å¼•å­æˆå¯¹å­˜åœ¨.\nMany Patterns Hebbâ€™s rule: å¯¹äºå­˜å‚¨æ€»å…± $p$ ä¸ªå›¾æ¡ˆ, ä½¿ç”¨ $\\mu$ æ ‡è®°å…¶ä¸­ä¸€ç§, å»¶æ‹“å®šä¹‰\n$$ w_{ij} = \\frac{1}{N}\\sum_{\\mu=1}^{p}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu} $$\nå¯¹ç¬¬ $\\nu$ ä¸ªå›¾æ¡ˆçš„ç¨³å®šæ€§æ¡ä»¶: $\\text{sgn}(h_{i}^{\\nu}) = \\xi_{i}^{\\nu}$\nä»¤è¾“å…¥\n$$ h_{i}^{\\nu} \\equiv \\sum_{j}w_{ij}\\xi_{j}^{\\nu} = \\frac{1}{N}\\sum_{j}\\sum_{\\mu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\xi_{j}^{\\nu} = \\xi_{i}^{\\nu} + \\frac{1}{N}\\sum_{j}\\sum_{\\mu \\neq \\nu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\xi_{j}^{\\nu} $$\nç¬¬äºŒé¡¹(è¢«ç§°ä¸º crosstalk)è¶³å¤Ÿå°(\u003c1)ç”šè‡³ä¸º $0$ æ—¶, ç¨³å®šæ€§æ¡ä»¶æ»¡è¶³.\nStorage Capacity ä»¤ç¬¬äºŒé¡¹ä¹˜ä¸Š $-\\xi_{i}^{\\nu}$, ä»è€Œå¼•å…¥\n$$ C_{i}^{\\nu} \\equiv -\\xi_{i}^{\\nu}\\frac{1}{N}\\sum_{j}\\sum_{\\mu \\neq \\nu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\xi_{j}^{\\nu} $$\né‚£ä¹ˆ\n$$ h_{i}^{\\nu} = \\xi_{i}^{\\nu} - \\frac{C_{i}^{\\nu}}{\\xi_{i}^{\\nu}} = \\xi_{i}^{\\nu}(1 - C_{i}^{\\nu}) $$\nå› ä¸º $(\\xi_{i}^{\\nu})^{2}=1$. é‚£ä¹ˆå½“ $C_{i}^{\\nu}\u003e1$ æ—¶, $h_{i}^{\\nu}$ å°†ä¸ $\\xi_{i}^{\\nu}$ å¼‚å·.\nä»¤å­˜å‚¨å›¾æ¡ˆä¸­ $\\xi_{j}^{\\mu} = \\pm 1$ ç­‰æ¦‚ç‡ç‹¬ç«‹åˆ†å¸ƒ. é‚£ä¹ˆå¼•å…¥ $X_{j\\mu}=(\\xi_{i}^{\\nu}\\xi_{i}^{\\mu})\\xi_{j}^{\\nu}\\xi_{j}^{\\mu}$, ä¸”æœ‰ $E[X_{j\\mu}]=0$, $\\text{Var}(X_{j\\mu})=1$.\nå› æ­¤\n$$ \\begin{aligned} E[C_{i}^{\\nu}] \u0026=0 \\\\ \\text{Var}(C_{i}^{\\nu}) \u0026= \\frac{1}{N^{2}}\\sum_{j}\\sum_{\\mu \\neq \\nu}\\text{Var}[X_{j\\mu}] = \\frac{1}{N^{2}}\\sum_{j}\\sum_{\\mu \\neq \\nu}1 = \\frac{1}{N^{2}}N(p-1) \\end{aligned} $$\né‚£ä¹ˆè¿‘ä¼¼ $C_{i}^{\\nu}\\approx \\mathcal{N}\\left(0,\\frac{p}{N}\\right)$.\nè§„å®š $P_{\\text{error}} = \\text{Prob}(C_{i}^{\\nu}\u003e1)$ ä¸ºå‡ºé”™æ¦‚ç‡, é‚£ä¹ˆ $P_{\\text{error}} \u003c\\epsilon$ æ—¶çš„ $p = p_{\\text{max}}$ è¢«ç§°ä½œ storage capacity(å­˜å‚¨å®¹é‡).\n$$ P_{\\text{error}} = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{1}^{\\infty}e^{-x^{2}}/2\\sigma^{2}\\mathrm{d}x = \\frac{1}{2}[1-\\text{erf}(1/\\sqrt{2\\sigma^{2}})] = \\frac{1}{2}[1-\\text{erf}(\\sqrt{N/2p})] $$\nerror function: $$ \\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{x}e^{-u^{2}}\\mathrm{d}u $$\nåˆ©ç”¨æé™\n$$ \\lim_{x\\rightarrow\\infty}1-\\text{erf}(x) \\rightarrow e^{-x^{2}}/\\sqrt{\\pi}x $$\nè¿‘ä¼¼\n$$ \\log{P_{\\text{error}}} \\approx -\\log{2} - N/2p - \\frac{1}{2}\\log{\\pi} - \\frac{1}{2}\\log{(N/2p)} $$\né”™è¯¯ç‡æ¡ä»¶ $P_{\\text{error}}\u003c0.01/N$ è½¬åŒ–ä¸º $N/2p\u003elog{N}$, å¾—åˆ° $p_{\\text{max}} = N/2\\log{N}$.\nThe Energy Function å®šä¹‰èƒ½é‡å‡½æ•°ä¸º\n$$ H = -\\frac{1}{2}\\sum_{i}\\sum_{j}w_{ij}S_{i}S_{j} $$\nLyapunov function.\nå¯¹ç§°é˜µ($w_{ij}=w_{ji}$) æ—¶èƒ½é‡å‡½æ•°å­˜åœ¨. æ­¤æ—¶ä¸å¦¨å†™ä½œ\n$$ H = C - \\sum_{(ij)}w_{ij}S_{i}S_{j} $$\nå°è¯•æ›´æ–°ä¸€æ¬¡èŠ‚ç‚¹ $i$:\n$$ S_{i}^{\\prime} = \\text{sgn}\\left(\\sum_{j}w_{ij}S_{j}\\right) $$\n$S_{i}^{\\prime} = S_{i}$ èƒ½é‡ä¸å˜; $S_{i}^{\\prime} = -S_{i}$, èƒ½é‡å˜æ¢ä¸º\n$$ H^{\\prime} - H = -\\sum_{j\\neq i}w_{ij}S_{i}^{\\prime}S_{j} + \\sum_{j\\neq i}w_{ij}S_{i}S_{j} = 2S_{i}\\sum_{j\\neq i}w_{ij}S_{j} = 2S_{i}\\sum_{j}w_{ij}S_{j} - 2w_{ii} $$\nå…¶ä¸­ $w_{ii} = p/N$, æ‰€ä»¥ $\\Delta H\u003c0$.\né€šè¿‡è®¾å®š $w_{ii}=0$, ä½¿å¾— $S_{i}=\\pm 1$ ä¸ä¼šåŒæ—¶ä¸ºç¨³å®šæ€.\nStarting from an Energy Function å•å›¾æ¡ˆ.\n$$ H = -\\frac{1}{2N}\\left(\\sum_{i}S_{i}\\xi_{i}\\right)^{2} $$\nå¤šå›¾æ¡ˆ.\n$$ \\begin{aligned} H \u0026= - \\frac{1}{2N}\\sum_{\\mu=1}^{p}\\left(\\sum_{i}S_{i}\\xi_{i}^{\\mu}\\right)^{2} \\\\ \u0026= -\\frac{1}{2N}\\sum_{\\mu=1}^{p}\\left(\\sum_{i}S_{i}\\xi_{i}^{\\mu}\\right)\\left(\\sum_{i}S_{j}\\xi_{j}^{\\mu}\\right) = -\\frac{1}{2}\\sum_{ij}\\left(\\frac{1}{N}\\sum_{\\mu=1}^{p}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\right)S_{i}S_{j} \\end{aligned} $$\né‡‡ç”¨ Hebbâ€™s rule æ—¶å³ä¸ºèƒ½é‡å‡½æ•°çš„å®šä¹‰. è¿™å°±æ˜¯é€šè¿‡æœ€å°èƒ½é‡è§‚ç‚¹å¯»æ‰¾ $w_{ij}$ çš„æ€è·¯.\nSpurious States(æ‚æ•£æ€) Hebbâ€™s rule é€‚ç”¨çš„æ˜¯ retrieval states(è®°å¿†æ€).\nSpurious States è¢«å®šä¹‰ä¸ºå¥‡æ•°ä¸ª retrieval states çš„çº¿æ€§ç»„åˆ. å¦‚\n$$ \\xi_{i}^{\\text{mix}} = \\text{sgn}\\left(\\pm \\xi_{i}^{\\mu_{1}} \\pm \\xi_{i}^{\\mu_{2}} \\pm \\xi_{i}^{\\mu_{3}}\\right) $$\nä»¥ $(+,+,+)$ ä¸ºä¾‹, è¾“å…¥\n$$ h_{i}^{\\text{mix}} = \\frac{1}{N}\\sum_{j\\mu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\xi_{j}^{\\text{mix}} = \\frac{1}{2}\\xi_{i}^{\\mu_{1}} + \\frac{1}{2}\\xi_{i}^{\\mu_{2}} + \\frac{1}{2}\\xi_{i}^{\\mu_{3}} + \\text{cross-terms} $$\nå¤§ $p$ æ—¶å‡ºç° spin glass states. è¿™äº›åŒæ ·æ˜¯èƒ½é‡å‡½æ•°çš„å±€éƒ¨æå°å€¼ç‚¹, éœ€è¦åç»­é€šè¿‡å„ç±»æ–¹æ³•åˆ¤åˆ«å¹¶æ’é™¤.\n2.3 Statistical Mechanics of Magnetic Systems ç£åœº\n$$ h_{i} = \\sum_{j}w_{ij}S_{j} + h^{\\text{ext}},\\quad w_{ij} = w_{ji} $$\nèƒ½é‡\n$$ H = -\\frac{1}{2}\\sum_{ij}w_{ij}S_{i}S_{j} - h^{\\text{ext}}\\sum_{i}S_{i} $$\nå¤–éƒ¨ç£åœº $\\leftrightarrow$ é˜ˆå€¼.\nFinite Temperature Dynamics æ¸©åº¦ çƒ­æ¶¨è½ ä½¿å¾—è‡ªæ—‹ç¿»è½¬.\nGlauber dynamics:\n$$ S_{i} := \\begin{cases} +1 \u0026 \\text{with probability } g(h_{i}) \\\\ -1 \u0026 \\text{with probability } 1 - g(h_{i}) \\end{cases},\\quad g(h) = f_{\\beta}(h)\\equiv \\frac{1}{1+e^{-2\\beta h}},\\quad \\beta = \\frac{1}{k_{B}T} $$\næ³¨æ„åˆ°æ€§è´¨ $1-f_{\\beta}(h) = f_{\\beta}(-h)$.\nåˆ™å†™ä½œå¯¹ç§°å½¢å¼\n$$ \\text{Prob}(S_{i}=\\pm 1) = f_{\\beta}(\\pm h_{i}) = \\frac{1}{1+e^{\\mp 2\\beta h_{i}}} $$\n$T\\rightarrow 0$($\\beta\\rightarrow\\infty$) æ—¶, $f_{\\beta}(h)$ é€€åŒ–ä¸ºé˜¶è·ƒå‡½æ•° $\\Theta(h)$, åˆ™ $S_{i}:=\\text{sgn}(h_{i})$;\n$T\\rightarrow \\infty$($\\beta\\rightarrow 0$) æ—¶, $f_{\\beta}(h)\\rightarrow 1/2$, åˆ™ $S_{i}$ ä»¥ $1/2$ æ¦‚ç‡å– $\\pm 1$, å³å®Œå…¨éšæœº.\nA Single Spin in Equilibrium $$ \\langle S\\rangle = \\text{Prob}(+1)\\cdot (+1) + \\text{Prob}(-1)\\cdot (-1) = \\frac{1}{1+e^{-2\\beta h}} - \\frac{1}{1+e^{2\\beta h}} = \\tanh(\\beta h) $$\nhyperbolic tangent function: $$ \\tanh(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $$\nMean Field Theory ç£åœºå¹³å‡å€¼å’Œè‡ªæ—‹å¹³å‡å€¼:\n$$ \\begin{aligned} \\langle h_{i}\\rangle \u0026= \\sum_{j}w_{ij}\\langle S_{j}\\rangle + h^{\\text{ext}}\\\\ \\langle S_{i}\\rangle \u0026= \\tanh\\left(\\beta\\langle h_{i}\\rangle\\right) = \\tanh\\left(\\beta\\sum_{j}w_{ij}\\langle S_{j}\\rangle + \\beta h^{\\text{ext}}\\right) \\end{aligned} $$\nThe Ferromagnet(é“ç£ä½“) é“ç£æ€ä¸‹ $w_{ij}\u003e0$, $\\langle S_{i}\\rangle = \\langle S\\rangle$.\n$$ w_{ij} = \\frac{J}{N} $$\n$$ \\langle S\\rangle = \\tanh(\\beta J\\langle S\\rangle) $$\né«˜æ¸©ä¸€ä¸ªé¡ºç£è§£, ä½æ¸©å¤šä¸¤ä¸ªé“ç£è§£(è‡ªå‘ç£åŒ– spontaneous magnetization).\n2.4 Stochastic Networks ä»¤ç¥ç»å…ƒçš„æ¿€æ´»/é™æ¯æ¦‚ç‡ä¸º\n$$ \\text{Prob}(S_{i} = \\pm 1) = f_{\\beta}(\\pm h_{i}) = \\frac{1}{1+e^{\\mp 2\\beta h_{i}}} $$\n$f_{\\beta}(h)$: logistic function(é€»è¾‘å‡½æ•°).\nå¼•å…¥ç­‰æ•ˆæ¸©åº¦ pseudo-temperature $T$, å³ $\\beta\\equiv \\frac{1}{T}$.\nä½æ¸©æé™ä¸‹ sigmoid å‡½æ•°é€€åŒ–ä¸ºé˜¶è·ƒå‡½æ•°, æ¦‚ç‡å‡½æ•°é€€åŒ–ä¸º McCulloch-Pitts rule.\nå¯¹ç§°é˜µ $w_{ij}$ ä½¿å¾—ç³»ç»¼å¹³å‡å¯ä»¥è¾¾åˆ°ä¸”ä¸æ—¶é—´æ— å…³.\nMean Field Theory $p\\ll N$\nå¹³å‡åœºæ–¹ç¨‹:\n$$ \\langle S_{i}\\rangle = \\tanh{\\left(\\frac{\\beta}{N}\\sum_{j\\mu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}\\langle S_{j}\\rangle\\right)}. $$\nå‡å®š $\\langle S_{i}\\rangle = m\\xi_{i}^{\\nu}$:\n$$ m\\xi_{i}^{\\nu} = \\tanh{\\left(\\frac{\\beta}{N}\\sum_{j\\mu}\\xi_{i}^{\\mu}\\xi_{j}^{\\mu}m\\xi_{j}^{\\nu}\\right)}\\Rightarrow m\\xi_{i}^{\\nu} = \\tanh{(\\beta m\\xi_{i}^{\\nu})}\\Rightarrow m = \\tanh{(\\beta m)} $$\nè®°å¿†æ€åœ¨ $T",
  "wordCount" : "5391",
  "inLanguage": "zh",
  "image":"https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png","datePublished": "2025-10-12T00:18:23+08:00",
  "dateModified": "2025-10-12T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "Muartz"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Muatyz.github.io/posts/read/theory-of-neural-computation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "æ— å¤„æƒ¹å°˜åŸƒ",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Muatyz.github.io/img/Head32.png"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  CommonHTML: {
  scale: 100
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
  
  
  
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script>

<style>
  code.has-jax {
      font: "LXGW WenKai Screen", sans-serif, Arial;
      scale: 1;
      background: "LXGW WenKai Screen", sans-serif, Arial;
      border: "LXGW WenKai Screen", sans-serif, Arial;
      color: #515151;
  }
</style>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Muatyz.github.io/" accesskey="h" title="è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿— (Alt + H)">
            <img src="https://Muatyz.github.io/img/Head64.png" alt="logo" aria-label="logo"
                 height="35">è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿—</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Muatyz.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Muatyz.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/">ğŸ“• é˜…è¯»</a></div>
            <h1 class="post-title">
                Theory of Neural Computation
            </h1>
            <div class="post-description">
                æ¯å‘¨é˜…è¯»ç¬”è®°
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-10-12
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>5391å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>11åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Muartz
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://Muatyz.github.io/tags/physics/" style="color: var(--secondary)!important;">Physics</a>
                &nbsp;<a href="https://Muatyz.github.io/tags/numerical-calculation/" style="color: var(--secondary)!important;">Numerical Calculation</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Muatyz.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId: "Admin", 
                                region: "ap-shanghai", 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a><ul>
                        
                <li>
                    <a href="#11-inspiration-from-neuroscience" aria-label="1.1 Inspiration from Neuroscience">1.1 Inspiration from Neuroscience</a><ul>
                        
                <li>
                    <a href="#neurons" aria-label="Neurons">Neurons</a></li>
                <li>
                    <a href="#parallel-processing" aria-label="Parallel Processing">Parallel Processing</a></li></ul>
                </li>
                <li>
                    <a href="#12-history" aria-label="1.2 History">1.2 History</a></li></ul>
                </li>
                <li>
                    <a href="#the-hopfield-model" aria-label="The Hopfield Model">The Hopfield Model</a><ul>
                        
                <li>
                    <a href="#21-the-associative-memory-problem" aria-label="2.1 The Associative Memory Problem">2.1 The Associative Memory Problem</a></li>
                <li>
                    <a href="#22-the-model" aria-label="2.2 The Model">2.2 The Model</a><ul>
                        
                <li>
                    <a href="#one-pattern" aria-label="One Pattern">One Pattern</a></li>
                <li>
                    <a href="#many-patterns" aria-label="Many Patterns">Many Patterns</a></li>
                <li>
                    <a href="#storage-capacity" aria-label="Storage Capacity">Storage Capacity</a></li>
                <li>
                    <a href="#the-energy-function" aria-label="The Energy Function">The Energy Function</a></li>
                <li>
                    <a href="#starting-from-an-energy-function" aria-label="Starting from an Energy Function">Starting from an Energy Function</a></li>
                <li>
                    <a href="#spurious-states%e6%9d%82%e6%95%a3%e6%80%81" aria-label="Spurious States(æ‚æ•£æ€)">Spurious States(æ‚æ•£æ€)</a></li></ul>
                </li>
                <li>
                    <a href="#23-statistical-mechanics-of-magnetic-systems" aria-label="2.3 Statistical Mechanics of Magnetic Systems">2.3 Statistical Mechanics of Magnetic Systems</a><ul>
                        
                <li>
                    <a href="#finite-temperature-dynamics" aria-label="Finite Temperature Dynamics">Finite Temperature Dynamics</a></li>
                <li>
                    <a href="#a-single-spin-in-equilibrium" aria-label="A Single Spin in Equilibrium">A Single Spin in Equilibrium</a></li>
                <li>
                    <a href="#mean-field-theory" aria-label="Mean Field Theory">Mean Field Theory</a></li>
                <li>
                    <a href="#the-ferromagnet%e9%93%81%e7%a3%81%e4%bd%93" aria-label="The Ferromagnet(é“ç£ä½“)">The Ferromagnet(é“ç£ä½“)</a></li></ul>
                </li>
                <li>
                    <a href="#24-stochastic-networks" aria-label="2.4 Stochastic Networks">2.4 Stochastic Networks</a><ul>
                        
                <li>
                    <a href="#mean-field-theory-1" aria-label="Mean Field Theory">Mean Field Theory</a></li></ul>
                </li>
                <li>
                    <a href="#25-capacity-of-the-stochastic-network" aria-label="2.5 Capacity of the Stochastic Network">2.5 Capacity of the Stochastic Network</a><ul>
                        
                <li>
                    <a href="#capacity-calculation" aria-label="Capacity Calculation">Capacity Calculation</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#simple-percptrons%e7%ae%80%e5%8d%95%e6%84%9f%e7%9f%a5%e6%9c%ba" aria-label="Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)">Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)</a><ul>
                        
                <li>
                    <a href="#51-feed-forward-networks" aria-label="5.1 Feed-Forward Networks">5.1 Feed-Forward Networks</a></li>
                <li>
                    <a href="#52-threshould-units%e9%98%88%e5%80%bc%e5%8d%95%e5%85%83" aria-label="5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)">5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)</a><ul>
                        
                <li>
                    <a href="#linear-separability%e7%ba%bf%e6%80%a7%e5%8f%af%e5%88%86%e6%80%a7" aria-label="Linear Separability(çº¿æ€§å¯åˆ†æ€§)">Linear Separability(çº¿æ€§å¯åˆ†æ€§)</a></li>
                <li>
                    <a href="#a-simple-learning-algorithm" aria-label="A Simple Learning Algorithm">A Simple Learning Algorithm</a></li></ul>
                </li>
                <li>
                    <a href="#53-proof-of-convergence-of-the-perceptron-learning-rule" aria-label="5.3 Proof of Convergence of the Perceptron Learning Rule">5.3 Proof of Convergence of the Perceptron Learning Rule</a></li>
                <li>
                    <a href="#54-linear-units" aria-label="5.4 Linear Units">5.4 Linear Units</a><ul>
                        
                <li>
                    <a href="#explicit-solution%e6%98%be%e5%bc%8f%e8%a7%a3" aria-label="Explicit Solution(æ˜¾å¼è§£)">Explicit Solution(æ˜¾å¼è§£)</a></li>
                <li>
                    <a href="#gradient-descent-learning%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e5%ad%a6%e4%b9%a0" aria-label="Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )">Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )</a></li>
                <li>
                    <a href="#convergence-of-gradient-descent" aria-label="Convergence of Gradient Descent">Convergence of Gradient Descent</a></li></ul>
                </li>
                <li>
                    <a href="#55-nonlinear-units" aria-label="5.5 Nonlinear Units">5.5 Nonlinear Units</a><ul>
                        
                <li>
                    <a href="#other-cost-functions" aria-label="Other Cost Functions">Other Cost Functions</a></li></ul>
                </li>
                <li>
                    <a href="#56-stochastic-units" aria-label="5.6 Stochastic Units">5.6 Stochastic Units</a></li>
                <li>
                    <a href="#57-capacity-of-the-simple-perceptron%e7%ae%80%e5%8d%95%e6%84%9f%e7%9f%a5%e6%9c%ba%e7%9a%84%e5%ae%b9%e9%87%8f" aria-label="5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)">5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<h2 id="11-inspiration-from-neuroscience">1.1 Inspiration from Neuroscience<a hidden class="anchor" aria-hidden="true" href="#11-inspiration-from-neuroscience">#</a></h2>
<h3 id="neurons">Neurons<a hidden class="anchor" aria-hidden="true" href="#neurons">#</a></h3>
<p>McCulloch-Pitts Neuron Model</p>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/CAyHLcoaRu2GKqz.png" alt=""  />
</p>
<p>$$
n_{i}(t+1) = \Theta\left[\sum_{j}w_{ij}n_{j}(t)-\mu_{i}\right],\quad
\Theta(x) = \begin{cases}
1, &amp; x \geq 0 \\
0, &amp; \text{otherwise}
\end{cases}
$$</p>
<p>$w_{ij}$: the strength of the synapse connecting neuron $j$ to neuron $i$.</p>
<p>graded response: respond to their input in a continuous way</p>
<p>asynchronous updating(å¼‚æ­¥æ›´æ–°)</p>
<p>$$
n_{i}:= g\left(
\sum_{j}w_{ij}n_{j}-\mu_{i}
\right)
$$</p>
<blockquote>
<p>$n_{i}$: the state or activation of unit $i$.</p>
<p>$g(x)$: (nonlinear) activation function, gain function, transfer function, or squashing function</p>
</blockquote>
<p>neuron $\rightarrow$ unit(processing element, neurodes), synapse(çªè§¦) $\rightarrow$ weight(æƒé‡).</p>
<h3 id="parallel-processing">Parallel Processing<a hidden class="anchor" aria-hidden="true" href="#parallel-processing">#</a></h3>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/FqBn6sHu7A3EVUO.png" alt=""  />
</p>
<p>æ•°é‡çš„å·¨å¤§ä»¥å…è®¸é”™è¯¯ä¸å™ªå£°.</p>
<h2 id="12-history">1.2 History<a hidden class="anchor" aria-hidden="true" href="#12-history">#</a></h2>
<p>associative content-addressable memory(è”æƒ³å†…å®¹å¯»å€è®°å¿†), CAM</p>
<h1 id="the-hopfield-model">The Hopfield Model<a hidden class="anchor" aria-hidden="true" href="#the-hopfield-model">#</a></h1>
<h2 id="21-the-associative-memory-problem">2.1 The Associative Memory Problem<a hidden class="anchor" aria-hidden="true" href="#21-the-associative-memory-problem">#</a></h2>
<blockquote>
<p>Store a set of $p$ patterns $\xi_{i}^{\mu}$? in such a way that when presented with a new pattern $\zeta_{i}$, the network responds by producing whichever one o f the stored patterns most closely resembles $\zeta_{i}$.</p>
</blockquote>
<p>å­˜å‚¨ $p$ ä¸ªå›¾æ¡ˆ $\xi_{i}^{\mu}$ ä¸ºä¸€ç»„ï¼Œè¿™æ ·å½“å‡ºç°ä¸€ä¸ªæ–°å›¾æ¡ˆ $\zeta_{i}$ æ—¶ï¼Œç½‘ç»œå°±ä¼šåšå‡ºååº”ï¼Œç”Ÿæˆå­˜å‚¨å›¾æ¡ˆä¸­ä¸ $\zeta_{i}$ æœ€ç›¸ä¼¼çš„å›¾æ¡ˆã€‚å…¶ä¸­ $\mu=1,2,\cdots,p$ æ˜¯å›¾æ¡ˆçš„ç´¢å¼•ï¼Œ$i=1,2,\cdots N$ æ˜¯ç¥ç»å…ƒçš„ç´¢å¼•.</p>
<p>Hamming distance:</p>
<p>$$
\sum_{i}[\xi_{i}^{\mu}(1-\zeta_{i}) + (1-\xi_{i}^{\mu})\zeta_{i}]
$$</p>
<p>å¦‚ä½•æ„å»º $w_{ij}$, ä½¿å¾—è¾“å…¥æµ‹è¯•å›¾æ¡ˆ $n_{i}=\zeta_{i}$ æ—¶, è¾“å‡ºè®°å¿†å›¾æ¡ˆ $n_{i}=\xi_{i}^{\mu_{0}}$, å…¶ä¸­ $\mu_{0}$ ä½¿å¾— Hamming distance($\zeta_{i},\xi_{i}^{\mu}$) æœ€å°.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/YlxrHLwtsOBGZXC.png" alt=""  />
</p>
</blockquote>
<p>è®°å¿†å›¾æ¡ˆæ˜¯ç›¸ç©ºé—´ä¸­ $\mu$ ä¸ªå¸å¼•å­(attractor).</p>
<h2 id="22-the-model">2.2 The Model<a hidden class="anchor" aria-hidden="true" href="#22-the-model">#</a></h2>
<p>$n_{i}=0,1$ è®°å½•å•å…ƒçš„çŠ¶æ€, å¼•å…¥ $S_{i} = 2n_{i}-1 = \pm 1$ è¡¨ç¤ºæ˜¯å¦æ¿€æ´».</p>
<p>ä»¤æ¿€æ´»å‡½æ•°ä¸ºç¬¦å·å‡½æ•°:</p>
<p>$$
S_{i} := \text{sgn}\left(\sum_{j}w_{ij}S_{j}-\theta_{i}\right),\quad \text{sgn}(x) = \begin{cases}
1, &amp; x \geq 0 \\
-1, &amp; x &lt; 0
\end{cases}
$$</p>
<p>$\theta_{i}$: threshold(é˜ˆå€¼), å…¶ä¸­ $\theta_{i} = 2\mu_{i}-\sum_{j}w_{ij}$. ä¸ºç®€åŒ–å¯ä»¤ $\theta_{i}=0$, é‚£ä¹ˆ</p>
<p>$$
S_{i} := \text{sgn}\left(\sum_{j}w_{ij}S_{j}\right)
$$</p>
<p>å¼‚æ­¥æ›´æ–°(asynchronous)/åŒæ­¥æ›´æ–°(synchronous).</p>
<blockquote>
<ol>
<li>éšæœºé€‰å–ä¸€ä¸ªèŠ‚ç‚¹ $i$, ä»¤å…¶æ›´æ–°</li>
<li>ä»¤å„èŠ‚ç‚¹ä»¥æŸæ¦‚ç‡åˆ¤å®šæ˜¯å¦æ›´æ–°.</li>
</ol>
<p>ä¸¤ç§æ–¹æ³•æ˜¯ç­‰ä»·çš„.</p>
</blockquote>
<p>å¼‚æ­¥æ›´æ–°çš„ç»ˆç‚¹æ˜¯æ²¡æœ‰ä»»ä½• $S_{i}$ å¯å˜åŒ–. è¿™è¦æ±‚ $w_{ij}$: 1. å›¾æ¡ˆå¯è¢«è®°å¿†ä¸ºç¨³å®šç‚¹; 2. æŠ—å¾®æ‰°.</p>
<h3 id="one-pattern">One Pattern<a hidden class="anchor" aria-hidden="true" href="#one-pattern">#</a></h3>
<p>åªè®°å¿†ä¸€ä¸ªå›¾æ¡ˆ $\{\xi_{i}\}$, åˆ™æ”¶æ•›æ¡ä»¶ä¸º</p>
<p>$$
\text{sgn}\left(\sum_{j}^{N}w_{ij}\xi_{j}\right) = \xi_{i},\quad \forall i
$$</p>
<p>å–</p>
<p>$$
w_{ij} = \frac{1}{N}\xi_{i}\xi_{j}
$$</p>
<p>å› ä¸º $\xi_{j}^{2} = 1$, å¯ä»¥è½»æ¾éªŒè¯è¯¥è®°å¿†æ–¹æ³•æˆç«‹.</p>
<p>å› ä¸ºæ˜¯ç¬¦å·å‡½æ•°, å› æ­¤å³ä½¿åˆå§‹æ€ $h_{i}=\sum_{j}w_{ij}S_{j}$ åå·®äº $\xi_{i}$, åªè¦ç¬¦å·ä¸å˜, ä»ç„¶ä¼šæ”¶æ•›åˆ° $\xi_{i}$. è¿™å°±æ˜¯ attractor(å¸å¼•å­).</p>
<p>åœ¨è¿™ç§æ¿€æ´»å‡½æ•°ä¸‹, å¸å¼•å­æˆå¯¹å­˜åœ¨.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/hzEOak3HnRCtL5G.png" alt=""  />
</p>
</blockquote>
<h3 id="many-patterns">Many Patterns<a hidden class="anchor" aria-hidden="true" href="#many-patterns">#</a></h3>
<p>Hebb&rsquo;s rule: å¯¹äºå­˜å‚¨æ€»å…± $p$ ä¸ªå›¾æ¡ˆ, ä½¿ç”¨ $\mu$ æ ‡è®°å…¶ä¸­ä¸€ç§, å»¶æ‹“å®šä¹‰</p>
<p>$$
w_{ij} = \frac{1}{N}\sum_{\mu=1}^{p}\xi_{i}^{\mu}\xi_{j}^{\mu}
$$</p>
<p>å¯¹ç¬¬ $\nu$ ä¸ªå›¾æ¡ˆçš„ç¨³å®šæ€§æ¡ä»¶: $\text{sgn}(h_{i}^{\nu}) = \xi_{i}^{\nu}$</p>
<p>ä»¤è¾“å…¥</p>
<p>$$
h_{i}^{\nu} \equiv \sum_{j}w_{ij}\xi_{j}^{\nu} = \frac{1}{N}\sum_{j}\sum_{\mu}\xi_{i}^{\mu}\xi_{j}^{\mu}\xi_{j}^{\nu} = \xi_{i}^{\nu} + \frac{1}{N}\sum_{j}\sum_{\mu \neq \nu}\xi_{i}^{\mu}\xi_{j}^{\mu}\xi_{j}^{\nu}
$$</p>
<p>ç¬¬äºŒé¡¹(è¢«ç§°ä¸º crosstalk)è¶³å¤Ÿå°(&lt;1)ç”šè‡³ä¸º $0$ æ—¶, ç¨³å®šæ€§æ¡ä»¶æ»¡è¶³.</p>
<h3 id="storage-capacity">Storage Capacity<a hidden class="anchor" aria-hidden="true" href="#storage-capacity">#</a></h3>
<p>ä»¤ç¬¬äºŒé¡¹ä¹˜ä¸Š $-\xi_{i}^{\nu}$, ä»è€Œå¼•å…¥</p>
<p>$$
C_{i}^{\nu} \equiv -\xi_{i}^{\nu}\frac{1}{N}\sum_{j}\sum_{\mu \neq \nu}\xi_{i}^{\mu}\xi_{j}^{\mu}\xi_{j}^{\nu}
$$</p>
<p>é‚£ä¹ˆ</p>
<p>$$
h_{i}^{\nu} = \xi_{i}^{\nu} - \frac{C_{i}^{\nu}}{\xi_{i}^{\nu}} = \xi_{i}^{\nu}(1 - C_{i}^{\nu})
$$</p>
<p>å› ä¸º $(\xi_{i}^{\nu})^{2}=1$. é‚£ä¹ˆå½“ $C_{i}^{\nu}&gt;1$ æ—¶, $h_{i}^{\nu}$ å°†ä¸ $\xi_{i}^{\nu}$ å¼‚å·.</p>
<p>ä»¤å­˜å‚¨å›¾æ¡ˆä¸­ $\xi_{j}^{\mu} = \pm 1$ ç­‰æ¦‚ç‡ç‹¬ç«‹åˆ†å¸ƒ. é‚£ä¹ˆå¼•å…¥ $X_{j\mu}=(\xi_{i}^{\nu}\xi_{i}^{\mu})\xi_{j}^{\nu}\xi_{j}^{\mu}$, ä¸”æœ‰ $E[X_{j\mu}]=0$, $\text{Var}(X_{j\mu})=1$.</p>
<p>å› æ­¤</p>
<p>$$
\begin{aligned}
E[C_{i}^{\nu}] &amp;=0 \\
\text{Var}(C_{i}^{\nu}) &amp;= \frac{1}{N^{2}}\sum_{j}\sum_{\mu \neq \nu}\text{Var}[X_{j\mu}] = \frac{1}{N^{2}}\sum_{j}\sum_{\mu \neq \nu}1 = \frac{1}{N^{2}}N(p-1)
\end{aligned}
$$</p>
<p>é‚£ä¹ˆè¿‘ä¼¼ $C_{i}^{\nu}\approx \mathcal{N}\left(0,\frac{p}{N}\right)$.</p>
<p>è§„å®š $P_{\text{error}} = \text{Prob}(C_{i}^{\nu}&gt;1)$ ä¸ºå‡ºé”™æ¦‚ç‡, é‚£ä¹ˆ $P_{\text{error}} &lt;\epsilon$ æ—¶çš„ $p = p_{\text{max}}$ è¢«ç§°ä½œ storage capacity(å­˜å‚¨å®¹é‡).</p>
<p>$$
P_{\text{error}} = \frac{1}{\sqrt{2\pi}\sigma}\int_{1}^{\infty}e^{-x^{2}}/2\sigma^{2}\mathrm{d}x = \frac{1}{2}[1-\text{erf}(1/\sqrt{2\sigma^{2}})] = \frac{1}{2}[1-\text{erf}(\sqrt{N/2p})]
$$</p>
<blockquote>
<p>error function:
$$
\text{erf}(x) = \frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-u^{2}}\mathrm{d}u
$$</p>
</blockquote>
<p>åˆ©ç”¨æé™</p>
<p>$$
\lim_{x\rightarrow\infty}1-\text{erf}(x) \rightarrow e^{-x^{2}}/\sqrt{\pi}x
$$</p>
<p>è¿‘ä¼¼</p>
<p>$$
\log{P_{\text{error}}} \approx -\log{2} - N/2p - \frac{1}{2}\log{\pi} - \frac{1}{2}\log{(N/2p)}
$$</p>
<p>é”™è¯¯ç‡æ¡ä»¶ $P_{\text{error}}&lt;0.01/N$ è½¬åŒ–ä¸º $N/2p&gt;log{N}$, å¾—åˆ° $p_{\text{max}} = N/2\log{N}$.</p>
<h3 id="the-energy-function">The Energy Function<a hidden class="anchor" aria-hidden="true" href="#the-energy-function">#</a></h3>
<p>å®šä¹‰èƒ½é‡å‡½æ•°ä¸º</p>
<p>$$
H = -\frac{1}{2}\sum_{i}\sum_{j}w_{ij}S_{i}S_{j}
$$</p>
<p>Lyapunov function.</p>
<p>å¯¹ç§°é˜µ($w_{ij}=w_{ji}$) æ—¶èƒ½é‡å‡½æ•°å­˜åœ¨. æ­¤æ—¶ä¸å¦¨å†™ä½œ</p>
<p>$$
H = C - \sum_{(ij)}w_{ij}S_{i}S_{j}
$$</p>
<p>å°è¯•æ›´æ–°ä¸€æ¬¡èŠ‚ç‚¹ $i$:</p>
<p>$$
S_{i}^{\prime} = \text{sgn}\left(\sum_{j}w_{ij}S_{j}\right)
$$</p>
<p>$S_{i}^{\prime} = S_{i}$ èƒ½é‡ä¸å˜; $S_{i}^{\prime} = -S_{i}$, èƒ½é‡å˜æ¢ä¸º</p>
<p>$$
H^{\prime} - H = -\sum_{j\neq i}w_{ij}S_{i}^{\prime}S_{j} + \sum_{j\neq i}w_{ij}S_{i}S_{j} = 2S_{i}\sum_{j\neq i}w_{ij}S_{j} = 2S_{i}\sum_{j}w_{ij}S_{j} - 2w_{ii}
$$</p>
<p>å…¶ä¸­ $w_{ii} = p/N$, æ‰€ä»¥ $\Delta H&lt;0$.</p>
<p>é€šè¿‡è®¾å®š $w_{ii}=0$, ä½¿å¾— $S_{i}=\pm 1$ ä¸ä¼šåŒæ—¶ä¸ºç¨³å®šæ€.</p>
<h3 id="starting-from-an-energy-function">Starting from an Energy Function<a hidden class="anchor" aria-hidden="true" href="#starting-from-an-energy-function">#</a></h3>
<p>å•å›¾æ¡ˆ.</p>
<p>$$
H = -\frac{1}{2N}\left(\sum_{i}S_{i}\xi_{i}\right)^{2}
$$</p>
<p>å¤šå›¾æ¡ˆ.</p>
<p>$$
\begin{aligned}
H &amp;= - \frac{1}{2N}\sum_{\mu=1}^{p}\left(\sum_{i}S_{i}\xi_{i}^{\mu}\right)^{2} \\
&amp;= -\frac{1}{2N}\sum_{\mu=1}^{p}\left(\sum_{i}S_{i}\xi_{i}^{\mu}\right)\left(\sum_{i}S_{j}\xi_{j}^{\mu}\right) = -\frac{1}{2}\sum_{ij}\left(\frac{1}{N}\sum_{\mu=1}^{p}\xi_{i}^{\mu}\xi_{j}^{\mu}\right)S_{i}S_{j}
\end{aligned}
$$</p>
<p>é‡‡ç”¨ Hebb&rsquo;s rule æ—¶å³ä¸ºèƒ½é‡å‡½æ•°çš„å®šä¹‰. è¿™å°±æ˜¯é€šè¿‡æœ€å°èƒ½é‡è§‚ç‚¹å¯»æ‰¾ $w_{ij}$ çš„æ€è·¯.</p>
<h3 id="spurious-statesæ‚æ•£æ€">Spurious States(æ‚æ•£æ€)<a hidden class="anchor" aria-hidden="true" href="#spurious-statesæ‚æ•£æ€">#</a></h3>
<p>Hebb&rsquo;s rule é€‚ç”¨çš„æ˜¯ retrieval states(è®°å¿†æ€).</p>
<p>Spurious States è¢«å®šä¹‰ä¸ºå¥‡æ•°ä¸ª retrieval states çš„çº¿æ€§ç»„åˆ. å¦‚</p>
<p>$$
\xi_{i}^{\text{mix}} = \text{sgn}\left(\pm \xi_{i}^{\mu_{1}} \pm \xi_{i}^{\mu_{2}} \pm \xi_{i}^{\mu_{3}}\right)
$$</p>
<p>ä»¥ $(+,+,+)$ ä¸ºä¾‹, è¾“å…¥</p>
<p>$$
h_{i}^{\text{mix}} = \frac{1}{N}\sum_{j\mu}\xi_{i}^{\mu}\xi_{j}^{\mu}\xi_{j}^{\text{mix}} = \frac{1}{2}\xi_{i}^{\mu_{1}} + \frac{1}{2}\xi_{i}^{\mu_{2}} + \frac{1}{2}\xi_{i}^{\mu_{3}} + \text{cross-terms}
$$</p>
<p>å¤§ $p$ æ—¶å‡ºç° spin glass states. è¿™äº›åŒæ ·æ˜¯èƒ½é‡å‡½æ•°çš„å±€éƒ¨æå°å€¼ç‚¹, éœ€è¦åç»­é€šè¿‡å„ç±»æ–¹æ³•åˆ¤åˆ«å¹¶æ’é™¤.</p>
<h2 id="23-statistical-mechanics-of-magnetic-systems">2.3 Statistical Mechanics of Magnetic Systems<a hidden class="anchor" aria-hidden="true" href="#23-statistical-mechanics-of-magnetic-systems">#</a></h2>
<p>ç£åœº</p>
<p>$$
h_{i} = \sum_{j}w_{ij}S_{j} + h^{\text{ext}},\quad w_{ij} = w_{ji}
$$</p>
<p>èƒ½é‡</p>
<p>$$
H = -\frac{1}{2}\sum_{ij}w_{ij}S_{i}S_{j} - h^{\text{ext}}\sum_{i}S_{i}
$$</p>
<p>å¤–éƒ¨ç£åœº $\leftrightarrow$ é˜ˆå€¼.</p>
<h3 id="finite-temperature-dynamics">Finite Temperature Dynamics<a hidden class="anchor" aria-hidden="true" href="#finite-temperature-dynamics">#</a></h3>
<p>æ¸©åº¦ çƒ­æ¶¨è½ ä½¿å¾—è‡ªæ—‹ç¿»è½¬.</p>
<p>Glauber dynamics:</p>
<p>$$
S_{i} := \begin{cases}
+1 &amp; \text{with probability } g(h_{i}) \\
-1 &amp; \text{with probability } 1 - g(h_{i})
\end{cases},\quad g(h) = f_{\beta}(h)\equiv \frac{1}{1+e^{-2\beta h}},\quad \beta = \frac{1}{k_{B}T}
$$</p>
<p>æ³¨æ„åˆ°æ€§è´¨ $1-f_{\beta}(h) = f_{\beta}(-h)$.</p>
<p>åˆ™å†™ä½œå¯¹ç§°å½¢å¼</p>
<p>$$
\text{Prob}(S_{i}=\pm 1) = f_{\beta}(\pm h_{i}) = \frac{1}{1+e^{\mp 2\beta h_{i}}}
$$</p>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/MbktpjSUlued9wO.png" alt=""  />
</p>
<p>$T\rightarrow 0$($\beta\rightarrow\infty$) æ—¶, $f_{\beta}(h)$ é€€åŒ–ä¸ºé˜¶è·ƒå‡½æ•° $\Theta(h)$, åˆ™ $S_{i}:=\text{sgn}(h_{i})$;</p>
<p>$T\rightarrow \infty$($\beta\rightarrow 0$) æ—¶, $f_{\beta}(h)\rightarrow 1/2$, åˆ™ $S_{i}$ ä»¥ $1/2$ æ¦‚ç‡å– $\pm 1$, å³å®Œå…¨éšæœº.</p>
<h3 id="a-single-spin-in-equilibrium">A Single Spin in Equilibrium<a hidden class="anchor" aria-hidden="true" href="#a-single-spin-in-equilibrium">#</a></h3>
<p>$$
\langle S\rangle = \text{Prob}(+1)\cdot (+1) + \text{Prob}(-1)\cdot (-1) = \frac{1}{1+e^{-2\beta h}} - \frac{1}{1+e^{2\beta h}} = \tanh(\beta h)
$$</p>
<blockquote>
<p>hyperbolic tangent function:
$$
\tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
$$</p>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/12/QW61iKcCrqRgaZd.png" alt=""  />
</p>
</blockquote>
<h3 id="mean-field-theory">Mean Field Theory<a hidden class="anchor" aria-hidden="true" href="#mean-field-theory">#</a></h3>
<p>ç£åœºå¹³å‡å€¼å’Œè‡ªæ—‹å¹³å‡å€¼:</p>
<p>$$
\begin{aligned}
\langle h_{i}\rangle &amp;= \sum_{j}w_{ij}\langle S_{j}\rangle + h^{\text{ext}}\\
\langle S_{i}\rangle &amp;= \tanh\left(\beta\langle h_{i}\rangle\right) = \tanh\left(\beta\sum_{j}w_{ij}\langle S_{j}\rangle + \beta h^{\text{ext}}\right)
\end{aligned}
$$</p>
<h3 id="the-ferromagneté“ç£ä½“">The Ferromagnet(é“ç£ä½“)<a hidden class="anchor" aria-hidden="true" href="#the-ferromagneté“ç£ä½“">#</a></h3>
<p>é“ç£æ€ä¸‹ $w_{ij}&gt;0$, $\langle S_{i}\rangle = \langle S\rangle$.</p>
<p>$$
w_{ij} = \frac{J}{N}
$$</p>
<p>$$
\langle S\rangle = \tanh(\beta J\langle S\rangle)
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/13/FtXqxhlMK7rQeV9.png" alt=""  />
</p>
<p>é«˜æ¸©ä¸€ä¸ªé¡ºç£è§£, ä½æ¸©å¤šä¸¤ä¸ªé“ç£è§£(è‡ªå‘ç£åŒ– spontaneous magnetization).</p>
</blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/13/eIMiAyw3EZdT47S.png" alt=""  />
</p>
</blockquote>
<h2 id="24-stochastic-networks">2.4 Stochastic Networks<a hidden class="anchor" aria-hidden="true" href="#24-stochastic-networks">#</a></h2>
<p>ä»¤ç¥ç»å…ƒçš„æ¿€æ´»/é™æ¯æ¦‚ç‡ä¸º</p>
<p>$$
\text{Prob}(S_{i} = \pm 1) = f_{\beta}(\pm h_{i}) = \frac{1}{1+e^{\mp 2\beta h_{i}}}
$$</p>
<p>$f_{\beta}(h)$: logistic function(é€»è¾‘å‡½æ•°).</p>
<p>å¼•å…¥ç­‰æ•ˆæ¸©åº¦ pseudo-temperature $T$, å³ $\beta\equiv \frac{1}{T}$.</p>
<p>ä½æ¸©æé™ä¸‹ sigmoid å‡½æ•°é€€åŒ–ä¸ºé˜¶è·ƒå‡½æ•°, æ¦‚ç‡å‡½æ•°é€€åŒ–ä¸º McCulloch-Pitts rule.</p>
<p>å¯¹ç§°é˜µ $w_{ij}$ ä½¿å¾—ç³»ç»¼å¹³å‡å¯ä»¥è¾¾åˆ°ä¸”ä¸æ—¶é—´æ— å…³.</p>
<h3 id="mean-field-theory-1">Mean Field Theory<a hidden class="anchor" aria-hidden="true" href="#mean-field-theory-1">#</a></h3>
<p>$p\ll N$</p>
<p>å¹³å‡åœºæ–¹ç¨‹:</p>
<p>$$
\langle S_{i}\rangle = \tanh{\left(\frac{\beta}{N}\sum_{j\mu}\xi_{i}^{\mu}\xi_{j}^{\mu}\langle S_{j}\rangle\right)}.
$$</p>
<p>å‡å®š $\langle S_{i}\rangle = m\xi_{i}^{\nu}$:</p>
<p>$$
m\xi_{i}^{\nu} = \tanh{\left(\frac{\beta}{N}\sum_{j\mu}\xi_{i}^{\mu}\xi_{j}^{\mu}m\xi_{j}^{\nu}\right)}\Rightarrow m\xi_{i}^{\nu} = \tanh{(\beta m\xi_{i}^{\nu})}\Rightarrow m = \tanh{(\beta m)}
$$</p>
<p>è®°å¿†æ€åœ¨ $T&lt;T_{c} = 1$ æ—¶ç¨³å®š.</p>
<p>$$
m = \frac{\langle S_{i}\rangle}{\xi_{i}^{\nu}} = \text{Prob}(\text{bit }i\text{ is correct}) - \text{Prob}(\text{bit }i\text{ is incorrect})
$$</p>
<p>$$
\langle N_{\text{correct}}\rangle = \frac{1}{2}N(1+m)
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/13/854daTcO3pgufVK.png" alt=""  />
</p>
</blockquote>
<p>è¿™ä¸æ˜¯å®Œç¾è£…ç½®. åè½¬æ€å’Œæ··åˆæ€éƒ½ä¼šå­˜åœ¨.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/10/13/wJ2ympMLhTiRzdN.png" alt=""  />
</p>
</blockquote>
<h2 id="25-capacity-of-the-stochastic-network">2.5 Capacity of the Stochastic Network<a hidden class="anchor" aria-hidden="true" href="#25-capacity-of-the-stochastic-network">#</a></h2>
<p>è€ƒå¯Ÿ $p\sim N$.</p>
<p>å®šä¹‰ load parameter(è´Ÿè½½å‚æ•°): $\alpha = \frac{p}{N}$.</p>
<p>ä¿ç•™ crosstalk é¡¹, å³</p>
<p>$$
m_{\nu} = \frac{1}{N}\sum_{i}\xi_{i}^{\nu}\langle S_{i}\rangle
$$</p>
<p>$$
r = \frac{1}{\alpha}\sum_{\nu\neq 1}m_{\nu}^{2}
$$</p>
<p>æ˜¯ç³»ç»Ÿæ„å‹çš„å‡æ–¹é‡å .</p>
<h3 id="capacity-calculation">Capacity Calculation<a hidden class="anchor" aria-hidden="true" href="#capacity-calculation">#</a></h3>
<p>å¹³å‡åœºæ–¹ç¨‹:</p>
<p>$$
\begin{aligned}
m_{\nu} &amp;= \frac{1}{N}\sum_{i}\xi_{i}^{\nu}\tanh{\left(\beta\sum_{\mu}\xi_{i}^{\mu}m_{\mu}\right)} = \frac{1}{N}\sum_{i}\xi_{i}^{\nu}\xi_{i}^{1}\tanh{\left[
\beta\left(
m_{1} + \xi_{i}^{\nu}\xi_{i}^{1}m_{\nu} + \sum_{\mu\neq 1,\nu}\xi_{i}^{\mu}\xi_{i}^{1}m_{\mu}
\right)
\right]}\\
&amp;= \frac{1}{N}\sum_{i}\xi_{i}^{\nu}\xi_{i}^{1}\tanh{\left[
\beta\left(
m_{1} + \sum_{\mu\neq 1,\nu}\xi_{i}^{\mu}\xi_{i}^{1}m_{\mu}
\right)
\right]} + \frac{\beta}{N}\sum_{i}\left\{
1-\tanh^{2}\left[
\beta\left(
m_{1} + \sum_{\mu\neq 1,\nu}\xi_{i}^{\mu}\xi_{i}^{1}m_{\mu}
\right)
\right]
\right\}m_{\nu}
\end{aligned}
$$</p>
<blockquote>
<p>å› ä¸ºç¬¬äºŒé¡¹æå°:
$$
\frac{\mathrm{d}}{\mathrm{d}x}\tanh(x) = 1-\tanh^{2}(x)
$$</p>
</blockquote>
<p>ä¸­å¿ƒæé™å®šç†: $N^{-1}\sum_{i}$ è§†ä¸º Gaussian å™ªå£° $\sum_{\mu\neq 1,\nu}\xi_{i}^{\mu}\xi_{i}^{1}m_{\mu}$, æ–¹å·®ä¸º $\alpha r$.</p>
<h1 id="simple-percptronsç®€å•æ„ŸçŸ¥æœº">Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)<a hidden class="anchor" aria-hidden="true" href="#simple-percptronsç®€å•æ„ŸçŸ¥æœº">#</a></h1>
<p>supervised learning(learning with a teacher)ç›‘ç£å­¦ä¹ </p>
<h2 id="51-feed-forward-networks">5.1 Feed-Forward Networks<a hidden class="anchor" aria-hidden="true" href="#51-feed-forward-networks">#</a></h2>
<p>Perceptrons: layered feed-forward networks(åˆ†å±‚å‰é¦ˆç½‘ç»œ).</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/yn3CIk9Q7qutsfB.png" alt=""  />

one-layer and two-layer(hidden units) perceptrons. $N$-layer network has $N$ layers of connections and $N â€” 1$ hidden layers.</p>
</blockquote>
<p>asymmetric connection matrices $w_{ij}$(triangular matrix, ä¸‰è§’çŸ©é˜µ): no energy function exists. åªæœ‰å¯¹ç§°é˜µå­˜åœ¨èƒ½é‡å‡½æ•°</p>
<p>$$
H = -\frac{1}{2}\sum_{ij}w_{ij}S_{i}S_{j}
$$</p>
<p>Simple perceptron(no hidden units). Input: $\xi_{k}$; Output: $O_{i}$.</p>
<p>$$
O_{i} = g(h_{i}) = g\left(\sum_{k}w_{ik}\xi_{k}\right),\quad g(h): \text{activation function}
$$</p>
<blockquote>
<p>Output is an explicit(æ˜¾å¼) function of the input.</p>
</blockquote>
<p>é˜ˆå€¼å¯ä»¥è¢«å¤„ç†ä¸ºä¸€ä¸ªç­‰æ•ˆçš„è¾“å…¥èŠ‚ç‚¹ $\xi_{0} = - 1$, ä¸”æƒé‡ $w_{i0} = \theta_{i}$.</p>
<p>$$
O_{i} = g\left(\sum_{k=0}^{N}w_{ik}\xi_{k}\right) = g\left(\sum_{k=1}^{N}w_{ik}\xi_{k}-\theta_{i}\right)
$$</p>
<p>ç›®æ ‡: è‹¥ input $\xi_{k}^{\mu}$ æ‰€å¾—çš„ output ä¸º $O_{i}^{\mu}$, è¦æ±‚ the general association task: $O_{i}^{\mu} = \zeta_{i}^{\mu}$(target pattern).</p>
<blockquote>
<p>å…¶ä¸­ $k$ ä¸º input èŠ‚ç‚¹æ ‡è®°, $i$ ä¸º output èŠ‚ç‚¹æ ‡è®°, $\mu=1,\cdots,p$ ä¸º pattern/pairs æ ‡è®°.</p>
</blockquote>
<p>boolean($\pm 1$) / continuous-valued.</p>
<ul>
<li>
<p>auto-association task(è‡ªå…³è”ä»»åŠ¡): è¾“å…¥ pattern $\xi_{k}^{\mu}$, è¾“å‡º pattern ä¹Ÿæ˜¯ $\xi_{k}^{\mu}$.</p>
</li>
<li>
<p><strong>hetero-association task</strong>(å¼‚å…³è”ä»»åŠ¡): è¾“å…¥ pattern $\xi_{k}^{\mu}$, è¾“å‡º pattern ä¸º $\zeta_{i}^{\mu}$. é€šå¸¸è¾“å…¥ä¸è¾“å‡ºçš„ units æ•°ä¸åŒ.</p>
</li>
</ul>
<blockquote>
<p>classification problems: inputs ä¼šè¢«åˆ†åˆ°ä¸åŒ categories.</p>
</blockquote>
<p>find the weights $w_{ik}$ in a finite number of steps.</p>
<h2 id="52-threshould-unitsé˜ˆå€¼å•å…ƒ">5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)<a hidden class="anchor" aria-hidden="true" href="#52-threshould-unitsé˜ˆå€¼å•å…ƒ">#</a></h2>
<p>è®¾ $g(h) = \text{sgn}(h)$, target $\zeta_{i}^{\mu} = \pm 1$.</p>
<p>ç”±äº output unit å½¼æ­¤ç‹¬ç«‹, ä¸å¤±ä¸€èˆ¬æ€§åœ°, çœç•¥ output æ ‡è®° $i$: $\vec{w} = (w_{1},w_{2},\cdots,w_{N})$.</p>
<p>input pattern $\vec{\xi}^{\mu}\in\mathbb{R}^{N}$.</p>
<p>é‚£ä¹ˆæ±‚å’Œå½¢å¼å¯å†™ä½œçŸ¢é‡å†…ç§¯å½¢å¼:</p>
<p>$$
\sum_{k}w_{k}\xi_{k}^{\mu} = \vec{w}\cdot\vec{\xi}_{\mu},\quad \text{sgn}(\vec{w}\cdot\vec{\xi}_{\mu}) = \zeta^{\mu}
$$</p>
<p>é€šè¿‡é€‰æ‹© $\vec{w}$, ä½¿å¾— $\vec{\xi}_{\mu}$ åœ¨å…¶æŠ•å½±(projection) å’Œ $\zeta^{\mu}$ åŒå·. å­˜åœ¨ä¸´ç•Œ $\vec{w}\cdot\vec{\xi}_{\mu} = 0$, å³ä¸¤è€…æ­£äº¤.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/F2NigAmo1lZJDdK.png" alt=""  />

(a) é€šè¿‡åˆé€‚çš„ $\vec{w}$, ä½¿å¾—å®å¿ƒåœ†($\zeta^{\mu}=+1$)å’Œç©ºå¿ƒåœ†($\zeta^{\mu}=-1$)è¢«è¶…å¹³é¢åˆ†å¼€.</p>
<p>(b) é€šè¿‡åˆé€‚çš„ $\vec{w}$, ä½¿å¾—æ‰€æœ‰åœ†éƒ½åœ¨è¶…å¹³é¢(hyperplane)æ³•å‘é‡ $\vec{w}$ æ‰€æŒ‡çš„ä¸€ä¾§.</p>
</blockquote>
<p>å®šä¹‰è¾…åŠ©çŸ¢é‡ $\vec{x}^{\mu}\equiv \zeta^{\mu}\vec{\xi}$, ä»è€Œæ¡ä»¶å†™ä½œ</p>
<p>$$
\vec{w}\cdot\vec{x}^{\mu} &gt; 0
$$</p>
<p>ä¹Ÿå¯å°†æ±‚å’Œé¡¹å…·ä½“å±•å¼€, è¡¥ä¸ŠåŸå…ˆå¿½ç•¥çš„æŒ‡æ ‡ $i$:</p>
<p>$$
\sum_{k}w_{ik}\zeta^{\mu}\xi_{k}^{\mu} = \zeta^{\mu}\left(\sum_{k}w_{ik}\xi_{k}^{\mu}\right) = \zeta^{\mu}h_{i}^{\mu} &gt; 0
$$</p>
<h3 id="linear-separabilityçº¿æ€§å¯åˆ†æ€§">Linear Separability(çº¿æ€§å¯åˆ†æ€§)<a hidden class="anchor" aria-hidden="true" href="#linear-separabilityçº¿æ€§å¯åˆ†æ€§">#</a></h3>
<p>è¶…å¹³é¢æ˜¯å¦å­˜åœ¨, å†³å®šåˆ†ç±»é—®é¢˜æ˜¯å¦å¯é€šè¿‡ perceptron è§£, æˆ–çº¿æ€§å¯åˆ†(linearly separable).</p>
<p>è¾“å‡º</p>
<p>$$
O_{i} = \text{sgn}\left(\sum_{k&gt;0}w_{ik}\xi_{k}-w_{i0}\right)
\Leftarrow O = \text{sgn}\left(\vec{w}\cdot\vec{\xi}-w_{0}\right)
$$</p>
<p>é‚£ä¹ˆ $N-1$ ç»´è¶…å¹³é¢æ˜¯ç”±</p>
<p>$$
\vec{w}\cdot\vec{\xi} = w_{0} \Leftrightarrow \hat{n}\cdot\vec{\xi} = \frac{w_{0}}{||\vec{w}||}
$$</p>
<p>å†³å®šçš„. å…¶ä¸­å®šä¹‰æ³•å‘å•ä½å‘é‡ $\hat{n} = \frac{\vec{w}}{||\vec{w}||}$, å¯è§é˜ˆå€¼ $w_{0}$ çš„ä½œç”¨æ˜¯ä½¿å¾—è¶…å¹³é¢æ²¿ç€ $\vec{w}$ æ–¹å‘ä»åŸç‚¹åç§» $\frac{w_{0}}{||\vec{w}||}$.</p>
<blockquote>
<p><strong>AND function/Truth table</strong></p>
<p>$\xi$: on = 1; off = 0.</p>
<p>$\zeta$: true = 1; false = -1.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/QHg8sKpJcNDvEZV.png" alt=""  />

&ldquo;ä¸”&rdquo; é—®é¢˜æ˜¯çº¿æ€§å¯åˆ†çš„. (b) ç»™å‡ºäº†ä¸€ä¸ªå¯èƒ½çš„ç½‘ç»œç¤ºä¾‹.</p>
</blockquote>
<p>å®šä¹‰é˜ˆå€¼æ‰€ç”¨çš„ç­‰æ•ˆèŠ‚ç‚¹ $\xi_{0} = -1$, åˆ™ &ldquo;ä¸”&rdquo; é—®é¢˜åŒ–ä¸º 3D å›¾ç¤º</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/FB6zERn9VxsYaLi.png" alt=""  />
</p>
<p>ç”±äºæ‰€æœ‰ input($\vec{\xi}_{\mu}$) éƒ½åç§»äº†ä¸€ä¸ªçŸ¢é‡ $(0,0,\cdots,w_{0})$, é‚£ä¹ˆè¿™ä¸ªç‚¹æˆä¸ºäº‹å®ä¸Šçš„æ–°åŸç‚¹. äºæ˜¯å›å½’åˆ°æ— é˜ˆå€¼æƒ…å†µ, è¶…å¹³é¢ç»è¿‡æ–°åŸç‚¹.</p>
</blockquote>
<p>éçº¿æ€§å¯åˆ†é—®é¢˜: XOR function(å¼‚æˆ–é—®é¢˜, åŒä¸ºå‡, å¼‚ä¸ºçœŸ)</p>
<blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/PK9QaBvsgAXFdky.png" alt=""  />

(a) XOR (b) ä¸‰ç‚¹å…±çº¿çš„æ¦‚ç‡ä¸º 0.</p>
</blockquote>
<p>å¯¹ general position çš„è§£è¯»:</p>
<ul>
<li>é™¤å¼€è¿™ç±»ç‰¹æ®Šæƒ…å†µ, ç‚¹é›†å¤„äº general position.</li>
<li>$N$ ç»´ç©ºé—´ä¸­, å–ä»»æ„ $d&lt;N$ ç»´è¶…å¹³é¢, å…¶æ‰€å«ç‚¹æ•°ä¸è¶…è¿‡ $d+1$. åˆ™ç‚¹é›†å¤„äº general position.</li>
<li>æ— é˜ˆå€¼é—®é¢˜æ—¶, ç­‰ä»·ä¸ºä»»æ„ $d\leq N$ ä¸ªç‚¹å½¼æ­¤çº¿æ€§ç‹¬ç«‹(ä¸å…±é¢).</li>
</ul>
<h3 id="a-simple-learning-algorithm">A Simple Learning Algorithm<a hidden class="anchor" aria-hidden="true" href="#a-simple-learning-algorithm">#</a></h3>
<p>$$
\begin{aligned}
w_{ik}^{\prime} = w_{ik} + \Delta w_{ik},\quad \Delta w_{ik} = \begin{cases}
2\eta \zeta_{i}^{\mu}\xi_{k}^{\mu} &amp; \text{if }\zeta_{i}^{\mu}\neq O_{i}^{\mu};\\
0 &amp; \text{otherwise}
\end{cases}
\end{aligned}
$$</p>
<p>å…¶ä¸­</p>
<p>$$
\Delta w_{ik} = \eta(1-\zeta_{i}^{\mu}O_{i}^{\mu})\zeta_{i}^{\mu}\xi_{k}^{\mu} = \eta(\zeta_{i}^{\mu} - O_{i}^{\mu})\xi_{k}^{\mu}; \quad \text{since }\zeta_{i}^{\mu}, O_{i}^{\mu} = \pm 1
$$</p>
<p>ä¸¤ç§è¡¨è¿°æ˜¯ç­‰ä»·çš„, åªæ˜¯åè€…å»æ‰äº†æ¡ä»¶åˆ¤æ–­.</p>
<blockquote>
<p>$\eta&gt;0$: learning rate(å­¦ä¹ ç‡).</p>
</blockquote>
<blockquote>
<p><strong>Will it work?</strong></p>
<ul>
<li>è‹¥å·²ç»æ­£ç¡®åˆ†ç±»($O_{i}^{\mu} = \zeta_{i}^{\mu}$), åˆ™æƒé‡æ— éœ€æ›´æ–°. æ­¤æ—¶ $\zeta_{i}^{\mu}O_{i}^{\mu} = +1$;</li>
<li>è‹¥è¯¯åˆ†ç±»($O_{i}^{\mu} = -\zeta_{i}^{\mu}$), æ—¢ç„¶ç›®æ ‡ä¹Ÿå¯å†™ä½œå½¢å¼ $\vec{w}\cdot\vec{x}^{\mu}&gt;0$, ä¸éš¾æ³¨æ„åˆ°å­¦ä¹ ç®—æ³•ä¹Ÿå¯ä»¥å†™ä½œ $\Delta w_{ik} = 2\eta x_{ik}^{\mu}$, è¿™ä½¿å¾—
$$
w^{\prime}_{i}\cdot\vec{x}^{\mu} = \sum_{k}(w_{ik} + \Delta w_{ik})x_{ik}^{\mu} = \sum_{k}(w_{ik} + 2\eta x_{ik}^{\mu})x_{ik}^{\mu} = \vec{w}_{i}\cdot \vec{x}_{i}^{\mu} + \Delta,\quad \Delta &gt; 0
$$</li>
</ul>
<p>$\Delta$ é¡¹ä½¿å¾— $w_{i}^{\prime}\cdot\vec{x}^{\mu}_{i}$ å¿…å®šé€’å¢, ä»è€Œè¾¾æˆ $w_{i}^{\prime}\cdot\vec{x}^{\mu}_{i}&gt;0$ çš„ç›®æ ‡.</p>
</blockquote>
<p>$$
\begin{aligned}
\zeta_{i}^{\mu}h_{i}^{\mu} &amp;\equiv \zeta_{i}^{\mu}\sum_{k}w_{ik}\xi_{k}^{\mu} \\
&amp;= \sum_{k}w_{ik} (\zeta_{i}^{\mu}\xi_{k}^{\mu}) = \vec{w}\cdot\vec{x}^{\mu}&gt; N\kappa
\end{aligned}
$$</p>
<p>ç¬¬äºŒè¡Œæ˜¯å¦ä¸€ç§ç›®æ ‡çš„ç­‰ä»·è¡¨è¾¾.</p>
<blockquote>
<p>å…¶ä¸­ $\kappa$ è¢«ç§°ä½œ margin size, è¿™æ˜¯ä¸ºäº†é˜²æ­¢æŸäº› $\vec{\xi}^{\mu}$ éå¸¸æ¥è¿‘è¶…å¹³é¢, å¯¼è‡´å™ªå£°æˆ–è¯¯å·®ä½¿å¾—è¯¯åˆ†ç±». æ·»åŠ  $N$ ä½¿å¾—ä»»æ„ input unit æ•°å‡å¯å·¥ä½œ.</p>
</blockquote>
<p>å°† $N\kappa$ è§†ä¸ºé˜ˆå€¼, é‚£ä¹ˆå­¦ä¹ ç®—æ³•æ”¹è¿›ä¸º</p>
<p>$$
\Delta w_{ik} = \eta\Theta(N\kappa-\zeta_{i}^{\mu}h_{i}^{\mu})\zeta_{i}^{\mu}\xi_{k}^{\mu},\quad\Theta(x) = \begin{cases}
1 &amp; \text{if } x &gt; 0;\\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<blockquote>
<p>è‹¥å­˜åœ¨è¾“å‡ºèŠ‚ç‚¹ $i$ æœ‰ $N\kappa &gt; \zeta_{i}^{\mu}h_{i}^{\mu}$, è¯´æ˜æœªè¾¾æˆç›®æ ‡, éœ€è¦é€šè¿‡ $\vec{x}^{\mu}_{i}$ ç»§ç»­å¢å¤§ $\Delta w_{ik}$, ä»è€Œäº§ç”Ÿæ¼”åŒ– $w\rightarrow w^{\prime}\rightarrow w^{\prime\prime}\rightarrow \cdots$</p>
</blockquote>
<blockquote>
<p>å½“ $\kappa=0$, é€€åŒ–ä¸ºåŸç®—æ³•å½¢å¼.</p>
</blockquote>
<p>å†™ä½œçŸ¢é‡å½¢å¼:</p>
<p>$$
\Delta \vec{w} = \eta\Theta(N\kappa-\vec{w}\cdot\vec{x}^{\mu})\vec{x}^{\mu}
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/05/6Yr3INjwWDpamCT.png" alt=""  />
</p>
<p>$\kappa = 0, \eta = 1$. æ¯æ¬¡éƒ½ä¼šæ‰¾åˆ°ä¸è¶…å¹³é¢å¼‚ä¾§çš„ç‚¹, é‚£ä¹ˆä¼˜åŒ– $\vec{w}$ æ—¶ä»¤å…¶åŠ ä¸Šå¯¹åº”ç‚¹çŸ¢, ç›´è‡³æ‰€æœ‰ç‚¹å‡åœ¨è¶…å¹³é¢ $\vec{w}$ æ‰€æŒ‡ä¸€ä¾§ä¸ºæ­¢.</p>
</blockquote>
<p>$\vec{x}^{\mu}$ åˆ°è¶…å¹³é¢çš„è·ç¦»å†³å®šäº†åˆ†ç±»é—®é¢˜çš„éš¾æ˜“ç¨‹åº¦. å®šä¹‰</p>
<p>$$
D(\vec{w}) = \frac{1}{||\vec{w}||}\underset{\mu}{\text{min }}\vec{w}\cdot\vec{x}^{\mu}
$$</p>
<p>æ˜¯å„ç‚¹åˆ°è¶…å¹³é¢çš„æœ€å°è·ç¦».</p>
<p>Optimal perceptron è‡´åŠ›äºå¯»æ‰¾ä½¿å¾— $D$ æœ€å¤§åŒ–çš„ $\vec{w}$:</p>
<p>$$
D_{\text{max}} \equiv \underset{\vec{w}}{\text{max }}D(\vec{w})
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/05/o8S3TMF69PEWkgQ.png" alt=""  />
</p>
<p>ä¸€èˆ¬æ€§æƒé‡ $\vec{w}$ å’Œ optimal $\vec{w}^{\prime}$.</p>
</blockquote>
<p>$D_{\text{max}}$ è¶Šå¤§, é—®é¢˜è¶Šç®€å•. $D_{\text{max}}&lt;0$, é—®é¢˜ä¸å¯è§£.</p>
<h2 id="53-proof-of-convergence-of-the-perceptron-learning-rule">5.3 Proof of Convergence of the Perceptron Learning Rule<a hidden class="anchor" aria-hidden="true" href="#53-proof-of-convergence-of-the-perceptron-learning-rule">#</a></h2>
<p>Perceptron learning rule reaches a solution in a <em>finite</em> number of steps.</p>
<p>è®¾ $\vec{w}^{*}$ ä¸ºä¸€å·²çŸ¥è§£($D(\vec{w}^{*})&gt;0$).</p>
<p>è®¾åˆå§‹æƒé‡ $\vec{w}_{0}=0$. ä»¤ $M^{\mu}$ ä¸ºæ¨¡å¼ $\mu$ æ›´æ–°æ¬¡æ•°. æ›´æ–°åæƒé‡ä¸º</p>
<p>$$
\vec{w} = \vec{w}_{0} + \sum\Delta\vec{w} = \eta\sum_{\mu}M^{\mu}\vec{x}^{\mu},\quad M = \sum_{\mu}M^{\mu}
$$</p>
<p>è®¡ç®—æ›´æ–°åæƒé‡ $\vec{w}$ å’Œå·²çŸ¥æƒé‡è§£ $\vec{w}^{*}$ å†…ç§¯:</p>
<p>$$
\begin{aligned}
\vec{w}\cdot\vec{w}^{*} &amp;= \eta\sum_{\mu}M^{\mu}\vec{x}^{\mu}\cdot\vec{w}^{*}\geq \eta M\underset{\mu}{\text{min }}\vec{x}^{\mu}\cdot\vec{w}^{*} = \eta M D(\vec{w}^{*})||\vec{w}^{*}||\sim M\\
&amp;\Rightarrow \vec{w^{*}}\cdot\frac{\vec{w}}{||\vec{w}||}\sim M
\end{aligned}
$$</p>
<p>è¿™è¡¨æ˜, å¦‚æœ $M$ ä¸æ˜¯æœ‰é™å€¼, $\vec{w}^{*}$ åœ¨ $\vec{w}$ æ–¹å‘ä¸Šçš„æŠ•å½±å°†ä¼šå‘æ•£, è¿™å’Œ $\vec{w^{*}}\cdot\frac{\vec{w}}{||\vec{w}||}\leq ||\vec{w}^{*}||$ æ˜¾ç„¶æ˜¯çŸ›ç›¾çš„.</p>
<p>è‹¥æ¨¡å¼ $\alpha$ åœ¨è¯¯åˆ†ç±»è€Œéœ€æ›´æ–°, æ›´æ–°åæ¨¡é•¿å¹³æ–¹å˜åŒ–ä¸º</p>
<p>$$
\begin{aligned}
\Delta(||\vec{w}||^{2}) &amp;= (\vec{w}+\eta\vec{x}^{\alpha})^{2} - (\vec{w})^{2} = \eta^{2}(\vec{x}^{\alpha})^{2} + 2\eta\vec{w}\cdot\vec{x}^{\alpha}\\
&amp;\leq \eta^{2} N + 2\eta N\kappa = N\eta(\eta + 2\kappa)
\end{aligned}
$$</p>
<blockquote>
<ul>
<li>å­¦ä¹ ç®—æ³•ç›®æ ‡çš„åˆ¤åˆ«å¼ä¹Ÿå¯å†™ä½œ $\vec{w}\cdot\vec{x}^{\mu}&gt;N\kappa$, æ—¢ç„¶ $\mu = \alpha$ æ—¶è¯¯åˆ†ç±», åˆ™ $\vec{w}\cdot\vec{x}^{\alpha}\leq N\kappa$;</li>
<li>$x_{k}^{\alpha} = \pm 1$, æ‰€ä»¥ $(\vec{x}^{\alpha})^{2} = \sum_{k}^{N}(x_{k}^{\alpha})^{2} = N$.</li>
</ul>
</blockquote>
<p>æ‰€ä»¥ $||\vec{w}||^{2}$ å­˜åœ¨ä¸Šç•Œ</p>
<p>$$
||\vec{w}||^{2} \leq M [\Delta (||\vec{w}||^{2})] \leq M N\eta(\eta + 2\kappa)\\
\Rightarrow ||\vec{w}|| \sim \sqrt{M}
$$</p>
<p>è®¡ç®— $\vec{w}$ ä¸ $\vec{w}^{*}$ å¤¹è§’ä½™å¼¦å¹³æ–¹:</p>
<p>$$
\phi = \frac{(\vec{w}\cdot\vec{w}^{*})^{2}}{||\vec{w}||^{2}||\vec{w}^{*}||^{2}}\leq 1
$$</p>
<p>å‰æ–‡è®¨è®ºå¯å¾—</p>
<p>$$
\begin{aligned}
(\vec{w}\cdot\vec{w}^{*})^{2} &amp;\geq \eta^{2} M^{2}D(\vec{w}^{*})^{2}||\vec{w}^{*}||^{2}\\
\frac{1}{||\vec{w}||^{2}} &amp;\geq \frac{1}{MN\eta(\eta+2\kappa)}
\end{aligned}
$$</p>
<p>ç›¸ä¹˜å¯å¾—</p>
<p>$$
1 \geq \phi \geq M\frac{D(\vec{w}^{*})^{2}\eta}{N(\eta+2\kappa)}
$$</p>
<p>æ‰€ä»¥ $M$ å­˜åœ¨ä¸Šç•Œ</p>
<p>$$
M\leq N\frac{1 + 2\kappa/\eta}{D_{\text{max}}^{2}}
$$</p>
<blockquote>
<p>ä¸æ˜¾å«æ¨¡å¼æ•° $p$, ä½†é€šå¸¸ä¼šå› ä¸º $p\uparrow$ è€Œ  $D_{\text{max}}\downarrow$, ä»è€Œä½¿ $M\uparrow$.</p>
</blockquote>
<h2 id="54-linear-units">5.4 Linear Units<a hidden class="anchor" aria-hidden="true" href="#54-linear-units">#</a></h2>
<p>ç”± $g(h)=\text{sgn}(h)$ æ‹“å±•åˆ° è¿ç»­ä¸”å¯å¯¼å‡½æ•° $g(h)$. Linear units: $g(h)=h$.</p>
<p>ç›®æ ‡å†™ä½œ</p>
<p>$$
\zeta_{i}^{\mu} = O_{i}^{\mu} = \sum_{k}w_{ik}\xi_{k}^{\mu}
$$</p>
<blockquote>
<p>$O_{i}^{\mu}$ ä¸ºè¿ç»­å€¼, è€Œ $\zeta_{i}^{\mu}=\pm 1$ ä»ç„¶æ˜¯è¢«å…è®¸çš„.</p>
</blockquote>
<h3 id="explicit-solutionæ˜¾å¼è§£">Explicit Solution(æ˜¾å¼è§£)<a hidden class="anchor" aria-hidden="true" href="#explicit-solutionæ˜¾å¼è§£">#</a></h3>
<p>auto-association: $\zeta_{i}^{\mu} = \xi_{i}^{\mu}$. æ¨å¹¿è‡³ hetero-association:</p>
<p>$$
\begin{aligned}
w_{ik} &amp;= \frac{1}{N}\sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\xi_{k}^{\nu}\\
\mathbf{Q}_{\mu\nu} &amp;= \frac{1}{N}\sum_{k}\xi_{k}^{\mu}\xi_{k}^{\nu}
\end{aligned}
$$</p>
<blockquote>
<p>Proof:</p>
<p>$$
\begin{aligned}
O_{i}^{\lambda} \equiv \sum_{k}w_{ik}\xi_{k}^{\lambda} &amp;= \frac{1}{N}\sum_{k}\sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\xi_{k}^{\nu}\xi_{k}^{\lambda}\\
&amp;= \sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\mathbf{Q}_{\nu\lambda}\\
&amp;= \sum_{\mu}\zeta_{i}^{\mu}\delta_{\mu\lambda} = \zeta_{i}^{\lambda}
\end{aligned}
$$</p>
</blockquote>
<p>$\mathbf{Q}$ çš„é€†å­˜åœ¨æ¡ä»¶ä¸ºæ»¡ç§©/${\xi_{k}^{\mu}}$ çº¿æ€§æ— å…³(linearly independent). ç”±äº input units æ•°ä¸º $N$, å› æ­¤èƒ½å­˜å‚¨ $p\leq N$ ä¸ªçº¿æ€§æ— å…³çš„æ¨¡å¼.</p>
<p>å³ä½¿ $p&lt;N$, ä¹Ÿä¸èƒ½ä¿è¯å…¶çº¿æ€§æ— å…³. è‹¥å­˜åœ¨å…³ç³» $\sum_{\mu=1}^{p}a_{k}\xi_{k}^{\mu} = 0$, åˆ™ ${\xi_{k}^{p}}$ åªèƒ½å¼ æˆæ¨¡å¼å­ç©ºé—´(pattern subspace). å¯ä»¥æ‰¾åˆ° $\xi_{k}^{*}$ ä¸è¯¥å­ç©ºé—´æ­£äº¤:</p>
<p>$$
\sum_{k}\xi_{k}^{\mu}\xi_{k}^{*} = 0,\quad \forall \mu = 1,2,\cdots,p
$$</p>
<p>è‹¥ $w_{ik}$ ä¸ºä¸€ä¸ªè§£, åˆ™ $w_{ik}^{\prime} = w_{ik} + a_{i}\xi_{k}^{*}$ å½¢æˆä¸€ä¸ªè§£ç³».</p>
<blockquote>
<p>çº¿æ€§ç‹¬ç«‹é—®é¢˜å…·æœ‰çº¿æ€§å¯åˆ†æ€§, åä¹‹åˆ™ä¸åŒ. å¤§å¤šæ•°é˜ˆå€¼ç½‘ç»œ $p&gt;N$, å¦‚ AND å’Œ XOR.</p>
</blockquote>
<h3 id="gradient-descent-learningæ¢¯åº¦ä¸‹é™å­¦ä¹ ">Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )<a hidden class="anchor" aria-hidden="true" href="#gradient-descent-learningæ¢¯åº¦ä¸‹é™å­¦ä¹ ">#</a></h3>
<p>æ˜¾å¼è§£å…è®¸æˆ‘ä»¬ç›´æ¥æ±‚ $w_{ik}$, ä½†å¤§å¤šæ•°æƒ…å†µä¸‹éœ€è¦é€šè¿‡ learning rule æ‰¾åˆ° $w_{ik}$.</p>
<p>è¯„ä¼°è¯¯å·®çš„ Cost function:</p>
<p>$$
E[\vec{w}] = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})^{2} = \frac{1}{2}\sum_{i\mu}\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)^{2}
$$</p>
<blockquote>
<p>å½“ $E[\vec{w}] = 0$ æ—¶æ‰¾åˆ°è§£. å’Œä¾èµ–äºèŠ‚ç‚¹æ¿€æ´»çš„èƒ½é‡å‡½æ•°ä¸åŒ, è¿™é‡Œçš„å‡½æ•°ä¾èµ–äºæƒé‡/è¿æ¥.</p>
</blockquote>
<p><strong>Gradient descent algorithm</strong>: ä»¤ $w_{ik}$ åç§» $\Delta w_{ik}$, ä¸”å¹…åº¦ä¸æ¢¯åº¦æˆæ­£æ¯”:</p>
<p>$$
\begin{aligned}
\Delta w_{ik} &amp;= -\eta\frac{\partial E}{\partial w_{ik}} = \eta\sum_{\mu}(\zeta_{i}^{\mu}-O_{i}^{\mu})\xi_{k}^{\mu}
\end{aligned}
$$</p>
<blockquote>
<p>$$
\begin{aligned}
\frac{\partial E}{\partial w_{ik}} &amp;= \frac{1}{2}\sum_{\mu}2\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)\cdot\frac{\partial}{\partial w_{ik}}\left(
\zeta_{i}^{\mu} - \sum_{l}w_{il}\xi_{l}^{\mu}
\right)\\
&amp;= \sum_{\mu}\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)\cdot \left(
-\sum_{l}\xi_{l}^{\mu}\delta_{lk}
\right)\\
&amp;= -\sum_{\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})\xi_{k}^{\mu}
\end{aligned}
$$</p>
</blockquote>
<p>è‹¥å›ºå®šæ¨¡å¼ $\mu$, åˆ™æœ‰ <strong>delta rule/adaline rule/Widrow-Hoff rule/Least Mean Squares (LMS) rule</strong></p>
<p>$$
\Delta w_{ik} = \eta(\zeta_{i}^{\mu}-O_{i}^{\mu})\xi_{k}^{\mu} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu}
$$</p>
<p>Cost function æ˜¯ä¸€ä¸ªäºŒæ¬¡å‹(quadratic form), å› æ­¤åœ¨ pattern subspace å½¢æˆæŠ›ç‰©çº¿é¢, æœ€å°å€¼å³ $E=0$; åœ¨æ­£äº¤äº subspace çš„æ–¹å‘ä¸Š cost function ä¸ºå¸¸å€¼.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/06/zu6rkjYxOhyeF18.png" alt=""  />
</p>
<p>${\xi_{k}^{\mu}}$ çº¿æ€§ç›¸å…³æ—¶.</p>
</blockquote>
<p>åœ¨å¯¹ $\vec{\xi}^{\mu}$ å­¦ä¹ å, æƒé‡ $\vec{w}_{i} = (w_{i1},w_{i2},\cdots, w_{ik},\cdots,w_{iN})$ åªä¼šåœ¨ $\vec{\xi}^{\mu}$ çš„æ–¹å‘ä¸Šå˜åŒ–, è€Œæ­£äº¤æ–¹å‘ä¸Šä¸å˜.</p>
<h3 id="convergence-of-gradient-descent">Convergence of Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#convergence-of-gradient-descent">#</a></h3>
<p>è‹¥ pattern vectors çº¿æ€§æ— å…³, åˆ™ cost function å†™ä½œ</p>
<p>$$
E = \sum_{\lambda = 1}^{M}a_{\lambda}(w_{\lambda} - w_{\lambda}^{0})^{2}
$$</p>
<blockquote>
<p>$M$: æƒé‡æ€»æ•°, ä¸ºè¾“å…¥èŠ‚ç‚¹æ•° $N$ ä¸è¾“å‡ºèŠ‚ç‚¹æ•°çš„ä¹˜ç§¯;</p>
<p>$w_{\lambda}$: $w_{ik}$ çš„çº¿æ€§ç»„åˆ;</p>
<p>$a_{\lambda}$, $w_{\lambda}^{0}$: ä¾èµ–äºæ¨¡å¼çŸ¢é‡çš„å¸¸æ•°. $a_{\lambda}$ åŠæ­£å®š(positive semi-definite); å½“ $a_{\lambda} = 0$, $E$ ç›¸å½“äºå¯¹è¯¥ $\lambda$ ç‹¬ç«‹.</p>
</blockquote>
<p>$$
\Delta w_{\lambda} = -\eta\frac{\partial E}{\partial w_{\lambda}} = -2\eta a_{\lambda}(w_{\lambda} - w_{\lambda}^{0}) = -2\eta a_{\lambda}\delta w_{\lambda}
$$</p>
<p>é‚£ä¹ˆå®šä¹‰è¾…åŠ©å˜é‡ $\delta w_{\lambda} = w_{\lambda} - w_{\lambda}^{0}$, å®ƒè¡¨æ˜åˆ°æœ€ä¼˜è§£çš„è·ç¦». åˆ™åŸæ¢¯åº¦ä¸‹é™è§„åˆ™çš„ç­‰å¼ä¸¤è¾¹åŒå‡ $w_{\lambda}^{0}$ å¾—</p>
<p>$$
\delta w_{\lambda}^{\text{new}} = \delta w_{\lambda}^{\text{old}} + \Delta w_{\lambda} = (1-2\eta a_{\lambda})\delta w_{\lambda}^{\text{old}}
$$</p>
<p>è‹¥ $|1-2\eta a_{\lambda}|&lt;1$, åˆ™å¯è¶‹è¿‘æœ€ä¼˜ç‚¹.</p>
<ul>
<li>$\eta&lt;1/a_{\lambda}^{\text{max}}$</li>
<li>$a_{\lambda}^{\text{min}}$ å†³å®šæ”¶æ•›é€Ÿåº¦.</li>
</ul>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/06/mWqxl17JvHjNYnb.png" alt=""  />
</p>
<p>$E = x^{2} + 20 y^{2}$, $\eta = 0.02, 0.0476, 0.049, 0.0505$</p>
</blockquote>
<p>åœ¨ patterns å­˜åœ¨çº¿æ€§ç›¸å…³ç»„æ—¶, åˆ™ cost function æ”¹å†™ä¸º</p>
<p>$$
E = E_{0} + \sum_{\lambda=1}^{M}a_{\lambda}(w_{\lambda}-w_{\lambda}^{0})^{2},\quad E_{0}&gt; 0
$$</p>
<h2 id="55-nonlinear-units">5.5 Nonlinear Units<a hidden class="anchor" aria-hidden="true" href="#55-nonlinear-units">#</a></h2>
<p>ç”±çº¿æ€§ $g(h) = h$ æ¨å¹¿è‡³ä»»æ„å¯å¯¼ $g(h)$. Cost function:</p>
<p>$$
E[\vec{w}] = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})^{2} = \frac{1}{2}\sum_{i\mu}\left[
\zeta_{i}^{\mu} - g\left(
\sum_{k}w_{ik}\xi_{k}^{\mu}
\right)
\right]^{2}
$$</p>
<p>æ¢¯åº¦</p>
<p>$$
\frac{\partial E}{\partial w_{ik}} = -\sum_{\mu}[\zeta_{i}^{\mu}-g(h_{i}^{\mu})]g^{\prime}(h_{i}^{\mu})\xi_{k}^{\mu}
$$</p>
<p>æƒé‡ä¿®æ­£</p>
<p>$$
\Delta w_{ik} = -\eta\frac{\partial E}{\partial w_{ik}} = \eta [\zeta_{i}^{\mu}-O_{i}^{\mu}]g^{\prime}(h_{i}^{\mu})\xi_{k}^{\mu} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu}
$$</p>
<p>å¯¹äº $g(h)=\tanh{(h)}$ è¿™ç±» sigmoid function, åœ¨ $|h_{i}^{\mu}|$ è¾ƒå°æ—¶æ¢¯åº¦è¾ƒå¤§.</p>
<blockquote>
<p>å¸¸ç”¨æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦:
$$
\begin{aligned}
\tanh{(h)} &amp;= \frac{e^{h}-e^{-h}}{e^{h}+e^{-h}}\\
g(h)^{\prime} &amp;= [\tanh{(\beta h)}]^{\prime} = \beta(1-g^{2});\\
f_{\beta}(h) &amp;= \frac{1}{1+\exp{(-2\beta h)}}\\
g(h)^{\prime} &amp;= f_{\beta}^{\prime}(h) = 2\beta g(1-g)
\end{aligned}
$$</p>
</blockquote>
<p>è§£å­˜åœ¨: patterns çº¿æ€§æ— å…³.</p>
<p>æ¢¯åº¦ä¸‹é™å¯èƒ½æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜è§£(local minima) è€Œéå…¨å±€æœ€ä¼˜è§£(global minima).</p>
<blockquote>
<p>e.g. $g(h) = \tanh{(h)}$ æ— æ³•å–åˆ°ç›®æ ‡å€¼ $\pm 1$.</p>
</blockquote>
<p>Nonlinear units åœ¨ patterns çº¿æ€§ç›¸å…³æ—¶æœ‰å¯èƒ½è¾…åŠ©æ‰¾åˆ° partial solutions.</p>
<blockquote>
<p>XOR problem.</p>
<blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<p>è‹¥å– $\tanh{(\beta h)}$ ä½œä¸ºæ¿€æ´»å‡½æ•°:</p>
<ul>
<li>æœ€å¹³å‡¡çš„æƒ…å†µ $\vec{w} = \vec{0}$, å³ $O = 0$ æ’æˆç«‹, æ­¤æ—¶ $E = \frac{1}{2}[2\cdot (1-0)^{2}+2\cdot (-1-0)^{2}] = 2$.</li>
<li>$|w_{0}|=|w_{1}|=|w_{2}|\rightarrow \infty$. è‹¥å–ç¬¦å·ä¸º $\{-,-,-\}$, åˆ™ è¾“å‡ºåˆ†åˆ«ä¸º
$\tanh{(0+0-\infty)} = -1$,
$\tanh{(0-\infty-\infty)} = -1$,
$\tanh{(-\infty+0-\infty)} = -1$,
$\tanh{(-\infty-\infty-\infty)} = -1$.
æ­¤æ—¶ $E = \frac{1}{2}[0^{2}+2^{2}+2^{2}+0^{2}] = 4$??</li>
</ul>
</blockquote>
<h3 id="other-cost-functions">Other Cost Functions<a hidden class="anchor" aria-hidden="true" href="#other-cost-functions">#</a></h3>
<ol>
<li>å¯¹ $\zeta_{i}^{\mu}, O_{i}^{\mu}$ å¯å¯¼; 2. åœ¨ $O_{i}^{\mu} = \zeta_{i}^{\mu}$ å–æœ€å°å€¼.</li>
</ol>
<p>æ»¡è¶³ä¸Šè¿°ä¸¤è¦æ±‚å‡å¯æˆä¸º cost function.</p>
<p>$$
E = \sum_{i\mu}\left[
\frac{1}{2}(1+\zeta_{i}^{\mu})\log{\frac{1+\zeta_{i}^{\mu}}{1+O_{i}^{\mu}}}
+ \frac{1}{2}(1-\zeta_{i}^{\mu})\log{\frac{1-\zeta_{i}^{\mu}}{1-O_{i}^{\mu}}}
\right]
$$</p>
<blockquote>
<p>åœ¨ä¿¡æ¯å­¦ä¸­, è‹¥æœ‰ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒ $P(x)$ å’Œ $Q(x)$, åˆ™ Relative entropy è¢«å®šä¹‰ä¸º
$$
D_{KL}(P||Q) = \sum_{x}P(x)\log{\frac{P(x)}{Q(x)}}
$$</p>
</blockquote>
<p>é‚£ä¹ˆå¯ä»¥å°† $\frac{1\pm O_{i}^{\mu}}{2}$ ç†è§£ä¸ºè¾“å‡º $\pm 1$ çš„æ¦‚ç‡, $\frac{1\pm \zeta_{i}^{\mu}}{2}$ ç†è§£ä¸ºå®é™…ç›®æ ‡ä¸º $\pm 1$ çš„æ¦‚ç‡.</p>
<p>å½“ $O_{i}^{\mu} = \zeta_{i}^{\mu}$ æ—¶, $E=0$, å¦åˆ™ $E&gt;0$.</p>
<ul>
<li>ç›¸æ¯”äºäºŒæ¬¡å‹, å½“ $|O_{i}^{\mu}|\rightarrow 1$ æ—¶, è¯¥ cost function ä¼šå‘æ•£, ä»è€Œæ¨åŠ¨ç½‘ç»œä¿®æ”¹æƒé‡. äºŒæ¬¡å‹åˆ™æ˜¯åœ¨ $|O_{i}^{\mu}|\rightarrow 1$ æ—¶æ¢¯åº¦è¶‹è¿‘äº 0, å¯¼è‡´å­¦ä¹ åœæ».</li>
<li>å½“è®­ç»ƒé›†æœ¬èº«ä¹Ÿæ˜¯æ¨¡ç³Šçš„(å¦‚åŒ»è¯è¡Œä¸š), å‡ºèº«äºæ¦‚ç‡è®ºçš„ relative entropy cost function æ›´åˆé€‚.</li>
</ul>
<p>å– $g(h)=\tanh{\beta h}$ ä½œä¸ºæ¿€æ´»å‡½æ•°, åˆ™æƒé‡æ›´æ–°ä»ç„¶ä¸º</p>
<p>$$
\Delta w_{ik} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu},\quad \delta_{i}^{\mu} = {\color{red}{\beta}}(\zeta_{i}^{\mu}-O_{i}^{\mu})
$$</p>
<blockquote>
<p>æ³¨æ„å…¶ä¸­å·²ç»æ²¡æœ‰ $g^{\prime}(h_{i}^{\mu})$.</p>
</blockquote>
<p>æ¢¯åº¦ä¸‹é™:</p>
<ul>
<li>ç”¨äºäºŒåˆ†å†³ç­–é—®é¢˜(binary decision problems). $O_{i}&gt;0$ å¯¹åº”è‚¯å®š, $O_{i}&lt;0$ å¯¹åº”å¦å®š;</li>
<li>é€‚ç”¨äºçº¿æ€§å¯åˆ†ä½† patterns çº¿æ€§ç›¸å…³çš„é—®é¢˜;</li>
<li>ä½¿ç”¨ well-formed cost function, å¦‚ relative entropy form, å…¶æ¢¯åº¦å¹…å€¼å¤§äºæŸå®šå€¼, ä»è€Œæ€»èƒ½æ‰¾åˆ°è§£(å¦‚æœè§£å­˜åœ¨).</li>
</ul>
<h2 id="56-stochastic-units">5.6 Stochastic Units<a hidden class="anchor" aria-hidden="true" href="#56-stochastic-units">#</a></h2>
<p>å€ŸåŠ© Boltzmann é…åˆ†å‡½æ•°, å®šä¹‰æ¦‚ç‡:</p>
<p>$$
P(S_{i}^{\mu}=+1) = \frac{e^{\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}},\quad
P(S_{i}^{\mu}=-1) = \frac{e^{-\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}}
$$</p>
<blockquote>
<p>$$
h_{i}^{\mu} = \sum_{k}w_{ik}\xi_{k}^{\mu}
$$</p>
</blockquote>
<p>æˆ–è€…å°†å…¶å†™ä½œåˆå¹¶å½¢å¼</p>
<p>$$
P(S_{i}^{\mu}=\pm 1) = \frac{1}{1+\exp{(-2\beta h_{i}^{\mu})}}
$$</p>
<p>äºæ˜¯å¾—åˆ°</p>
<p>$$
\begin{aligned}
\langle S_{i}^{\mu}\rangle &amp;= (+1)\cdot \frac{e^{\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}} + (-1)\cdot \frac{e^{-\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}} \\
&amp;= \tanh{(\beta h_{i}^{\mu})}\\
&amp;= \tanh\left(
\beta \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)
\end{aligned}
$$</p>
<p>æƒé‡æ›´æ–°</p>
<p>$$
\Delta w_{ik} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu},\quad \delta_{i}^{\mu} = \zeta_{i}^{\mu} - \langle S_{i}^{\mu}\rangle
$$</p>
<p>äºŒæ¬¡å‹ cost function:</p>
<p>$$
E = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - S_{i}^{\mu})^{2} = \sum_{i\mu}(1-\zeta_{i}^{\mu}S_{i}^{\mu})
$$</p>
<blockquote>
<p>$\zeta_{i}^{\mu},O_{i}^{\mu} = \pm 1$.</p>
</blockquote>
<p>å¹³å‡è¯¯å·®(avarage error):</p>
<p>$$
\langle E\rangle
= \sum_{i\mu}(1-\zeta_{i}^{\mu}\langle S_{i}^{\mu}\rangle)
= \sum_{i\mu}\left[
1-\zeta_{i}^{\mu}\tanh{\left(
\beta \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)}
\right]
$$</p>
<p>æ›´æ–°å¼•èµ·çš„ $\langle E\rangle$ å˜åŒ–:</p>
<p>$$
\begin{aligned}
\Delta\langle E\rangle &amp;= \sum_{ik}\Delta w_{ik}\frac{\partial \langle E\rangle}{\partial w_{ik}}\\
&amp;= \sum_{i\mu k}\Delta w_{ik}(-\zeta_{i}^{\mu})\frac{\partial }{\partial w_{ik}}\tanh{(\beta h_{i}^{\mu})}\\
&amp;= -\sum_{i\mu k}\eta[1-\zeta_{i}^{\mu}\tanh{(\beta h_{i}^{\mu})}]\beta \text{ sech}^{2}(\beta h_{i}^{\mu})&lt;0
\end{aligned}
$$</p>
<p>æ‰€ä»¥æ›´æ–°æ€»æ˜¯æ”¹å–„å¹³å‡è¡¨ç°.</p>
<blockquote>
<p>Hints:</p>
<p>$$
\frac{\mathrm{d}}{\mathrm{d}x}\tanh{(x)} = \text{sech}^{2}(x),\quad \text{sech}(x) = \frac{1}{\cosh(x)} = \frac{2}{e^{x}+e^{-x}}\\
\frac{\partial}{\partial w_{ik}}\sum_{l}w_{il}\xi_{l}^{\mu} = \sum_{l}\xi_{l}^{\mu}\delta_{lk} = \xi_{k}^{\mu}
$$</p>
</blockquote>
<h2 id="57-capacity-of-the-simple-perceptronç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡">5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)<a hidden class="anchor" aria-hidden="true" href="#57-capacity-of-the-simple-perceptronç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡">#</a></h2>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Muatyz.github.io/posts/read/neurons-with-graded-response-have-collective-computational-properties-like-those-of-two-state-neurons/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>Neurons with graded response have collective computational properties like those of two-state neurons</span>
  </a>
  <a class="next" href="https://Muatyz.github.io/posts/read/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>Neural networks and physical systems with emergent collective computational abilities</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>





<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-api-one-xi.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            region: 'ap-shanghai',  
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>Muartz</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script><script>

    let detail = document.getElementsByClassName('details')
   
    details = [].slice.call(detail);
   
    for (let index = 0; index < details.length; index++) {
   
    let element = details[index]
   
    const summary = element.getElementsByClassName('details-summary')[0];
   
    if (summary) {
   
    summary.addEventListener('click', () => {
   
    element.classList.toggle('open');
   
    }, false);
   
    }
   
    }
   
   </script>   

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>


<script>
    
    document.addEventListener('keydown', function(event) {
      
      if (event.key === 'j') {
        
        var nextPageLink = document.querySelector('.pagination-item.pagination-next > a');
        if (nextPageLink) {
          nextPageLink.click();
        }
      } else if (event.key === 'k') {
        
        var prevPageLink = document.querySelector('.pagination-item.pagination-previous > a');
        if (prevPageLink) {
          prevPageLink.click();
        }
      }
    });
  </script>
  

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/fz6m/Private-web@1.2/js/custom/click.min.js"></script>

</body>





<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
  </head>


<body>
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
</body>


</html>
