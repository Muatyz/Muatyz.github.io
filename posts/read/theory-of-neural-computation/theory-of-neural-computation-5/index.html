<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº) | æ— å¤„æƒ¹å°˜åŸƒ</title>
<meta name="keywords" content="">
<meta name="description" content="æ¯å‘¨é˜…è¯»ç¬”è®°">
<meta name="author" content="Muartz">
<link rel="canonical" href="https://Muatyz.github.io/posts/read/theory-of-neural-computation/theory-of-neural-computation-5/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://Muatyz.github.io/img/Head16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Muatyz.github.io/img/Head32.png">
<link rel="apple-touch-icon" href="https://Muatyz.github.io/img/Head32.png">
<link rel="mask-icon" href="https://Muatyz.github.io/img/Head32.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://Muatyz.github.io/posts/read/theory-of-neural-computation/theory-of-neural-computation-5/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>







<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script><meta property="og:title" content="Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)" />
<meta property="og:description" content="æ¯å‘¨é˜…è¯»ç¬”è®°" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Muatyz.github.io/posts/read/theory-of-neural-computation/theory-of-neural-computation-5/" />
<meta property="og:image" content="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-10-12T00:18:23+08:00" />
<meta property="article:modified_time" content="2025-10-12T00:18:23+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" />
<meta name="twitter:title" content="Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)"/>
<meta name="twitter:description" content="æ¯å‘¨é˜…è¯»ç¬”è®°"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "ğŸ“šæ–‡ç« ",
          "item": "https://Muatyz.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "ğŸ“• é˜…è¯»",
          "item": "https://Muatyz.github.io/posts/read/"
        },

        {
          "@type": "ListItem",
          "position":  3 ,
          "name": "ğŸ“• è®¡ç®—ç¥ç»ç§‘å­¦",
          "item": "https://Muatyz.github.io/posts/read/theory-of-neural-computation/"
        }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)",
      "item": "https://Muatyz.github.io/posts/read/theory-of-neural-computation/theory-of-neural-computation-5/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)",
  "name": "Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)",
  "description": "æ¯å‘¨é˜…è¯»ç¬”è®°",
  "keywords": [
    ""
  ],
  "articleBody": "supervised learning(learning with a teacher)ç›‘ç£å­¦ä¹ \n5.1 Feed-Forward Networks Perceptrons: layered feed-forward networks(åˆ†å±‚å‰é¦ˆç½‘ç»œ).\none-layer and two-layer(hidden units) perceptrons. $N$-layer network has $N$ layers of connections and $N â€” 1$ hidden layers.\nasymmetric connection matrices $w_{ij}$(triangular matrix, ä¸‰è§’çŸ©é˜µ): no energy function exists. åªæœ‰å¯¹ç§°é˜µå­˜åœ¨èƒ½é‡å‡½æ•°\n$$ H = -\\frac{1}{2}\\sum_{ij}w_{ij}S_{i}S_{j} $$\nSimple perceptron(no hidden units). Input: $\\xi_{k}$; Output: $O_{i}$.\n$$ O_{i} = g(h_{i}) = g\\left(\\sum_{k}w_{ik}\\xi_{k}\\right),\\quad g(h): \\text{activation function} $$\nOutput is an explicit(æ˜¾å¼) function of the input.\né˜ˆå€¼å¯ä»¥è¢«å¤„ç†ä¸ºä¸€ä¸ªç­‰æ•ˆçš„è¾“å…¥èŠ‚ç‚¹ $\\xi_{0} = - 1$, ä¸”æƒé‡ $w_{i0} = \\theta_{i}$.\n$$ O_{i} = g\\left(\\sum_{k=0}^{N}w_{ik}\\xi_{k}\\right) = g\\left(\\sum_{k=1}^{N}w_{ik}\\xi_{k}-\\theta_{i}\\right) $$\nç›®æ ‡: è‹¥ input $\\xi_{k}^{\\mu}$ æ‰€å¾—çš„ output ä¸º $O_{i}^{\\mu}$, è¦æ±‚ the general association task: $O_{i}^{\\mu} = \\zeta_{i}^{\\mu}$(target pattern).\nå…¶ä¸­ $k$ ä¸º input èŠ‚ç‚¹æ ‡è®°, $i$ ä¸º output èŠ‚ç‚¹æ ‡è®°, $\\mu=1,\\cdots,p$ ä¸º pattern/pairs æ ‡è®°.\nboolean($\\pm 1$) / continuous-valued.\nauto-association task(è‡ªå…³è”ä»»åŠ¡): è¾“å…¥ pattern $\\xi_{k}^{\\mu}$, è¾“å‡º pattern ä¹Ÿæ˜¯ $\\xi_{k}^{\\mu}$.\nhetero-association task(å¼‚å…³è”ä»»åŠ¡): è¾“å…¥ pattern $\\xi_{k}^{\\mu}$, è¾“å‡º pattern ä¸º $\\zeta_{i}^{\\mu}$. é€šå¸¸è¾“å…¥ä¸è¾“å‡ºçš„ units æ•°ä¸åŒ.\nclassification problems: inputs ä¼šè¢«åˆ†åˆ°ä¸åŒ categories.\nfind the weights $w_{ik}$ in a finite number of steps.\n5.2 Threshould Units(é˜ˆå€¼å•å…ƒ) è®¾ $g(h) = \\text{sgn}(h)$, target $\\zeta_{i}^{\\mu} = \\pm 1$.\nç”±äº output unit å½¼æ­¤ç‹¬ç«‹, ä¸å¤±ä¸€èˆ¬æ€§åœ°, çœç•¥ output æ ‡è®° $i$: $\\vec{w} = (w_{1},w_{2},\\cdots,w_{N})$.\ninput pattern $\\vec{\\xi}^{\\mu}\\in\\mathbb{R}^{N}$.\né‚£ä¹ˆæ±‚å’Œå½¢å¼å¯å†™ä½œçŸ¢é‡å†…ç§¯å½¢å¼:\n$$ \\sum_{k}w_{k}\\xi_{k}^{\\mu} = \\vec{w}\\cdot\\vec{\\xi}_{\\mu},\\quad \\text{sgn}(\\vec{w}\\cdot\\vec{\\xi}_{\\mu}) = \\zeta^{\\mu} $$\né€šè¿‡é€‰æ‹© $\\vec{w}$, ä½¿å¾— $\\vec{\\xi}_{\\mu}$ åœ¨å…¶æŠ•å½±(projection) å’Œ $\\zeta^{\\mu}$ åŒå·. å­˜åœ¨ä¸´ç•Œ $\\vec{w}\\cdot\\vec{\\xi}_{\\mu} = 0$, å³ä¸¤è€…æ­£äº¤.\n(a) é€šè¿‡åˆé€‚çš„ $\\vec{w}$, ä½¿å¾—å®å¿ƒåœ†($\\zeta^{\\mu}=+1$)å’Œç©ºå¿ƒåœ†($\\zeta^{\\mu}=-1$)è¢«è¶…å¹³é¢åˆ†å¼€.\n(b) é€šè¿‡åˆé€‚çš„ $\\vec{w}$, ä½¿å¾—æ‰€æœ‰åœ†éƒ½åœ¨è¶…å¹³é¢(hyperplane)æ³•å‘é‡ $\\vec{w}$ æ‰€æŒ‡çš„ä¸€ä¾§.\nå®šä¹‰è¾…åŠ©çŸ¢é‡ $\\vec{x}^{\\mu}\\equiv \\zeta^{\\mu}\\vec{\\xi}$, ä»è€Œæ¡ä»¶å†™ä½œ\n$$ \\vec{w}\\cdot\\vec{x}^{\\mu} \u003e 0 $$\nä¹Ÿå¯å°†æ±‚å’Œé¡¹å…·ä½“å±•å¼€, è¡¥ä¸ŠåŸå…ˆå¿½ç•¥çš„æŒ‡æ ‡ $i$:\n$$ \\sum_{k}w_{ik}\\zeta^{\\mu}\\xi_{k}^{\\mu} = \\zeta^{\\mu}\\left(\\sum_{k}w_{ik}\\xi_{k}^{\\mu}\\right) = \\zeta^{\\mu}h_{i}^{\\mu} \u003e 0 $$\nLinear Separability(çº¿æ€§å¯åˆ†æ€§) è¶…å¹³é¢æ˜¯å¦å­˜åœ¨, å†³å®šåˆ†ç±»é—®é¢˜æ˜¯å¦å¯é€šè¿‡ perceptron è§£, æˆ–çº¿æ€§å¯åˆ†(linearly separable).\nè¾“å‡º\n$$ O_{i} = \\text{sgn}\\left(\\sum_{k\u003e0}w_{ik}\\xi_{k}-w_{i0}\\right) \\Leftarrow O = \\text{sgn}\\left(\\vec{w}\\cdot\\vec{\\xi}-w_{0}\\right) $$\né‚£ä¹ˆ $N-1$ ç»´è¶…å¹³é¢æ˜¯ç”±\n$$ \\vec{w}\\cdot\\vec{\\xi} = w_{0} \\Leftrightarrow \\hat{n}\\cdot\\vec{\\xi} = \\frac{w_{0}}{||\\vec{w}||} $$\nå†³å®šçš„. å…¶ä¸­å®šä¹‰æ³•å‘å•ä½å‘é‡ $\\hat{n} = \\frac{\\vec{w}}{||\\vec{w}||}$, å¯è§é˜ˆå€¼ $w_{0}$ çš„ä½œç”¨æ˜¯ä½¿å¾—è¶…å¹³é¢æ²¿ç€ $\\vec{w}$ æ–¹å‘ä»åŸç‚¹åç§» $\\frac{w_{0}}{||\\vec{w}||}$.\nAND function/Truth table\n$\\xi$: on = 1; off = 0.\n$\\zeta$: true = 1; false = -1.\n$\\xi_{1}$ $\\xi_{2}$ $\\zeta$ 0 0 -1 0 1 -1 1 0 -1 1 1 +1 â€œä¸”â€ é—®é¢˜æ˜¯çº¿æ€§å¯åˆ†çš„. (b) ç»™å‡ºäº†ä¸€ä¸ªå¯èƒ½çš„ç½‘ç»œç¤ºä¾‹.\nå®šä¹‰é˜ˆå€¼æ‰€ç”¨çš„ç­‰æ•ˆèŠ‚ç‚¹ $\\xi_{0} = -1$, åˆ™ â€œä¸”â€ é—®é¢˜åŒ–ä¸º 3D å›¾ç¤º\nç”±äºæ‰€æœ‰ input($\\vec{\\xi}_{\\mu}$) éƒ½åç§»äº†ä¸€ä¸ªçŸ¢é‡ $(0,0,\\cdots,w_{0})$, é‚£ä¹ˆè¿™ä¸ªç‚¹æˆä¸ºäº‹å®ä¸Šçš„æ–°åŸç‚¹. äºæ˜¯å›å½’åˆ°æ— é˜ˆå€¼æƒ…å†µ, è¶…å¹³é¢ç»è¿‡æ–°åŸç‚¹.\néçº¿æ€§å¯åˆ†é—®é¢˜: XOR function(å¼‚æˆ–é—®é¢˜, åŒä¸ºå‡, å¼‚ä¸ºçœŸ)\n$\\xi_{1}$ $\\xi_{2}$ $\\zeta$ 0 0 -1 0 1 +1 1 0 +1 1 1 -1 (a) XOR (b) ä¸‰ç‚¹å…±çº¿çš„æ¦‚ç‡ä¸º 0.\nå¯¹ general position çš„è§£è¯»:\né™¤å¼€è¿™ç±»ç‰¹æ®Šæƒ…å†µ, ç‚¹é›†å¤„äº general position. $N$ ç»´ç©ºé—´ä¸­, å–ä»»æ„ $d",
  "wordCount" : "4702",
  "inLanguage": "zh",
  "image":"https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png","datePublished": "2025-10-12T00:18:23+08:00",
  "dateModified": "2025-10-12T00:18:23+08:00",
  "author":[{
    "@type": "Person",
    "name": "Muartz"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Muatyz.github.io/posts/read/theory-of-neural-computation/theory-of-neural-computation-5/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "æ— å¤„æƒ¹å°˜åŸƒ",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Muatyz.github.io/img/Head32.png"
    }
  }
}
</script><script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  CommonHTML: {
  scale: 100
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
  
  
  
  var all = MathJax.Hub.getAllJax(), i;
  for(i = 0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script>

<style>
  code.has-jax {
      font: "LXGW WenKai Screen", sans-serif, Arial;
      scale: 1;
      background: "LXGW WenKai Screen", sans-serif, Arial;
      border: "LXGW WenKai Screen", sans-serif, Arial;
      color: #515151;
  }
</style>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Muatyz.github.io/" accesskey="h" title="è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿— (Alt + H)">
            <img src="https://Muatyz.github.io/img/Head64.png" alt="logo" aria-label="logo"
                 height="35">è®¡ç®—ç‰©ç†å­¦ä¹ æ—¥å¿—</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Muatyz.github.io/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                <span>ğŸ” æœç´¢</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/" title="ğŸ  ä¸»é¡µ">
                <span>ğŸ  ä¸»é¡µ</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/posts" title="ğŸ“š æ–‡ç« ">
                <span>ğŸ“š æ–‡ç« </span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/tags" title="ğŸ§© æ ‡ç­¾">
                <span>ğŸ§© æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/archives/" title="â±ï¸ æ—¶é—´è½´">
                <span>â±ï¸ æ—¶é—´è½´</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                </a>
            </li>
            <li>
                <a href="https://Muatyz.github.io/links" title="ğŸ¤ å‹é“¾">
                <span>ğŸ¤ å‹é“¾</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://Muatyz.github.io/">ğŸ  ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/">ğŸ“šæ–‡ç« </a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/">ğŸ“• é˜…è¯»</a>&nbsp;Â»&nbsp;<a href="https://Muatyz.github.io/posts/read/theory-of-neural-computation/">ğŸ“• è®¡ç®—ç¥ç»ç§‘å­¦</a></div>
            <h1 class="post-title">
                Simple Percptrons(ç®€å•æ„ŸçŸ¥æœº)
            </h1>
            <div class="post-description">
                æ¯å‘¨é˜…è¯»ç¬”è®°
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-10-12
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>4702å­—
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>10åˆ†é’Ÿ
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Muartz
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://Muatyz.github.io/tags/physics/" style="color: var(--secondary)!important;">Physics</a>
                &nbsp;<a href="https://Muatyz.github.io/tags/numerical-calculation/" style="color: var(--secondary)!important;">Numerical Calculation</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "https://Muatyz.github.io/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId: "Admin", 
                                region: "ap-shanghai", 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://s2.loli.net/2025/10/12/xl7ojGEO5neCiRM.png" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#51-feed-forward-networks" aria-label="5.1 Feed-Forward Networks">5.1 Feed-Forward Networks</a></li>
                <li>
                    <a href="#52-threshould-units%e9%98%88%e5%80%bc%e5%8d%95%e5%85%83" aria-label="5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)">5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)</a><ul>
                        
                <li>
                    <a href="#linear-separability%e7%ba%bf%e6%80%a7%e5%8f%af%e5%88%86%e6%80%a7" aria-label="Linear Separability(çº¿æ€§å¯åˆ†æ€§)">Linear Separability(çº¿æ€§å¯åˆ†æ€§)</a></li>
                <li>
                    <a href="#a-simple-learning-algorithm" aria-label="A Simple Learning Algorithm">A Simple Learning Algorithm</a></li></ul>
                </li>
                <li>
                    <a href="#53-proof-of-convergence-of-the-perceptron-learning-rule" aria-label="5.3 Proof of Convergence of the Perceptron Learning Rule">5.3 Proof of Convergence of the Perceptron Learning Rule</a></li>
                <li>
                    <a href="#54-linear-units" aria-label="5.4 Linear Units">5.4 Linear Units</a><ul>
                        
                <li>
                    <a href="#explicit-solution%e6%98%be%e5%bc%8f%e8%a7%a3" aria-label="Explicit Solution(æ˜¾å¼è§£)">Explicit Solution(æ˜¾å¼è§£)</a></li>
                <li>
                    <a href="#gradient-descent-learning%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e5%ad%a6%e4%b9%a0" aria-label="Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )">Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )</a></li>
                <li>
                    <a href="#convergence-of-gradient-descent" aria-label="Convergence of Gradient Descent">Convergence of Gradient Descent</a></li></ul>
                </li>
                <li>
                    <a href="#55-nonlinear-units" aria-label="5.5 Nonlinear Units">5.5 Nonlinear Units</a><ul>
                        
                <li>
                    <a href="#other-cost-functions" aria-label="Other Cost Functions">Other Cost Functions</a></li></ul>
                </li>
                <li>
                    <a href="#56-stochastic-units" aria-label="5.6 Stochastic Units">5.6 Stochastic Units</a></li>
                <li>
                    <a href="#57-capacity-of-the-simple-perceptron%e7%ae%80%e5%8d%95%e6%84%9f%e7%9f%a5%e6%9c%ba%e7%9a%84%e5%ae%b9%e9%87%8f" aria-label="5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)">5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><p>supervised learning(learning with a teacher)ç›‘ç£å­¦ä¹ </p>
<h2 id="51-feed-forward-networks">5.1 Feed-Forward Networks<a hidden class="anchor" aria-hidden="true" href="#51-feed-forward-networks">#</a></h2>
<p>Perceptrons: layered feed-forward networks(åˆ†å±‚å‰é¦ˆç½‘ç»œ).</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/yn3CIk9Q7qutsfB.png" alt=""  />
one-layer and two-layer(hidden units) perceptrons. $N$-layer network has $N$ layers of connections and $N â€” 1$ hidden layers.</p>
</blockquote>
<p>asymmetric connection matrices $w_{ij}$(triangular matrix, ä¸‰è§’çŸ©é˜µ): no energy function exists. åªæœ‰å¯¹ç§°é˜µå­˜åœ¨èƒ½é‡å‡½æ•°</p>
<p>$$
H = -\frac{1}{2}\sum_{ij}w_{ij}S_{i}S_{j}
$$</p>
<p>Simple perceptron(no hidden units). Input: $\xi_{k}$; Output: $O_{i}$.</p>
<p>$$
O_{i} = g(h_{i}) = g\left(\sum_{k}w_{ik}\xi_{k}\right),\quad g(h): \text{activation function}
$$</p>
<blockquote>
<p>Output is an explicit(æ˜¾å¼) function of the input.</p>
</blockquote>
<p>é˜ˆå€¼å¯ä»¥è¢«å¤„ç†ä¸ºä¸€ä¸ªç­‰æ•ˆçš„è¾“å…¥èŠ‚ç‚¹ $\xi_{0} = - 1$, ä¸”æƒé‡ $w_{i0} = \theta_{i}$.</p>
<p>$$
O_{i} = g\left(\sum_{k=0}^{N}w_{ik}\xi_{k}\right) = g\left(\sum_{k=1}^{N}w_{ik}\xi_{k}-\theta_{i}\right)
$$</p>
<p>ç›®æ ‡: è‹¥ input $\xi_{k}^{\mu}$ æ‰€å¾—çš„ output ä¸º $O_{i}^{\mu}$, è¦æ±‚ the general association task: $O_{i}^{\mu} = \zeta_{i}^{\mu}$(target pattern).</p>
<blockquote>
<p>å…¶ä¸­ $k$ ä¸º input èŠ‚ç‚¹æ ‡è®°, $i$ ä¸º output èŠ‚ç‚¹æ ‡è®°, $\mu=1,\cdots,p$ ä¸º pattern/pairs æ ‡è®°.</p>
</blockquote>
<p>boolean($\pm 1$) / continuous-valued.</p>
<ul>
<li>
<p>auto-association task(è‡ªå…³è”ä»»åŠ¡): è¾“å…¥ pattern $\xi_{k}^{\mu}$, è¾“å‡º pattern ä¹Ÿæ˜¯ $\xi_{k}^{\mu}$.</p>
</li>
<li>
<p><strong>hetero-association task</strong>(å¼‚å…³è”ä»»åŠ¡): è¾“å…¥ pattern $\xi_{k}^{\mu}$, è¾“å‡º pattern ä¸º $\zeta_{i}^{\mu}$. é€šå¸¸è¾“å…¥ä¸è¾“å‡ºçš„ units æ•°ä¸åŒ.</p>
</li>
</ul>
<blockquote>
<p>classification problems: inputs ä¼šè¢«åˆ†åˆ°ä¸åŒ categories.</p>
</blockquote>
<p>find the weights $w_{ik}$ in a finite number of steps.</p>
<h2 id="52-threshould-unitsé˜ˆå€¼å•å…ƒ">5.2 Threshould Units(é˜ˆå€¼å•å…ƒ)<a hidden class="anchor" aria-hidden="true" href="#52-threshould-unitsé˜ˆå€¼å•å…ƒ">#</a></h2>
<p>è®¾ $g(h) = \text{sgn}(h)$, target $\zeta_{i}^{\mu} = \pm 1$.</p>
<p>ç”±äº output unit å½¼æ­¤ç‹¬ç«‹, ä¸å¤±ä¸€èˆ¬æ€§åœ°, çœç•¥ output æ ‡è®° $i$: $\vec{w} = (w_{1},w_{2},\cdots,w_{N})$.</p>
<p>input pattern $\vec{\xi}^{\mu}\in\mathbb{R}^{N}$.</p>
<p>é‚£ä¹ˆæ±‚å’Œå½¢å¼å¯å†™ä½œçŸ¢é‡å†…ç§¯å½¢å¼:</p>
<p>$$
\sum_{k}w_{k}\xi_{k}^{\mu} = \vec{w}\cdot\vec{\xi}_{\mu},\quad \text{sgn}(\vec{w}\cdot\vec{\xi}_{\mu}) = \zeta^{\mu}
$$</p>
<p>é€šè¿‡é€‰æ‹© $\vec{w}$, ä½¿å¾— $\vec{\xi}_{\mu}$ åœ¨å…¶æŠ•å½±(projection) å’Œ $\zeta^{\mu}$ åŒå·. å­˜åœ¨ä¸´ç•Œ $\vec{w}\cdot\vec{\xi}_{\mu} = 0$, å³ä¸¤è€…æ­£äº¤.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/F2NigAmo1lZJDdK.png" alt=""  />
(a) é€šè¿‡åˆé€‚çš„ $\vec{w}$, ä½¿å¾—å®å¿ƒåœ†($\zeta^{\mu}=+1$)å’Œç©ºå¿ƒåœ†($\zeta^{\mu}=-1$)è¢«è¶…å¹³é¢åˆ†å¼€.</p>
<p>(b) é€šè¿‡åˆé€‚çš„ $\vec{w}$, ä½¿å¾—æ‰€æœ‰åœ†éƒ½åœ¨è¶…å¹³é¢(hyperplane)æ³•å‘é‡ $\vec{w}$ æ‰€æŒ‡çš„ä¸€ä¾§.</p>
</blockquote>
<p>å®šä¹‰è¾…åŠ©çŸ¢é‡ $\vec{x}^{\mu}\equiv \zeta^{\mu}\vec{\xi}$, ä»è€Œæ¡ä»¶å†™ä½œ</p>
<p>$$
\vec{w}\cdot\vec{x}^{\mu} &gt; 0
$$</p>
<p>ä¹Ÿå¯å°†æ±‚å’Œé¡¹å…·ä½“å±•å¼€, è¡¥ä¸ŠåŸå…ˆå¿½ç•¥çš„æŒ‡æ ‡ $i$:</p>
<p>$$
\sum_{k}w_{ik}\zeta^{\mu}\xi_{k}^{\mu} = \zeta^{\mu}\left(\sum_{k}w_{ik}\xi_{k}^{\mu}\right) = \zeta^{\mu}h_{i}^{\mu} &gt; 0
$$</p>
<h3 id="linear-separabilityçº¿æ€§å¯åˆ†æ€§">Linear Separability(çº¿æ€§å¯åˆ†æ€§)<a hidden class="anchor" aria-hidden="true" href="#linear-separabilityçº¿æ€§å¯åˆ†æ€§">#</a></h3>
<p>è¶…å¹³é¢æ˜¯å¦å­˜åœ¨, å†³å®šåˆ†ç±»é—®é¢˜æ˜¯å¦å¯é€šè¿‡ perceptron è§£, æˆ–çº¿æ€§å¯åˆ†(linearly separable).</p>
<p>è¾“å‡º</p>
<p>$$
O_{i} = \text{sgn}\left(\sum_{k&gt;0}w_{ik}\xi_{k}-w_{i0}\right)
\Leftarrow O = \text{sgn}\left(\vec{w}\cdot\vec{\xi}-w_{0}\right)
$$</p>
<p>é‚£ä¹ˆ $N-1$ ç»´è¶…å¹³é¢æ˜¯ç”±</p>
<p>$$
\vec{w}\cdot\vec{\xi} = w_{0} \Leftrightarrow \hat{n}\cdot\vec{\xi} = \frac{w_{0}}{||\vec{w}||}
$$</p>
<p>å†³å®šçš„. å…¶ä¸­å®šä¹‰æ³•å‘å•ä½å‘é‡ $\hat{n} = \frac{\vec{w}}{||\vec{w}||}$, å¯è§é˜ˆå€¼ $w_{0}$ çš„ä½œç”¨æ˜¯ä½¿å¾—è¶…å¹³é¢æ²¿ç€ $\vec{w}$ æ–¹å‘ä»åŸç‚¹åç§» $\frac{w_{0}}{||\vec{w}||}$.</p>
<blockquote>
<p><strong>AND function/Truth table</strong></p>
<p>$\xi$: on = 1; off = 0.</p>
<p>$\zeta$: true = 1; false = -1.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/QHg8sKpJcNDvEZV.png" alt=""  />
&ldquo;ä¸”&rdquo; é—®é¢˜æ˜¯çº¿æ€§å¯åˆ†çš„. (b) ç»™å‡ºäº†ä¸€ä¸ªå¯èƒ½çš„ç½‘ç»œç¤ºä¾‹.</p>
</blockquote>
<p>å®šä¹‰é˜ˆå€¼æ‰€ç”¨çš„ç­‰æ•ˆèŠ‚ç‚¹ $\xi_{0} = -1$, åˆ™ &ldquo;ä¸”&rdquo; é—®é¢˜åŒ–ä¸º 3D å›¾ç¤º</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/FB6zERn9VxsYaLi.png" alt=""  /></p>
<p>ç”±äºæ‰€æœ‰ input($\vec{\xi}_{\mu}$) éƒ½åç§»äº†ä¸€ä¸ªçŸ¢é‡ $(0,0,\cdots,w_{0})$, é‚£ä¹ˆè¿™ä¸ªç‚¹æˆä¸ºäº‹å®ä¸Šçš„æ–°åŸç‚¹. äºæ˜¯å›å½’åˆ°æ— é˜ˆå€¼æƒ…å†µ, è¶…å¹³é¢ç»è¿‡æ–°åŸç‚¹.</p>
</blockquote>
<p>éçº¿æ€§å¯åˆ†é—®é¢˜: XOR function(å¼‚æˆ–é—®é¢˜, åŒä¸ºå‡, å¼‚ä¸ºçœŸ)</p>
<blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/04/PK9QaBvsgAXFdky.png" alt=""  />
(a) XOR (b) ä¸‰ç‚¹å…±çº¿çš„æ¦‚ç‡ä¸º 0.</p>
</blockquote>
<p>å¯¹ general position çš„è§£è¯»:</p>
<ul>
<li>é™¤å¼€è¿™ç±»ç‰¹æ®Šæƒ…å†µ, ç‚¹é›†å¤„äº general position.</li>
<li>$N$ ç»´ç©ºé—´ä¸­, å–ä»»æ„ $d&lt;N$ ç»´è¶…å¹³é¢, å…¶æ‰€å«ç‚¹æ•°ä¸è¶…è¿‡ $d+1$. åˆ™ç‚¹é›†å¤„äº general position.</li>
<li>æ— é˜ˆå€¼é—®é¢˜æ—¶, ç­‰ä»·ä¸ºä»»æ„ $d\leq N$ ä¸ªç‚¹å½¼æ­¤çº¿æ€§ç‹¬ç«‹(ä¸å…±é¢).</li>
</ul>
<h3 id="a-simple-learning-algorithm">A Simple Learning Algorithm<a hidden class="anchor" aria-hidden="true" href="#a-simple-learning-algorithm">#</a></h3>
<p>$$
\begin{aligned}
w_{ik}^{\prime} = w_{ik} + \Delta w_{ik},\quad \Delta w_{ik} = \begin{cases}
2\eta \zeta_{i}^{\mu}\xi_{k}^{\mu} &amp; \text{if }\zeta_{i}^{\mu}\neq O_{i}^{\mu};\\
0 &amp; \text{otherwise}
\end{cases}
\end{aligned}
$$</p>
<p>å…¶ä¸­</p>
<p>$$
\Delta w_{ik} = \eta(1-\zeta_{i}^{\mu}O_{i}^{\mu})\zeta_{i}^{\mu}\xi_{k}^{\mu} = \eta(\zeta_{i}^{\mu} - O_{i}^{\mu})\xi_{k}^{\mu}; \quad \text{since }\zeta_{i}^{\mu}, O_{i}^{\mu} = \pm 1
$$</p>
<p>ä¸¤ç§è¡¨è¿°æ˜¯ç­‰ä»·çš„, åªæ˜¯åè€…å»æ‰äº†æ¡ä»¶åˆ¤æ–­.</p>
<blockquote>
<p>$\eta&gt;0$: learning rate(å­¦ä¹ ç‡).</p>
</blockquote>
<blockquote>
<p><strong>Will it work?</strong></p>
<ul>
<li>è‹¥å·²ç»æ­£ç¡®åˆ†ç±»($O_{i}^{\mu} = \zeta_{i}^{\mu}$), åˆ™æƒé‡æ— éœ€æ›´æ–°. æ­¤æ—¶ $\zeta_{i}^{\mu}O_{i}^{\mu} = +1$;</li>
<li>è‹¥è¯¯åˆ†ç±»($O_{i}^{\mu} = -\zeta_{i}^{\mu}$), æ—¢ç„¶ç›®æ ‡ä¹Ÿå¯å†™ä½œå½¢å¼ $\vec{w}\cdot\vec{x}^{\mu}&gt;0$, ä¸éš¾æ³¨æ„åˆ°å­¦ä¹ ç®—æ³•ä¹Ÿå¯ä»¥å†™ä½œ $\Delta w_{ik} = 2\eta x_{ik}^{\mu}$, è¿™ä½¿å¾—
$$
w^{\prime}_{i}\cdot\vec{x}^{\mu} = \sum_{k}(w_{ik} + \Delta w_{ik})x_{ik}^{\mu} = \sum_{k}(w_{ik} + 2\eta x_{ik}^{\mu})x_{ik}^{\mu} = \vec{w}_{i}\cdot \vec{x}_{i}^{\mu} + \Delta,\quad \Delta &gt; 0
$$</li>
</ul>
<p>$\Delta$ é¡¹ä½¿å¾— $w_{i}^{\prime}\cdot\vec{x}^{\mu}_{i}$ å¿…å®šé€’å¢, ä»è€Œè¾¾æˆ $w_{i}^{\prime}\cdot\vec{x}^{\mu}_{i}&gt;0$ çš„ç›®æ ‡.</p>
</blockquote>
<p>$$
\begin{aligned}
\zeta_{i}^{\mu}h_{i}^{\mu} &amp;\equiv \zeta_{i}^{\mu}\sum_{k}w_{ik}\xi_{k}^{\mu} \\
&amp;= \sum_{k}w_{ik} (\zeta_{i}^{\mu}\xi_{k}^{\mu}) = \vec{w}\cdot\vec{x}^{\mu}&gt; N\kappa
\end{aligned}
$$</p>
<p>ç¬¬äºŒè¡Œæ˜¯å¦ä¸€ç§ç›®æ ‡çš„ç­‰ä»·è¡¨è¾¾.</p>
<blockquote>
<p>å…¶ä¸­ $\kappa$ è¢«ç§°ä½œ margin size, è¿™æ˜¯ä¸ºäº†é˜²æ­¢æŸäº› $\vec{\xi}^{\mu}$ éå¸¸æ¥è¿‘è¶…å¹³é¢, å¯¼è‡´å™ªå£°æˆ–è¯¯å·®ä½¿å¾—è¯¯åˆ†ç±». æ·»åŠ  $N$ ä½¿å¾—ä»»æ„ input unit æ•°å‡å¯å·¥ä½œ.</p>
</blockquote>
<p>å°† $N\kappa$ è§†ä¸ºé˜ˆå€¼, é‚£ä¹ˆå­¦ä¹ ç®—æ³•æ”¹è¿›ä¸º</p>
<p>$$
\Delta w_{ik} = \eta\Theta(N\kappa-\zeta_{i}^{\mu}h_{i}^{\mu})\zeta_{i}^{\mu}\xi_{k}^{\mu},\quad\Theta(x) = \begin{cases}
1 &amp; \text{if } x &gt; 0;\\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<blockquote>
<p>è‹¥å­˜åœ¨è¾“å‡ºèŠ‚ç‚¹ $i$ æœ‰ $N\kappa &gt; \zeta_{i}^{\mu}h_{i}^{\mu}$, è¯´æ˜æœªè¾¾æˆç›®æ ‡, éœ€è¦é€šè¿‡ $\vec{x}^{\mu}_{i}$ ç»§ç»­å¢å¤§ $\Delta w_{ik}$, ä»è€Œäº§ç”Ÿæ¼”åŒ– $w\rightarrow w^{\prime}\rightarrow w^{\prime\prime}\rightarrow \cdots$</p>
</blockquote>
<blockquote>
<p>å½“ $\kappa=0$, é€€åŒ–ä¸ºåŸç®—æ³•å½¢å¼.</p>
</blockquote>
<p>å†™ä½œçŸ¢é‡å½¢å¼:</p>
<p>$$
\Delta \vec{w} = \eta\Theta(N\kappa-\vec{w}\cdot\vec{x}^{\mu})\vec{x}^{\mu}
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/05/6Yr3INjwWDpamCT.png" alt=""  /></p>
<p>$\kappa = 0, \eta = 1$. æ¯æ¬¡éƒ½ä¼šæ‰¾åˆ°ä¸è¶…å¹³é¢å¼‚ä¾§çš„ç‚¹, é‚£ä¹ˆä¼˜åŒ– $\vec{w}$ æ—¶ä»¤å…¶åŠ ä¸Šå¯¹åº”ç‚¹çŸ¢, ç›´è‡³æ‰€æœ‰ç‚¹å‡åœ¨è¶…å¹³é¢ $\vec{w}$ æ‰€æŒ‡ä¸€ä¾§ä¸ºæ­¢.</p>
</blockquote>
<p>$\vec{x}^{\mu}$ åˆ°è¶…å¹³é¢çš„è·ç¦»å†³å®šäº†åˆ†ç±»é—®é¢˜çš„éš¾æ˜“ç¨‹åº¦. å®šä¹‰</p>
<p>$$
D(\vec{w}) = \frac{1}{||\vec{w}||}\underset{\mu}{\text{min }}\vec{w}\cdot\vec{x}^{\mu}
$$</p>
<p>æ˜¯å„ç‚¹åˆ°è¶…å¹³é¢çš„æœ€å°è·ç¦».</p>
<p>Optimal perceptron è‡´åŠ›äºå¯»æ‰¾ä½¿å¾— $D$ æœ€å¤§åŒ–çš„ $\vec{w}$:</p>
<p>$$
D_{\text{max}} \equiv \underset{\vec{w}}{\text{max }}D(\vec{w})
$$</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/05/o8S3TMF69PEWkgQ.png" alt=""  /></p>
<p>ä¸€èˆ¬æ€§æƒé‡ $\vec{w}$ å’Œ optimal $\vec{w}^{\prime}$.</p>
</blockquote>
<p>$D_{\text{max}}$ è¶Šå¤§, é—®é¢˜è¶Šç®€å•. $D_{\text{max}}&lt;0$, é—®é¢˜ä¸å¯è§£.</p>
<h2 id="53-proof-of-convergence-of-the-perceptron-learning-rule">5.3 Proof of Convergence of the Perceptron Learning Rule<a hidden class="anchor" aria-hidden="true" href="#53-proof-of-convergence-of-the-perceptron-learning-rule">#</a></h2>
<p>Perceptron learning rule reaches a solution in a <em>finite</em> number of steps.</p>
<p>è®¾ $\vec{w}^{*}$ ä¸ºä¸€å·²çŸ¥è§£($D(\vec{w}^{*})&gt;0$).</p>
<p>è®¾åˆå§‹æƒé‡ $\vec{w}_{0}=0$. ä»¤ $M^{\mu}$ ä¸ºæ¨¡å¼ $\mu$ æ›´æ–°æ¬¡æ•°. æ›´æ–°åæƒé‡ä¸º</p>
<p>$$
\vec{w} = \vec{w}_{0} + \sum\Delta\vec{w} = \eta\sum_{\mu}M^{\mu}\vec{x}^{\mu},\quad M = \sum_{\mu}M^{\mu}
$$</p>
<p>è®¡ç®—æ›´æ–°åæƒé‡ $\vec{w}$ å’Œå·²çŸ¥æƒé‡è§£ $\vec{w}^{*}$ å†…ç§¯:</p>
<p>$$
\begin{aligned}
\vec{w}\cdot\vec{w}^{*} &amp;= \eta\sum_{\mu}M^{\mu}\vec{x}^{\mu}\cdot\vec{w}^{*}\geq \eta M\underset{\mu}{\text{min }}\vec{x}^{\mu}\cdot\vec{w}^{*} = \eta M D(\vec{w}^{*})||\vec{w}^{*}||\sim M\\
&amp;\Rightarrow \vec{w^{*}}\cdot\frac{\vec{w}}{||\vec{w}||}\sim M
\end{aligned}
$$</p>
<p>è¿™è¡¨æ˜, å¦‚æœ $M$ ä¸æ˜¯æœ‰é™å€¼, $\vec{w}^{*}$ åœ¨ $\vec{w}$ æ–¹å‘ä¸Šçš„æŠ•å½±å°†ä¼šå‘æ•£, è¿™å’Œ $\vec{w^{*}}\cdot\frac{\vec{w}}{||\vec{w}||}\leq ||\vec{w}^{*}||$ æ˜¾ç„¶æ˜¯çŸ›ç›¾çš„.</p>
<p>è‹¥æ¨¡å¼ $\alpha$ åœ¨è¯¯åˆ†ç±»è€Œéœ€æ›´æ–°, æ›´æ–°åæ¨¡é•¿å¹³æ–¹å˜åŒ–ä¸º</p>
<p>$$
\begin{aligned}
\Delta(||\vec{w}||^{2}) &amp;= (\vec{w}+\eta\vec{x}^{\alpha})^{2} - (\vec{w})^{2} = \eta^{2}(\vec{x}^{\alpha})^{2} + 2\eta\vec{w}\cdot\vec{x}^{\alpha}\\
&amp;\leq \eta^{2} N + 2\eta N\kappa = N\eta(\eta + 2\kappa)
\end{aligned}
$$</p>
<blockquote>
<ul>
<li>å­¦ä¹ ç®—æ³•ç›®æ ‡çš„åˆ¤åˆ«å¼ä¹Ÿå¯å†™ä½œ $\vec{w}\cdot\vec{x}^{\mu}&gt;N\kappa$, æ—¢ç„¶ $\mu = \alpha$ æ—¶è¯¯åˆ†ç±», åˆ™ $\vec{w}\cdot\vec{x}^{\alpha}\leq N\kappa$;</li>
<li>$x_{k}^{\alpha} = \pm 1$, æ‰€ä»¥ $(\vec{x}^{\alpha})^{2} = \sum_{k}^{N}(x_{k}^{\alpha})^{2} = N$.</li>
</ul>
</blockquote>
<p>æ‰€ä»¥ $||\vec{w}||^{2}$ å­˜åœ¨ä¸Šç•Œ</p>
<p>$$
||\vec{w}||^{2} \leq M [\Delta (||\vec{w}||^{2})] \leq M N\eta(\eta + 2\kappa)\\
\Rightarrow ||\vec{w}|| \sim \sqrt{M}
$$</p>
<p>è®¡ç®— $\vec{w}$ ä¸ $\vec{w}^{*}$ å¤¹è§’ä½™å¼¦å¹³æ–¹:</p>
<p>$$
\phi = \frac{(\vec{w}\cdot\vec{w}^{*})^{2}}{||\vec{w}||^{2}||\vec{w}^{*}||^{2}}\leq 1
$$</p>
<p>å‰æ–‡è®¨è®ºå¯å¾—</p>
<p>$$
\begin{aligned}
(\vec{w}\cdot\vec{w}^{*})^{2} &amp;\geq \eta^{2} M^{2}D(\vec{w}^{*})^{2}||\vec{w}^{*}||^{2}\\
\frac{1}{||\vec{w}||^{2}} &amp;\geq \frac{1}{MN\eta(\eta+2\kappa)}
\end{aligned}
$$</p>
<p>ç›¸ä¹˜å¯å¾—</p>
<p>$$
1 \geq \phi \geq M\frac{D(\vec{w}^{*})^{2}\eta}{N(\eta+2\kappa)}
$$</p>
<p>æ‰€ä»¥ $M$ å­˜åœ¨ä¸Šç•Œ</p>
<p>$$
M\leq N\frac{1 + 2\kappa/\eta}{D_{\text{max}}^{2}}
$$</p>
<blockquote>
<p>ä¸æ˜¾å«æ¨¡å¼æ•° $p$, ä½†é€šå¸¸ä¼šå› ä¸º $p\uparrow$ è€Œ  $D_{\text{max}}\downarrow$, ä»è€Œä½¿ $M\uparrow$.</p>
</blockquote>
<h2 id="54-linear-units">5.4 Linear Units<a hidden class="anchor" aria-hidden="true" href="#54-linear-units">#</a></h2>
<p>ç”± $g(h)=\text{sgn}(h)$ æ‹“å±•åˆ° è¿ç»­ä¸”å¯å¯¼å‡½æ•° $g(h)$. Linear units: $g(h)=h$.</p>
<p>ç›®æ ‡å†™ä½œ</p>
<p>$$
\zeta_{i}^{\mu} = O_{i}^{\mu} = \sum_{k}w_{ik}\xi_{k}^{\mu}
$$</p>
<blockquote>
<p>$O_{i}^{\mu}$ ä¸ºè¿ç»­å€¼, è€Œ $\zeta_{i}^{\mu}=\pm 1$ ä»ç„¶æ˜¯è¢«å…è®¸çš„.</p>
</blockquote>
<h3 id="explicit-solutionæ˜¾å¼è§£">Explicit Solution(æ˜¾å¼è§£)<a hidden class="anchor" aria-hidden="true" href="#explicit-solutionæ˜¾å¼è§£">#</a></h3>
<p>auto-association: $\zeta_{i}^{\mu} = \xi_{i}^{\mu}$. æ¨å¹¿è‡³ hetero-association:</p>
<p>$$
\begin{aligned}
w_{ik} &amp;= \frac{1}{N}\sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\xi_{k}^{\nu}\\
\mathbf{Q}_{\mu\nu} &amp;= \frac{1}{N}\sum_{k}\xi_{k}^{\mu}\xi_{k}^{\nu}
\end{aligned}
$$</p>
<blockquote>
<p>Proof:</p>
<p>$$
\begin{aligned}
O_{i}^{\lambda} \equiv \sum_{k}w_{ik}\xi_{k}^{\lambda} &amp;= \frac{1}{N}\sum_{k}\sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\xi_{k}^{\nu}\xi_{k}^{\lambda}\\
&amp;= \sum_{\mu\nu}\zeta_{i}^{\mu}(\mathbf{Q}^{-1})_{\mu\nu}\mathbf{Q}_{\nu\lambda}\\
&amp;= \sum_{\mu}\zeta_{i}^{\mu}\delta_{\mu\lambda} = \zeta_{i}^{\lambda}
\end{aligned}
$$</p>
</blockquote>
<p>$\mathbf{Q}$ çš„é€†å­˜åœ¨æ¡ä»¶ä¸ºæ»¡ç§©/${\xi_{k}^{\mu}}$ çº¿æ€§æ— å…³(linearly independent). ç”±äº input units æ•°ä¸º $N$, å› æ­¤èƒ½å­˜å‚¨ $p\leq N$ ä¸ªçº¿æ€§æ— å…³çš„æ¨¡å¼.</p>
<p>å³ä½¿ $p&lt;N$, ä¹Ÿä¸èƒ½ä¿è¯å…¶çº¿æ€§æ— å…³. è‹¥å­˜åœ¨å…³ç³» $\sum_{\mu=1}^{p}a_{k}\xi_{k}^{\mu} = 0$, åˆ™ ${\xi_{k}^{p}}$ åªèƒ½å¼ æˆæ¨¡å¼å­ç©ºé—´(pattern subspace). å¯ä»¥æ‰¾åˆ° $\xi_{k}^{*}$ ä¸è¯¥å­ç©ºé—´æ­£äº¤:</p>
<p>$$
\sum_{k}\xi_{k}^{\mu}\xi_{k}^{*} = 0,\quad \forall \mu = 1,2,\cdots,p
$$</p>
<p>è‹¥ $w_{ik}$ ä¸ºä¸€ä¸ªè§£, åˆ™ $w_{ik}^{\prime} = w_{ik} + a_{i}\xi_{k}^{*}$ å½¢æˆä¸€ä¸ªè§£ç³».</p>
<blockquote>
<p>çº¿æ€§ç‹¬ç«‹é—®é¢˜å…·æœ‰çº¿æ€§å¯åˆ†æ€§, åä¹‹åˆ™ä¸åŒ. å¤§å¤šæ•°é˜ˆå€¼ç½‘ç»œ $p&gt;N$, å¦‚ AND å’Œ XOR.</p>
</blockquote>
<h3 id="gradient-descent-learningæ¢¯åº¦ä¸‹é™å­¦ä¹ ">Gradient Descent Learning(æ¢¯åº¦ä¸‹é™å­¦ä¹ )<a hidden class="anchor" aria-hidden="true" href="#gradient-descent-learningæ¢¯åº¦ä¸‹é™å­¦ä¹ ">#</a></h3>
<p>æ˜¾å¼è§£å…è®¸æˆ‘ä»¬ç›´æ¥æ±‚ $w_{ik}$, ä½†å¤§å¤šæ•°æƒ…å†µä¸‹éœ€è¦é€šè¿‡ learning rule æ‰¾åˆ° $w_{ik}$.</p>
<p>è¯„ä¼°è¯¯å·®çš„ Cost function:</p>
<p>$$
E[\vec{w}] = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})^{2} = \frac{1}{2}\sum_{i\mu}\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)^{2}
$$</p>
<blockquote>
<p>å½“ $E[\vec{w}] = 0$ æ—¶æ‰¾åˆ°è§£. å’Œä¾èµ–äºèŠ‚ç‚¹æ¿€æ´»çš„èƒ½é‡å‡½æ•°ä¸åŒ, è¿™é‡Œçš„å‡½æ•°ä¾èµ–äºæƒé‡/è¿æ¥.</p>
</blockquote>
<p><strong>Gradient descent algorithm</strong>: ä»¤ $w_{ik}$ åç§» $\Delta w_{ik}$, ä¸”å¹…åº¦ä¸æ¢¯åº¦æˆæ­£æ¯”:</p>
<p>$$
\begin{aligned}
\Delta w_{ik} &amp;= -\eta\frac{\partial E}{\partial w_{ik}} = \eta\sum_{\mu}(\zeta_{i}^{\mu}-O_{i}^{\mu})\xi_{k}^{\mu}
\end{aligned}
$$</p>
<blockquote>
<p>$$
\begin{aligned}
\frac{\partial E}{\partial w_{ik}} &amp;= \frac{1}{2}\sum_{\mu}2\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)\cdot\frac{\partial}{\partial w_{ik}}\left(
\zeta_{i}^{\mu} - \sum_{l}w_{il}\xi_{l}^{\mu}
\right)\\
&amp;= \sum_{\mu}\left(
\zeta_{i}^{\mu} - \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)\cdot \left(
-\sum_{l}\xi_{l}^{\mu}\delta_{lk}
\right)\\
&amp;= -\sum_{\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})\xi_{k}^{\mu}
\end{aligned}
$$</p>
</blockquote>
<p>è‹¥å›ºå®šæ¨¡å¼ $\mu$, åˆ™æœ‰ <strong>delta rule/adaline rule/Widrow-Hoff rule/Least Mean Squares (LMS) rule</strong></p>
<p>$$
\Delta w_{ik} = \eta(\zeta_{i}^{\mu}-O_{i}^{\mu})\xi_{k}^{\mu} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu}
$$</p>
<p>Cost function æ˜¯ä¸€ä¸ªäºŒæ¬¡å‹(quadratic form), å› æ­¤åœ¨ pattern subspace å½¢æˆæŠ›ç‰©çº¿é¢, æœ€å°å€¼å³ $E=0$; åœ¨æ­£äº¤äº subspace çš„æ–¹å‘ä¸Š cost function ä¸ºå¸¸å€¼.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/06/zu6rkjYxOhyeF18.png" alt=""  /></p>
<p>${\xi_{k}^{\mu}}$ çº¿æ€§ç›¸å…³æ—¶.</p>
</blockquote>
<p>åœ¨å¯¹ $\vec{\xi}^{\mu}$ å­¦ä¹ å, æƒé‡ $\vec{w}_{i} = (w_{i1},w_{i2},\cdots, w_{ik},\cdots,w_{iN})$ åªä¼šåœ¨ $\vec{\xi}^{\mu}$ çš„æ–¹å‘ä¸Šå˜åŒ–, è€Œæ­£äº¤æ–¹å‘ä¸Šä¸å˜.</p>
<h3 id="convergence-of-gradient-descent">Convergence of Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#convergence-of-gradient-descent">#</a></h3>
<p>è‹¥ pattern vectors çº¿æ€§æ— å…³, åˆ™ cost function å†™ä½œ</p>
<p>$$
E = \sum_{\lambda = 1}^{M}a_{\lambda}(w_{\lambda} - w_{\lambda}^{0})^{2}
$$</p>
<blockquote>
<p>$M$: æƒé‡æ€»æ•°, ä¸ºè¾“å…¥èŠ‚ç‚¹æ•° $N$ ä¸è¾“å‡ºèŠ‚ç‚¹æ•°çš„ä¹˜ç§¯;</p>
<p>$w_{\lambda}$: $w_{ik}$ çš„çº¿æ€§ç»„åˆ;</p>
<p>$a_{\lambda}$, $w_{\lambda}^{0}$: ä¾èµ–äºæ¨¡å¼çŸ¢é‡çš„å¸¸æ•°. $a_{\lambda}$ åŠæ­£å®š(positive semi-definite); å½“ $a_{\lambda} = 0$, $E$ ç›¸å½“äºå¯¹è¯¥ $\lambda$ ç‹¬ç«‹.</p>
</blockquote>
<p>$$
\Delta w_{\lambda} = -\eta\frac{\partial E}{\partial w_{\lambda}} = -2\eta a_{\lambda}(w_{\lambda} - w_{\lambda}^{0}) = -2\eta a_{\lambda}\delta w_{\lambda}
$$</p>
<p>é‚£ä¹ˆå®šä¹‰è¾…åŠ©å˜é‡ $\delta w_{\lambda} = w_{\lambda} - w_{\lambda}^{0}$, å®ƒè¡¨æ˜åˆ°æœ€ä¼˜è§£çš„è·ç¦». åˆ™åŸæ¢¯åº¦ä¸‹é™è§„åˆ™çš„ç­‰å¼ä¸¤è¾¹åŒå‡ $w_{\lambda}^{0}$ å¾—</p>
<p>$$
\delta w_{\lambda}^{\text{new}} = \delta w_{\lambda}^{\text{old}} + \Delta w_{\lambda} = (1-2\eta a_{\lambda})\delta w_{\lambda}^{\text{old}}
$$</p>
<p>è‹¥ $|1-2\eta a_{\lambda}|&lt;1$, åˆ™å¯è¶‹è¿‘æœ€ä¼˜ç‚¹.</p>
<ul>
<li>$\eta&lt;1/a_{\lambda}^{\text{max}}$</li>
<li>$a_{\lambda}^{\text{min}}$ å†³å®šæ”¶æ•›é€Ÿåº¦.</li>
</ul>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/06/mWqxl17JvHjNYnb.png" alt=""  /></p>
<p>$E = x^{2} + 20 y^{2}$, $\eta = 0.02, 0.0476, 0.049, 0.0505$</p>
</blockquote>
<p>åœ¨ patterns å­˜åœ¨çº¿æ€§ç›¸å…³ç»„æ—¶, åˆ™ cost function æ”¹å†™ä¸º</p>
<p>$$
E = E_{0} + \sum_{\lambda=1}^{M}a_{\lambda}(w_{\lambda}-w_{\lambda}^{0})^{2},\quad E_{0}&gt; 0
$$</p>
<h2 id="55-nonlinear-units">5.5 Nonlinear Units<a hidden class="anchor" aria-hidden="true" href="#55-nonlinear-units">#</a></h2>
<p>ç”±çº¿æ€§ $g(h) = h$ æ¨å¹¿è‡³ä»»æ„å¯å¯¼ $g(h)$. Cost function:</p>
<p>$$
E[\vec{w}] = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - O_{i}^{\mu})^{2} = \frac{1}{2}\sum_{i\mu}\left[
\zeta_{i}^{\mu} - g\left(
\sum_{k}w_{ik}\xi_{k}^{\mu}
\right)
\right]^{2}
$$</p>
<p>æ¢¯åº¦</p>
<p>$$
\frac{\partial E}{\partial w_{ik}} = -\sum_{\mu}[\zeta_{i}^{\mu}-g(h_{i}^{\mu})]g^{\prime}(h_{i}^{\mu})\xi_{k}^{\mu}
$$</p>
<p>æƒé‡ä¿®æ­£</p>
<p>$$
\Delta w_{ik} = -\eta\frac{\partial E}{\partial w_{ik}} = \eta [\zeta_{i}^{\mu}-O_{i}^{\mu}]g^{\prime}(h_{i}^{\mu})\xi_{k}^{\mu} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu}
$$</p>
<p>å¯¹äº $g(h)=\tanh{(h)}$ è¿™ç±» sigmoid function, åœ¨ $|h_{i}^{\mu}|$ è¾ƒå°æ—¶æ¢¯åº¦è¾ƒå¤§.</p>
<blockquote>
<p>å¸¸ç”¨æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦:
$$
\begin{aligned}
\tanh{(h)} &amp;= \frac{e^{h}-e^{-h}}{e^{h}+e^{-h}}\\
g(h)^{\prime} &amp;= [\tanh{(\beta h)}]^{\prime} = \beta(1-g^{2});\\
f_{\beta}(h) &amp;= \frac{1}{1+\exp{(-2\beta h)}}\\
g(h)^{\prime} &amp;= f_{\beta}^{\prime}(h) = 2\beta g(1-g)
\end{aligned}
$$</p>
</blockquote>
<p>è§£å­˜åœ¨: patterns çº¿æ€§æ— å…³.</p>
<p>æ¢¯åº¦ä¸‹é™å¯èƒ½æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜è§£(local minima) è€Œéå…¨å±€æœ€ä¼˜è§£(global minima).</p>
<blockquote>
<p>e.g. $g(h) = \tanh{(h)}$ æ— æ³•å–åˆ°ç›®æ ‡å€¼ $\pm 1$.</p>
</blockquote>
<p>Nonlinear units åœ¨ patterns çº¿æ€§ç›¸å…³æ—¶æœ‰å¯èƒ½è¾…åŠ©æ‰¾åˆ° partial solutions.</p>
<blockquote>
<p>XOR problem.</p>
<blockquote>
<table>
  <thead>
      <tr>
          <th style="text-align: left">$\xi_{1}$</th>
          <th style="text-align: left">$\xi_{2}$</th>
          <th style="text-align: left">$\zeta$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">-1</td>
      </tr>
      <tr>
          <td style="text-align: left">0</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">0</td>
          <td style="text-align: left">+1</td>
      </tr>
      <tr>
          <td style="text-align: left">1</td>
          <td style="text-align: left">1</td>
          <td style="text-align: left">-1</td>
      </tr>
  </tbody>
</table>
</blockquote>
<p>è‹¥å– $\tanh{(\beta h)}$ ä½œä¸ºæ¿€æ´»å‡½æ•°:</p>
<ul>
<li>æœ€å¹³å‡¡çš„æƒ…å†µ $\vec{w} = \vec{0}$, å³ $O = 0$ æ’æˆç«‹, æ­¤æ—¶ $E = \frac{1}{2}[2\cdot (1-0)^{2}+2\cdot (-1-0)^{2}] = 2$.</li>
<li>$|w_{0}|=|w_{1}|=|w_{2}|\rightarrow \infty$. çº¦å®šå½¢å¼ä¸º $h_{i}^{\mu} = w_{1}\xi_{1}+w_{2}\xi_{2} - w_{0}$; è‹¥å–ç¬¦å·ä¸º $\{-,-,-\}$, åˆ™ è¾“å‡ºåˆ†åˆ«ä¸º
$\tanh{(0+0+\infty)} = +1$,
$\tanh{(0-\infty+\infty)} = 0$,
$\tanh{(-\infty+0+\infty)} = 0$,
$\tanh{(-\infty-\infty+\infty)} = -1$.
æ­¤æ—¶ $E = \frac{1}{2}[(1+1)^{2}+(1-0)^{2}+(1-0)^{2}+0^{2}] = 3$??</li>
</ul>
</blockquote>
<h3 id="other-cost-functions">Other Cost Functions<a hidden class="anchor" aria-hidden="true" href="#other-cost-functions">#</a></h3>
<ol>
<li>å¯¹ $\zeta_{i}^{\mu}, O_{i}^{\mu}$ å¯å¯¼; 2. åœ¨ $O_{i}^{\mu} = \zeta_{i}^{\mu}$ å–æœ€å°å€¼.</li>
</ol>
<p>æ»¡è¶³ä¸Šè¿°ä¸¤è¦æ±‚å‡å¯æˆä¸º cost function.</p>
<p>$$
E = \sum_{i\mu}\left[
\frac{1}{2}(1+\zeta_{i}^{\mu})\log{\frac{1+\zeta_{i}^{\mu}}{1+O_{i}^{\mu}}}
+ \frac{1}{2}(1-\zeta_{i}^{\mu})\log{\frac{1-\zeta_{i}^{\mu}}{1-O_{i}^{\mu}}}
\right]
$$</p>
<blockquote>
<p>åœ¨ä¿¡æ¯å­¦ä¸­, è‹¥æœ‰ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒ $P(x)$ å’Œ $Q(x)$, åˆ™ Relative entropy è¢«å®šä¹‰ä¸º
$$
D_{KL}(P||Q) = \sum_{x}P(x)\log{\frac{P(x)}{Q(x)}}
$$</p>
</blockquote>
<p>é‚£ä¹ˆå¯ä»¥å°† $\frac{1\pm O_{i}^{\mu}}{2}$ ç†è§£ä¸ºè¾“å‡º $\pm 1$ çš„æ¦‚ç‡, $\frac{1\pm \zeta_{i}^{\mu}}{2}$ ç†è§£ä¸ºå®é™…ç›®æ ‡ä¸º $\pm 1$ çš„æ¦‚ç‡.</p>
<p>å½“ $O_{i}^{\mu} = \zeta_{i}^{\mu}$ æ—¶, $E=0$, å¦åˆ™ $E&gt;0$.</p>
<ul>
<li>ç›¸æ¯”äºäºŒæ¬¡å‹, å½“ $|O_{i}^{\mu}|\rightarrow 1$ æ—¶, è¯¥ cost function ä¼šå‘æ•£, ä»è€Œæ¨åŠ¨ç½‘ç»œä¿®æ”¹æƒé‡. äºŒæ¬¡å‹åˆ™æ˜¯åœ¨ $|O_{i}^{\mu}|\rightarrow 1$ æ—¶æ¢¯åº¦è¶‹è¿‘äº 0, å¯¼è‡´å­¦ä¹ åœæ».</li>
<li>å½“è®­ç»ƒé›†æœ¬èº«ä¹Ÿæ˜¯æ¨¡ç³Šçš„(å¦‚åŒ»è¯è¡Œä¸š), å‡ºèº«äºæ¦‚ç‡è®ºçš„ relative entropy cost function æ›´åˆé€‚.</li>
</ul>
<p>å– $g(h)=\tanh{\beta h}$ ä½œä¸ºæ¿€æ´»å‡½æ•°, åˆ™æƒé‡æ›´æ–°ä»ç„¶ä¸º</p>
<p>$$
\Delta w_{ik} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu},\quad \delta_{i}^{\mu} = {\color{red}{\beta}}(\zeta_{i}^{\mu}-O_{i}^{\mu})
$$</p>
<blockquote>
<p>æ³¨æ„å…¶ä¸­å·²ç»æ²¡æœ‰ $g^{\prime}(h_{i}^{\mu})$.</p>
</blockquote>
<p>æ¢¯åº¦ä¸‹é™:</p>
<ul>
<li>ç”¨äºäºŒåˆ†å†³ç­–é—®é¢˜(binary decision problems). $O_{i}&gt;0$ å¯¹åº”è‚¯å®š, $O_{i}&lt;0$ å¯¹åº”å¦å®š;</li>
<li>é€‚ç”¨äºçº¿æ€§å¯åˆ†ä½† patterns çº¿æ€§ç›¸å…³çš„é—®é¢˜;</li>
<li>ä½¿ç”¨ well-formed cost function, å¦‚ relative entropy form, å…¶æ¢¯åº¦å¹…å€¼å¤§äºæŸå®šå€¼, ä»è€Œæ€»èƒ½æ‰¾åˆ°è§£(å¦‚æœè§£å­˜åœ¨).</li>
</ul>
<h2 id="56-stochastic-units">5.6 Stochastic Units<a hidden class="anchor" aria-hidden="true" href="#56-stochastic-units">#</a></h2>
<p>å€ŸåŠ© Boltzmann é…åˆ†å‡½æ•°, å®šä¹‰æ¦‚ç‡:</p>
<p>$$
P(S_{i}^{\mu}=+1) = \frac{e^{\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}},\quad
P(S_{i}^{\mu}=-1) = \frac{e^{-\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}}
$$</p>
<blockquote>
<p>$$
h_{i}^{\mu} = \sum_{k}w_{ik}\xi_{k}^{\mu}
$$</p>
</blockquote>
<p>æˆ–è€…å°†å…¶å†™ä½œåˆå¹¶å½¢å¼</p>
<p>$$
P(S_{i}^{\mu}=\pm 1) = \frac{1}{1+\exp{(\mp 2\beta h_{i}^{\mu})}}
$$</p>
<p>äºæ˜¯å¾—åˆ°</p>
<p>$$
\begin{aligned}
\langle S_{i}^{\mu}\rangle &amp;= (+1)\cdot \frac{e^{\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}} + (-1)\cdot \frac{e^{-\beta h_{i}^{\mu}}}{e^{\beta h_{i}^{\mu}} + e^{-\beta h_{i}^{\mu}}} \\
&amp;= \tanh{(\beta h_{i}^{\mu})}\\
&amp;= \tanh\left(
\beta \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)
\end{aligned}
$$</p>
<p>æƒé‡æ›´æ–°</p>
<p>$$
\Delta w_{ik} = \eta\delta_{i}^{\mu}\xi_{k}^{\mu},\quad \delta_{i}^{\mu} = \zeta_{i}^{\mu} - \langle S_{i}^{\mu}\rangle
$$</p>
<p>äºŒæ¬¡å‹ cost function:</p>
<p>$$
E = \frac{1}{2}\sum_{i\mu}(\zeta_{i}^{\mu} - S_{i}^{\mu})^{2} = \sum_{i\mu}(1-\zeta_{i}^{\mu}S_{i}^{\mu})
$$</p>
<blockquote>
<p>$\zeta_{i}^{\mu},O_{i}^{\mu} = \pm 1$.</p>
</blockquote>
<p>å¹³å‡è¯¯å·®(avarage error):</p>
<p>$$
\langle E\rangle
= \sum_{i\mu}(1-\zeta_{i}^{\mu}\langle S_{i}^{\mu}\rangle)
= \sum_{i\mu}\left[
1-\zeta_{i}^{\mu}\tanh{\left(
\beta \sum_{k}w_{ik}\xi_{k}^{\mu}
\right)}
\right]
$$</p>
<p>æ›´æ–°å¼•èµ·çš„ $\langle E\rangle$ å˜åŒ–:</p>
<p>$$
\begin{aligned}
\Delta\langle E\rangle &amp;= \sum_{ik}\Delta w_{ik}\frac{\partial \langle E\rangle}{\partial w_{ik}}\\
&amp;= \sum_{i\mu k}\Delta w_{ik}(-\zeta_{i}^{\mu})\frac{\partial }{\partial w_{ik}}\tanh{(\beta h_{i}^{\mu})}\\
&amp;= -\sum_{i\mu k}\eta[1-\zeta_{i}^{\mu}\tanh{(\beta h_{i}^{\mu})}]\beta \text{ sech}^{2}(\beta h_{i}^{\mu})&lt;0
\end{aligned}
$$</p>
<p>æ‰€ä»¥æ›´æ–°æ€»æ˜¯æ”¹å–„å¹³å‡è¡¨ç°.</p>
<blockquote>
<p>Hints:</p>
<p>$$
\frac{\mathrm{d}}{\mathrm{d}x}\tanh{(x)} = \text{sech}^{2}(x),\quad \text{sech}(x) = \frac{1}{\cosh(x)} = \frac{2}{e^{x}+e^{-x}}\\
\frac{\partial}{\partial w_{ik}}\sum_{l}w_{il}\xi_{l}^{\mu} = \sum_{l}\xi_{l}^{\mu}\delta_{lk} = \xi_{k}^{\mu}
$$</p>
</blockquote>
<h2 id="57-capacity-of-the-simple-perceptronç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡">5.7 Capacity of the Simple Perceptron(ç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡)<a hidden class="anchor" aria-hidden="true" href="#57-capacity-of-the-simple-perceptronç®€å•æ„ŸçŸ¥æœºçš„å®¹é‡">#</a></h2>
<blockquote>
<ul>
<li>å¯å­˜å‚¨å¤šå°‘éšæœº input-output pairs?</li>
<li>é€šè¿‡ç‰¹å®šå­¦ä¹ è§„åˆ™, å¤šå°‘ input-output pairs å¯è¢«å­¦ä¹ ?</li>
</ul>
</blockquote>
<p>continuous-valued units: åªè¦ $p$ ä¸ª patterns çº¿æ€§æ— å…³. å³ $p&lt;N$. å› æ­¤å®¹é‡ $p_{\text{max}} = N$.</p>
<p>threshold units: è¦æ±‚çº¿æ€§å¯åˆ†æ€§(æ˜¯å¦å­˜åœ¨è¶…å¹³é¢äºŒåˆ†æ ·æœ¬). å¯¹äº random continous-valued inputs, $p_{\text{max}} = 2N$.</p>
<blockquote>
<p>$N$ é€šå¸¸ä¸ºå¾ˆå¤§çš„ input units æ•°; output units æ•°å¾ˆå°ä¸”å›ºå®š(ä¸ä¾èµ–äº $N$).</p>
<p>è‹¥ç»™å®š $p$ ä¸ªéšæœºç‚¹äºç©ºé—´ $\mathbb{R}^{N}$ ä¸­, ä¸”å…¶ç›®æ ‡è¾“å‡º/æ ‡ç­¾éšæœºåˆ†é…ä¸º $\pm 1$. å½“ $p\leq 2N$ æ—¶, å‡ ä¹æ€»èƒ½æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢å°†å…¶äºŒåˆ†; è€Œå½“ $p&gt;2N$ æ—¶, çº¿æ€§å¯åˆ†çš„æ¦‚ç‡è¿…é€Ÿä¸‹é™è‡³ 0.</p>
<p>æ¯å¢åŠ ä¸€ä¸ªç»´åº¦, è¶…å¹³é¢éƒ½å¯ä»¥å¤šåˆ†å‰²ä¸¤ä¸ªç‚¹.</p>
</blockquote>
<hr>
<p>è€ƒè™‘ $N$ continous-valued inputs å’Œå•ä¸ª $\pm 1$ output, ä¸” threshold ä¸º $0$(å³ $N-1$ ç»´ hyperplane è¿‡åŸç‚¹).</p>
<p>å°† $p$ ä¸ªç‚¹éšæœºæ”¾ç½®äº $N$ ç»´ç©ºé—´, ä¸”æ ‡ç­¾ä¸º $\pm 1$. ä»¤æ»¡è¶³çº¿æ€§å¯åˆ†æ€§çš„æ”¾ç½®æ–¹æ³•æ•°ä¸º $C(p,N)$.</p>
<blockquote>
<p>åœ¨ $p$ å¾ˆå°æ—¶, $C(p,N)$ å¯è¿‘ä¼¼ä¸º $2^{p}$, å³æ— è®ºæ€æ ·æŸ“è‰²éƒ½èƒ½æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢å°†å…¶äºŒåˆ†. $p$ è¾ƒå¤§æ—¶, å¼€å§‹å‡ºç°çº¿æ€§ä¸å¯åˆ†.</p>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/07/j8DHNkYvXsAiT3w.png" alt=""  /></p>
<p>$N = \{\overset{\cdot}{5},\overset{\cdots}{20},\overset{-}{100}\}$. åœ¨ $p/N = 2$ æ—¶, $C(p,N)/2^{p}$ æ€¥å‰§é™ä½, ä¸” $N$ è¶Šå¤§, è·Œè½è¶Šå¿«.</p>
</blockquote>
<p>éšæœºæ”¾ç½®ç‚¹ä¸æ˜¯å¿…é¡»çš„, éœ€è¦çš„æ˜¯ä»¤å…¶å¤„äº general position(æ»¡è¶³ linearly independent).</p>
<blockquote>
<p>$N=2$, å³äºŒç»´ç©ºé—´æ—¶, çº¿æ€§æ— å…³è¦æ±‚ä¸¤ç‚¹è¿çº¿ä¸è¿‡åŸç‚¹.</p>
</blockquote>
<p>dichotomy: å¯è¢« hyperplane äºŒåˆ†çš„æŸ“è‰²æ–¹æ³•æ•°.</p>
<p>åœ¨å·²æœ‰çš„ dichotomy åŸºç¡€ä¸Šæ·»åŠ ç¬¬ $p+1$ ä¸ªç‚¹,</p>
<ul>
<li>è¯¥ç‚¹æ°å¥½ä½äº hyperplane ä¸Š, åˆ™äº§ç”Ÿä¸¤ä¸ªæ–° dichotomy, å› ä¸ºæ— è®ºå°†è¯¥ç‚¹æ ‡è®°ä¸º $+1$ è¿˜æ˜¯ $-1$, éƒ½å¯ä»¥é€šè¿‡æ— é™å°åç§»åŸ hyperplane æ¥å®ç°äºŒåˆ†;</li>
<li>åªèƒ½æ ‡è®°ä¸ºä¸€ç§é¢œè‰², å¦åˆ™å°†ç ´åçº¿æ€§å¯åˆ†æ€§. åˆ™æ–° dichotomy å¯¹åº”äºåŸæ—§ dichotomy.</li>
</ul>
<p>$$
C(p+1,N) = C(p,N) + D
$$</p>
<blockquote>
<p>$D$ æ˜¯åŸ dichotomies ä¸­ hyperplane å¯åŒæ—¶ç©¿è¿‡åŸç‚¹ $O$ å’Œæ–°ç‚¹ $P$ çš„æ•°é‡.</p>
</blockquote>
<p>è¦æ±‚æ–°ç‚¹ $P$ åœ¨åŸ hyperplane ä¸Š, å®é™…ä¸Šå°±æ˜¯å¤šäº†ä¸€ä¸ªçº¦æŸæ¡ä»¶ $\vec{w}\cdot\vec{\xi}^{P} = 0$, hyperplane å‰©ä¸‹çš„è‡ªç”±åº¦åªæœ‰ $N-1$, è€Œéœ€è¦æŸ“è‰²çš„ç‚¹æ•°ä»ç„¶æ˜¯ $p$ ä¸ªä¸å˜, æ‰€ä»¥å®é™…ä¸Š $D = C(p,N-1)$.</p>
<blockquote>
<p><img loading="lazy" src="https://s2.loli.net/2025/11/07/MebcuYRgBSvCrzO.png" alt=""  />
æ‰€æœ‰ç»è¿‡ $OP$ çš„è¶…å¹³é¢é›†åˆ $\Leftrightarrow$ åœ¨ $N-1$ ç»´ç©ºé—´ä¸­çš„æ‰€æœ‰è¶…å¹³é¢.</p>
<p>å°†åŸ $p$ ä¸ªç‚¹æŠ•å½±åˆ°æ­£äº¤äº $OP$ çš„ $N-1$ ç»´å­ç©ºé—´, å†è€ƒè™‘å…¶çº¿æ€§åˆ†å‰².</p>
</blockquote>
<p>è¿™å°±å½¢æˆäº†é€’æ¨å…³ç³»</p>
<p>$$
C(p+1,N) = C(p,N) + C(p, N-1)
$$</p>
<p>è¿­ä»£å¾—åˆ°</p>
<p>$$
\begin{aligned}
C(p,N) &amp;= \begin{pmatrix}
p-1\\
0\end{pmatrix}C(1,N) + \begin{pmatrix}
p-1\\
1\end{pmatrix}C(1,N-1)+\cdots+\begin{pmatrix}
p-1\\
p-1\end{pmatrix}C(1,N-p+1)\\
&amp;= \sum_{j=0}^{p-1}\begin{pmatrix}
p-1\\
j\end{pmatrix}C(1,N-j) \\
&amp;= \sum_{j=0}^{p-1}C_{p-1}^{j}C(1,N-j)
\end{aligned}
$$</p>
<blockquote>
<p>ç»„åˆæ•°
$$
\begin{pmatrix} m \\ n \end{pmatrix} = \frac{m!}{n!(m-n)!} = C_{m}^{n}
$$</p>
<p>å³ä» $m$ ä¸ªä¸åŒå…ƒç´ ä¸­å–å‡º $n$ ä¸ªå…ƒç´ ($m&gt;n$)çš„æ–¹æ³•æ•°.</p>
</blockquote>
<blockquote>
<p>ä½¿ç”¨å½’çº³æ³•è¯æ˜.</p>
<ol>
<li>å¯¹äº $p=1$, ç”±äº $j\leq p-1$, æœ‰æ„ä¹‰çš„åªæœ‰ $j = 0$ é¡¹. åˆ™ç­‰å·å³è¾¹</li>
</ol>
<p>$$
C_{0}^{0}C(1,N) = 1\cdot C(1,N)
$$</p>
<p>ä¸ç­‰å·å·¦è¾¹ $C(1,N)$ ç›¸ç­‰.</p>
<ol start="2">
<li>å‡å®š $p\geq 1$ æ—¶ç»“è®ºæˆç«‹, åˆ™ $p+1$ æ—¶, éªŒè¯</li>
</ol>
<p>$$
\begin{aligned}
C(p+1,N) &amp;= C(p,N) + C(p,N-1)\\
&amp;= \sum_{j=0}^{p-1}C_{p-1}^{j}C(1,N-j) + \sum_{j=0}^{p-1}C_{p-1}^{j}C(1,N-1-j)\\
k:=j+1\rightarrow &amp;= \sum_{j=0}^{p-1}C_{p-1}^{j}C(1,N-j) + \sum_{k=1}^{p}C_{p-1}^{k-1}C(1,N-k)\\
&amp;= C_{p-1}^{0}C(1,N) + \sum_{j=1}^{p-1}[C_{p-1}^{j}+C_{p-1}^{j-1}]C(1,N-j) + C_{p-1}^{p-1}C(1,N-p)\\
&amp;= C_{p}^{0}C(1,N) + \sum_{j=1}^{p-1}C_{p}^{j}C(1,N-j) + C_{p}^{p}C(1,N-p)\\
&amp;= \sum_{j=0}^{p}C_{p}^{j}C(1,N-j)
\end{aligned}
$$</p>
<p>æ­£æ˜¯å– $p+1$ æ—¶çš„å…¬å¼.</p>
<blockquote>
<p>Pascal æ’ç­‰å¼</p>
<p>$$
C_{p}^{j} = C_{p-1}^{j} + C_{p-1}^{j-1}
$$</p>
<p>å³ä» $p$ ä¸ªå…ƒç´ ä¸­é€‰å– $j$ ä¸ªå…ƒç´ , ç­‰æ•ˆäºå…ˆç¡®å®šæŸå›ºå®šç‰¹æ®Šå…ƒç´  $x$, é‚£ä¹ˆ</p>
<ol>
<li>ä¸å«è¯¥å…ƒç´ , å³åœ¨å‰©ä¸‹ $p-1$ ä¸ªå…ƒç´ ä¸­é€‰å– $j$ ä¸ªå…ƒç´ , å³ $C_{p-1}^{j}$;</li>
<li>ä¸€å®šè¦é€‰å–å…ƒç´  $x$, è¿˜æœ‰ $j-1$ ä¸ªå…ƒç´ æ²¡æœ‰é€‰å–, å¹¶ä¸”è¦åœ¨å‰©ä¸‹çš„ $p-1$ ä¸ªå…ƒç´ ä¸­é€‰, å³ $C_{p-1}^{j-1}$.</li>
</ol>
</blockquote>
</blockquote>
<ul>
<li>$p\leq N$: $\forall N$, $C(1,N)=2$, å› ä¸ºä¸€ä¸ªç‚¹å¯ä»¥ä»»æ„æŸ“è‰² $\pm 1$.</li>
<li>$p&gt;N$: å– $N\leq 0$ çš„ $C(p,N) = 0$.</li>
</ul>
<p>æ‰€ä»¥å…¬å¼ä¸­çš„ $C(1,N-j) = 2$. ä»£å…¥å¾—åˆ°</p>
<p>$$
C(p,N) = 2\sum_{i=0}^{N-1}C_{p-1}^{i} = 2\sum_{i=0}^{N-1}\begin{pmatrix}
p-1\\
i
\end{pmatrix}
$$</p>
<blockquote>
<p>å½“ $p = 2N$ æ—¶, åˆ©ç”¨äºŒé¡¹å¼ç³»æ•°çš„å¯¹ç§°æ€§ $C_{2n}^{n-m} = C_{2n}^{n+m}$, å¾—åˆ° $C(2N,N) = 2^{p-1}$. å’Œå›¾ä¸­ $p/N = 2$ æ—¶ $C(p,N)/2^{p} = 1/2$ ä¸€è‡´</p>
</blockquote>
<p>åœ¨ $N$ å……åˆ†å¤§æ—¶, å¯å°†äºŒé¡¹å¼ç³»æ•°å¤„ç†ä¸º Guassian æé™:</p>
<p>$$
\frac{C(p,N)}{2^{p}} \approx \frac{1}{2}\left[
1 + \text{erf }\left(
\sqrt{\frac{p}{2}}\left(
\frac{2N}{p} - 1
\right)
\right)
\right]
$$</p>
<p>è¯æ˜:</p>
<p>$$
\frac{C(p,N)}{2^{p}} = \frac{2\sum_{i=0}^{N-1}C_{p-1}^{i}}{2^{p}} = \sum_{i=0}^{N-1}\frac{C_{p-1}^{i}}{2^{p-1}} = \text{Prob}(X\leq N-1)
$$</p>
<blockquote>
<p>æ³¨æ„åˆ° $\begin{aligned}
P(X = i) = C_{p-1}^{i}\left(\frac{1}{2}\right)^{p-1}
\end{aligned}$, åˆ™å¯å¼•å…¥äºŒé¡¹åˆ†å¸ƒ $X\sim B(p-1, 0.5)$.</p>
</blockquote>
<p>$$
\langle X\rangle = \frac{1}{2}\cdot (p-1) = \frac{p-1}{2};\quad (\Delta X)^{2} = \langle X^{2}\rangle - \langle X\rangle^{2} = \frac{p-1}{4}
$$</p>
<blockquote>
<p><strong>De Moivreâ€“Laplace theorem</strong></p>
<p>è‹¥ $X\sim B(n,p)$, ä»¤ $\begin{aligned}z = \frac{x-\langle X\rangle}{\Delta X} = \frac{x-np}{\sqrt{np(1-p)}}\end{aligned}$. å½“ $n\rightarrow \infty$:</p>
<ul>
<li>$\begin{aligned}P(X = x) = \frac{1}{\sqrt{np(1-p)}}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^{2}}\end{aligned}$;</li>
<li>$\begin{aligned}P(a\leq z\leq b) = \int_{a}^{b}\frac{1}{\sqrt{2\pi}}e^{-\frac{z^{2}}{2}}\mathrm{d}z\end{aligned}$.</li>
</ul>
</blockquote>
<p>å®šä¹‰ $\begin{aligned}\Phi(z) = \frac{1}{2}\left[1 + \text{erf}\left(\frac{z}{2}\right)\right]\end{aligned}$</p>
<p>$$
\begin{aligned}
\frac{C(p,N)}{2^{p}} &amp;\approx \Phi\left(\frac{(N-1)-\frac{p-1}{2}}{\sqrt{\frac{p-1}{4}}}\right)\approx \Phi\left(\frac{N - \frac{p}{2}}{\sqrt{\frac{p}{4}}}\right)\\
&amp;= \frac{1}{2}\left\{
1+ \text{erf}\left[\sqrt{\frac{p}{2}}\left(
\frac{2N}{p} - 1
\right)\right]
\right\} &amp; \square
\end{aligned}
$$</p>
<p>Hopfield network é€šè¿‡å¸å¼•å­å­˜å‚¨, å…¶ä¸å¯ç›¸äº’å¹²æ‰°, å³ç¨³å®šæ¡ä»¶æ›´ä¸¥æ ¼. å› æ­¤ $\alpha_{c} \approx 0.138$ ç›¸è¾ƒäº perceptron çš„è¦å°çš„å¤š.</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://Muatyz.github.io/posts/read/reference/statistical-mechanics-for-networks-of-real-neurons/statistical-mechanics-for-networks-of-real-neurons-5/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>A unique test</span>
  </a>
  <a class="next" href="https://Muatyz.github.io/posts/read/reference/statistical-mechanics-for-networks-of-real-neurons/statistical-mechanics-for-networks-of-real-neurons-6/">
    <span class="title">ä¸‹ä¸€é¡µ Â»</span>
    <br>
    <span>Criticality</span>
  </a>
</nav>

        </footer>
    </div>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: 'ğŸ‘‰å±•å¼€è¯„è®º';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: 'ğŸ‘‡å…³é—­è¯„è®º';
        color: var(--content);
    }
</style>





<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.16/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-api-one-xi.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            region: 'ap-shanghai',  
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>
</article>
</main>

<footer class="footer">
    <span>Muartz</span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script><script>

    let detail = document.getElementsByClassName('details')
   
    details = [].slice.call(detail);
   
    for (let index = 0; index < details.length; index++) {
   
    let element = details[index]
   
    const summary = element.getElementsByClassName('details-summary')[0];
   
    if (summary) {
   
    summary.addEventListener('click', () => {
   
    element.classList.toggle('open');
   
    }, false);
   
    }
   
    }
   
   </script>   

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'å·²å¤åˆ¶ï¼';
            setTimeout(() => {
                copybutton.innerText = 'å¤åˆ¶';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\r\n' +
                    'ç‰ˆæƒå£°æ˜ï¼šæœ¬æ–‡ä¸ºã€Œ'+"æ— å¤„æƒ¹å°˜åŸƒ"+'ã€çš„åŸåˆ›æ–‡ç« ï¼Œéµå¾ªCC 4.0 BY-SAç‰ˆæƒåè®®ï¼Œè½¬è½½è¯·é™„ä¸ŠåŸæ–‡å‡ºå¤„é“¾æ¥åŠæœ¬å£°æ˜ã€‚' +
                '\r\nåŸæ–‡é“¾æ¥ï¼š' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>


<script>
    
    document.addEventListener('keydown', function(event) {
      
      if (event.key === 'j') {
        
        var nextPageLink = document.querySelector('.pagination-item.pagination-next > a');
        if (nextPageLink) {
          nextPageLink.click();
        }
      } else if (event.key === 'k') {
        
        var prevPageLink = document.querySelector('.pagination-item.pagination-previous > a');
        if (prevPageLink) {
          prevPageLink.click();
        }
      }
    });
  </script>
  
</body>







<body>
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
</body>


</html>
